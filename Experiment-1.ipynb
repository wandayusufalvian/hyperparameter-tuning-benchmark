{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T05:57:59.330218Z",
     "start_time": "2020-11-18T05:57:59.316208Z"
    }
   },
   "source": [
    "## Import Library dan data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T14:20:39.710823Z",
     "start_time": "2021-01-10T14:20:38.448951Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from hpbandster_sklearn import HpBandSterSearchCV\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "\n",
    "\n",
    "from skopt.space import Real,Integer\n",
    "\n",
    "\n",
    "from hpbandster.optimizers import BOHB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T14:20:34.660324Z",
     "start_time": "2021-01-10T14:20:34.590336Z"
    }
   },
   "outputs": [],
   "source": [
    "X_bank=pd.read_csv('dataset/X_bank_preprocessed.csv').to_numpy()\n",
    "y_bank=pd.read_csv('dataset/y_bank_preprocessed.csv').to_numpy().ravel()\n",
    "\n",
    "X_credit=pd.read_csv('dataset/X_credit.csv').to_numpy()\n",
    "y_credit=pd.read_csv('dataset/y_credit.csv').to_numpy().ravel()\n",
    "\n",
    "X_income=pd.read_csv('dataset/X_income.csv').to_numpy()\n",
    "y_income=pd.read_csv('dataset/y_income.csv').to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model dan Search Space of Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost : \n",
    "- hyper_space_1  : untuk GS\n",
    "- hyper_space_2  : untuk RS\n",
    "- hyper_space_3  : untuk BO\n",
    "- hyper_space_4  : untuk BOHB\n",
    "\n",
    "LightGBM :\n",
    "- hyper_space_5  : untuk GS\n",
    "- hyper_space_6  : untuk RS\n",
    "- hyper_space_7  : untuk BO\n",
    "- hyper_space_8  : untuk BOHB\n",
    "\n",
    "CatBoost :\n",
    "- hyper_space_9  : untuk GS\n",
    "- hyper_space_10 : untuk RS\n",
    "- hyper_space_11 : untuk BO\n",
    "- hyper_space_12 : untuk BOHB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inisialisasi Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T14:18:36.487987Z",
     "start_time": "2020-12-28T14:18:35.331987Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier \n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model_x=XGBClassifier()\n",
    "model_l=LGBMClassifier()\n",
    "model_c=CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T14:17:48.344300Z",
     "start_time": "2020-12-28T14:17:48.297731Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper_space_1={\n",
    "    'eta': [0.01,0.5], \n",
    "    'subsample': [0.1,0.8],\n",
    "    'max_depth': [2,8,14,20,26],\n",
    "    'gamma':[0.001,0.4],\n",
    "    'min_child_weight':[2,5,7,11,15]\n",
    "}\n",
    "\n",
    "hyper_space_2={\n",
    "    'eta': list(np.logspace\n",
    "                (np.log10(0.001),np.log10(1),base=10,num=1000)), \n",
    "    'subsample': list(np.linspace(0.1,1,100)),\n",
    "    'max_depth':list(range(1,101)),\n",
    "    'gamma':list(np.linspace(0.001,2,100)),\n",
    "    'min_child_weight':list(range(1,101))\n",
    "}\n",
    "\n",
    "hyper_space_3={\n",
    "    'eta': Real(0.001,1,'log-uniform'), \n",
    "    'subsample': Real(0.1,1,'uniform'),\n",
    "    'max_depth': Integer(1,100,'uniform'),\n",
    "    'gamma': Real(0.001,2,'uniform'),\n",
    "    'min_child_weight': Integer(1,100,'uniform')\n",
    "}\n",
    "\n",
    "def hyper_space_4(benih):\n",
    "    cs = CS.ConfigurationSpace(seed=benih)\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('eta',lower=0.001,upper=1,log=True))\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('subsample',lower=0.1,upper=1,log=False))\n",
    "    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter\n",
    "                          ('max_depth',lower=1,upper=100,log=False))\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('gamma',lower=0.001,upper=2,log=False))\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('min_child_weight',lower=1,upper=100,log=False))\n",
    "    return cs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T02:31:27.405361Z",
     "start_time": "2020-12-29T02:31:27.387366Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper_space_5={\n",
    "    'max_depth': [10,20,30,40,50],\n",
    "    'min_data_in_leaf':[10,30,50,70,90],\n",
    "    'num_leaves': [10,40],\n",
    "    'learning_rate': [0.01,0.5], \n",
    "    'bagging_fraction':[0.1,0.9]\n",
    "}\n",
    "\n",
    "hyper_space_6={\n",
    "    'max_depth': list(range(1,101)),\n",
    "    'min_data_in_leaf':list(range(1,101)),\n",
    "    'num_leaves': list(range(10,101)),\n",
    "    'learning_rate': list(np.logspace\n",
    "                          (np.log10(0.001),np.log10(1),base=10,num=1000)),\n",
    "    'bagging_fraction':list(np.linspace(0.1,1,100))\n",
    "}\n",
    "\n",
    "hyper_space_7={\n",
    "    'max_depth': Integer(1,100,'uniform'),\n",
    "    'min_data_in_leaf': Integer(1,100,'uniform'),\n",
    "    'num_leaves': Integer(10,100,'uniform'),\n",
    "    'learning_rate': Real(0.001,1,'log-uniform'),\n",
    "    'bagging_fraction':Real(0.1,1,'uniform')    \n",
    "}\n",
    "\n",
    "def hyper_space_8(benih):\n",
    "    cs = CS.ConfigurationSpace(seed=benih)\n",
    "    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter\n",
    "                          ('max_depth',lower=1,upper=100,log=False))\n",
    "    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter\n",
    "                          ('min_data_in_leaf',lower=1,upper=100,log=False))\n",
    "    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter\n",
    "                          ('num_leaves',lower=1,upper=100,log=False))\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('learning_rate',lower=0.001,upper=1,log=True))\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('bagging_fraction',lower=0.1,upper=1,log=False))\n",
    "    \n",
    "    return cs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_space_9={\n",
    "    'max_depth': [2,5,8,11,14],\n",
    "    'learning_rate': [0.01,0.1],\n",
    "    'l2_leaf_reg':[1,6,11,16,21],\n",
    "    'bagging_temperature':[0.5,20],\n",
    "    'random_strength':[0.5,20]\n",
    "}\n",
    "\n",
    "hyper_space_10={\n",
    "    'max_depth': list(range(1,17)),\n",
    "    'learning_rate': list(np.logspace\n",
    "                          (np.log10(0.001),np.log10(1),base=10,num=1000)),\n",
    "    'l2_leaf_reg':list(np.linspace(1,50,100)),\n",
    "    'bagging_temperature':list(np.linspace(1,50,100)),\n",
    "    'random_strength':list(np.linspace(1,50,100))\n",
    "}\n",
    "\n",
    "hyper_space_11={\n",
    "    'max_depth': Integer(1,16,'uniform'),\n",
    "    'learning_rate': Real(0.001,1,'log-uniform'),\n",
    "    'l2_leaf_reg': Real(1,50,'uniform'),\n",
    "    'bagging_temperature':Real(1,50,'uniform'),\n",
    "    'random_strength':Real(1,50,'uniform')\n",
    "}\n",
    "\n",
    "def hyper_space_12(benih):\n",
    "    cs = CS.ConfigurationSpace(seed=benih)\n",
    "    cs.add_hyperparameter(CSH.UniformIntegerHyperparameter\n",
    "                          ('max_depth',lower=1,upper=16,log=False))\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('learning_rate',lower=0.001,upper=1,log=True))\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('l2_leaf_reg',lower=1,upper=50,log=False))\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('bagging_temperature',lower=1,upper=50,log=False))\n",
    "    cs.add_hyperparameter(CSH.UniformFloatHyperparameter\n",
    "                          ('random_strength',lower=1,upper=50,log=False))\n",
    "    return cs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T10:39:16.417693Z",
     "start_time": "2020-12-22T10:39:14.950489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribusi untuk eta atau learning rate \n",
    "import seaborn as sns\n",
    "\n",
    "# Learning rate histogram\n",
    "plt.hist(hyper_space_2['eta'], bins = 20, color = 'r', edgecolor = 'k');\n",
    "plt.xlabel('Learning Rate', size = 14); plt.ylabel('Count', size = 14); plt.title('Learning Rate Distribution', size = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T11:39:05.668906Z",
     "start_time": "2020-12-22T11:39:05.656980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 333 values between 0.001 and 0.01\n",
      "There are 333 values between 0.01 and 0.1\n",
      "There are 333 values between 0.1 and 1\n"
     ]
    }
   ],
   "source": [
    "# Check number of values in each category\n",
    "a,b,c = 0,0,0\n",
    "\n",
    "\n",
    "for x in hyper_space_2['eta']:\n",
    "    # Check values\n",
    "    if x >= 0.001 and x < 0.01:\n",
    "        a += 1\n",
    "    elif x >= 0.01 and x < 0.1:\n",
    "        b += 1\n",
    "    elif x >= 0.1 and x < 1:\n",
    "        c += 1\n",
    "\n",
    "print('There are {} values between 0.001 and 0.01'.format(a))\n",
    "print('There are {} values between 0.01 and 0.1'.format(b))\n",
    "print('There are {} values between 0.1 and 1'.format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T14:17:58.712908Z",
     "start_time": "2020-12-28T14:17:58.705328Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_search(X,y,model,parameter,iterasi,evalscore,seed):\n",
    "    auc=[]\n",
    "    std=[]\n",
    "\n",
    "    random_search=RandomizedSearchCV(\n",
    "                   model,\n",
    "                   parameter, \n",
    "                   n_iter=iterasi, \n",
    "                   scoring=evalscore, \n",
    "                   n_jobs=-1, \n",
    "                   cv=5, \n",
    "                   random_state=seed,\n",
    "                   verbose= 1)\n",
    "    \n",
    "    random_search.fit(X,y)\n",
    "\n",
    "    best_index=random_search.best_index_\n",
    "    auc.append(random_search.cv_results_['mean_test_score'])\n",
    "    std.append(random_search.cv_results_['std_test_score'])\n",
    "    best_param=random_search.best_params_\n",
    "    \n",
    "    return auc,std,best_index,best_param\n",
    "\n",
    "def grid_search(X,y,model,parameter,evalscore):\n",
    "    auc=[]\n",
    "    std=[]\n",
    "\n",
    "    grid_search=GridSearchCV(\n",
    "                model,\n",
    "                parameter,\n",
    "                scoring = evalscore,\n",
    "                n_jobs = -1,\n",
    "                cv = 5,\n",
    "                verbose= 1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X,y)\n",
    "\n",
    "    best_index=grid_search.best_index_\n",
    "    auc.append(grid_search.cv_results_['mean_test_score'])\n",
    "    std.append(grid_search.cv_results_['std_test_score'])\n",
    "    best_param=grid_search.best_params_\n",
    "    \n",
    "    return auc,std,best_index,best_param\n",
    "\n",
    "def bayes_opt(X,y,model,parameter,iterasi,evalscore,seed):\n",
    "    \n",
    "    auc=[]\n",
    "    std=[]\n",
    "\n",
    "    bayes_search= BayesSearchCV(\n",
    "                   model, \n",
    "                   parameter, \n",
    "                   n_jobs=-1, \n",
    "                   n_iter=iterasi,\n",
    "                   scoring=evalscore,\n",
    "                   cv=5,\n",
    "                   random_state=seed,\n",
    "                   verbose= 0,\n",
    "                   iid=True \n",
    "    )\n",
    "    \n",
    "    bayes_search.fit(X,y)\n",
    "    \n",
    "    best_index=bayes_search.best_index_\n",
    "    auc.append(bayes_search.cv_results_['mean_test_score'])\n",
    "    std.append(bayes_search.cv_results_['std_test_score'])\n",
    "    best_param=bayes_search.best_params_\n",
    "    \n",
    "    return auc,std,best_index,best_param\n",
    "\n",
    "# def bohb(X,y,model,parameter,iterasi,evalscore):\n",
    "#     auc=[]\n",
    "#     std=[]\n",
    "    \n",
    "#     bohb_search=HpBandSterSearchCV(\n",
    "#                 model,\n",
    "                \n",
    "#                 )\n",
    "    \n",
    "# def bohb_2():\n",
    "#     NS=hpns.NameServer(run_id='example1',host='127.0.0.1',port=None)\n",
    "#     NS.start()\n",
    "#     w=MyWorker(sleep_interval=0,nameserver='127.0.0.1',run_id='example1')\n",
    "#     w.run(background=True)\n",
    "#     bohb=BOHB(configspace=w.get_configspace(),\n",
    "#               run_id='example1',\n",
    "#               nanme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisasi Hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T05:14:32.510480Z",
     "start_time": "2020-12-29T05:14:32.492604Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_hasil(iteration,auc,std,best_param,best_index):\n",
    "    print(\"Iterasi: \",iteration)\n",
    "    print(\"All AUC: \",auc,'\\n')\n",
    "    print(\"mean AUC : \", np.mean(auc))\n",
    "    print(\"All std: \",std,'\\n')\n",
    "    print(\"Best Hyperparameter: \",best_param,'\\n')\n",
    "    print(\"Best index/iterasi : \",best_index)\n",
    "    print(\"Best AUC :\",auc[0][best_index],\"( std:\",std[0][best_index],\")\",'\\n')\n",
    "\n",
    "def scatter_plot_1(x,y,best_index,iteration,label_x,label_y):\n",
    "    fig=plt.figure(figsize=(20,5))\n",
    "    plt.scatter(x,y)\n",
    "    plt.plot(x[best_index],y[best_index],marker='*',markersize=22,markerfacecolor='yellow')\n",
    "    fig=plt.xticks(range(1,iteration+1))\n",
    "    fig=plt.xlabel(label_x)\n",
    "    fig=plt.ylabel(label_y)\n",
    "    fig=plt.xticks(range(0,210,10))\n",
    "    \n",
    "def line_plot_1(iteration,label_x,label_y):\n",
    "    fig=plt.figure(figsize=(20,5))\n",
    "    x=range(1,iteration+1)\n",
    "    y=auc[0]\n",
    "    error=std[0]\n",
    "    plt.plot(x,y,'or')\n",
    "    plt.plot(x,y,color='gray')\n",
    "    plt.plot(x[best_index],y[best_index],marker='*',markersize=22,markerfacecolor='yellow')\n",
    "    fig=plt.xticks(range(1,iteration+1))\n",
    "    fig=plt.xlabel(label_x)\n",
    "    fig=plt.ylabel(label_y)\n",
    "    fig=plt.xticks(range(0,210,10))\n",
    "    \n",
    "def line_plot_2(x,y,label_x,label_y):\n",
    "    fig=plt.figure(figsize=(20,5))\n",
    "    rata2=np.mean(best_auc)\n",
    "    y_rata2=np.array([rata2,rata2])\n",
    "    x_rata2=np.array([x[0],x[x.size-1]])\n",
    "    plt.plot(x_rata2,y_rata2,'gray')\n",
    "    plt.scatter(x,y,s=100)\n",
    "    plt.vlines(x, y, np.array([rata2]*x.size), linestyle=\"dashed\")\n",
    "    plt.plot(x[np.where(y==np.max(y))],np.max(y),marker='*',markersize=22,markerfacecolor='yellow')\n",
    "    fig=plt.xticks(x,fontsize=20)\n",
    "    fig=plt.yticks(fontsize=20)\n",
    "    fig=plt.xlabel(label_x,fontsize=20)\n",
    "    fig=plt.ylabel(label_y,fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Experiment 1: \n",
    "    - Random search \n",
    "    - Iterasi : 200\n",
    "    - random state= 1,12,22,32,42,52,62,72,82,92\n",
    "- Experiment 2: \n",
    "    - BO (gaussian process) \n",
    "    - iterasi : 200\n",
    "    - random state= 1,12,22,32,42,52,62,72,82,92\n",
    "- Experiment 3: \n",
    "    - GS \n",
    "- Experiment 4: \n",
    "    - BOHB \n",
    "    - random state= 1,12,22,32,42,52,62,72,82,92\n",
    "- Experiment 5: \n",
    "    - default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dataset 1 (Bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T22:04:40.304867Z",
     "start_time": "2020-12-22T13:03:31.992687Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 56.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.69435251, 0.64560267, 0.69927825, 0.66355059, 0.63494667,\n",
      "       0.61164226, 0.63211011, 0.58447049, 0.67608159, 0.70117667,\n",
      "       0.70423483, 0.78435882, 0.6172116 , 0.78717867, 0.81756688,\n",
      "       0.6001899 , 0.55522184, 0.57915515, 0.65626428, 0.70727716,\n",
      "       0.69062679, 0.74823268, 0.69429067, 0.56678073, 0.79897098,\n",
      "       0.52329022, 0.60875337, 0.58435658, 0.80894147, 0.78463278,\n",
      "       0.54352735, 0.62512766, 0.5397341 , 0.70598199, 0.71235449,\n",
      "       0.73125775, 0.71764783, 0.76953782, 0.51570915, 0.56225407,\n",
      "       0.72241752, 0.63004175, 0.50769273, 0.72811126, 0.74481943,\n",
      "       0.66312437, 0.70149469, 0.69673343, 0.70235935, 0.80048493,\n",
      "       0.79614475, 0.60477837, 0.72132402, 0.74864474, 0.7429541 ,\n",
      "       0.69282731, 0.77408389, 0.80277391, 0.55093267, 0.75214278,\n",
      "       0.59974246, 0.76209993, 0.82089491, 0.53609963, 0.5589035 ,\n",
      "       0.69741   , 0.61805897, 0.57910253, 0.71853587, 0.53323401,\n",
      "       0.67033418, 0.75585521, 0.72946056, 0.63589849, 0.81203773,\n",
      "       0.73624983, 0.54483061, 0.62659213, 0.75948766, 0.60838707,\n",
      "       0.56897686, 0.7340817 , 0.61497817, 0.59859969, 0.77433626,\n",
      "       0.69799762, 0.81958826, 0.72682603, 0.55318995, 0.66623418,\n",
      "       0.82425638, 0.65923595, 0.74454078, 0.51377322, 0.64769357,\n",
      "       0.52133513, 0.76004414, 0.54520957, 0.58679161, 0.75109246,\n",
      "       0.67922438, 0.69336858, 0.60786289, 0.65719932, 0.80758985,\n",
      "       0.67280749, 0.70700269, 0.54207073, 0.67490223, 0.53316997,\n",
      "       0.56592435, 0.59481985, 0.74093588, 0.73047245, 0.67926446,\n",
      "       0.6055887 , 0.58994952, 0.62672309, 0.67175598, 0.68454505,\n",
      "       0.78473255, 0.81181384, 0.68292942, 0.62167472, 0.58392552,\n",
      "       0.80986097, 0.71399482, 0.76944922, 0.80740715, 0.64342978,\n",
      "       0.76330071, 0.80204796, 0.78348193, 0.63140686, 0.68320172,\n",
      "       0.72676594, 0.70733157, 0.75962509, 0.52572989, 0.70459507,\n",
      "       0.55583098, 0.52555345, 0.81428705, 0.62227793, 0.62264094,\n",
      "       0.58424325, 0.68047147, 0.53279096, 0.6557745 , 0.81267221,\n",
      "       0.63697731, 0.55153152, 0.81497488, 0.81731615, 0.66348708,\n",
      "       0.81863078, 0.55155971, 0.66355337, 0.67932488, 0.71137855,\n",
      "       0.71428336, 0.63839571, 0.80871761, 0.76147981, 0.68306834,\n",
      "       0.69474122, 0.74322096, 0.71510288, 0.72880255, 0.70482693,\n",
      "       0.71447459, 0.71793149, 0.50906436, 0.69813861, 0.69874313,\n",
      "       0.77256213, 0.71377696, 0.72271963, 0.53890272, 0.73772801,\n",
      "       0.60869935, 0.48995939, 0.6262425 , 0.54742469, 0.72005607,\n",
      "       0.66780469, 0.59572658, 0.58585764, 0.72398342, 0.77569731,\n",
      "       0.62086321, 0.71975324, 0.7300704 , 0.81549177, 0.78127173,\n",
      "       0.63140181, 0.71474265, 0.66964789, 0.68515151, 0.6506066 ])] \n",
      "\n",
      "mean AUC :  0.6767702743473243\n",
      "All std:  [array([0.15050289, 0.10751582, 0.12527336, 0.13087735, 0.12261115,\n",
      "       0.07683103, 0.08443143, 0.0791974 , 0.12648015, 0.12435247,\n",
      "       0.13615219, 0.09293186, 0.12412737, 0.08970577, 0.07146884,\n",
      "       0.06865566, 0.04970713, 0.13160604, 0.1090527 , 0.12572247,\n",
      "       0.13568478, 0.10342405, 0.14417749, 0.12250225, 0.07212502,\n",
      "       0.08450503, 0.06948132, 0.12249413, 0.07743998, 0.09121708,\n",
      "       0.06548338, 0.12187967, 0.08271482, 0.12764676, 0.12880814,\n",
      "       0.12620892, 0.12081763, 0.08123046, 0.11029222, 0.05899737,\n",
      "       0.12904178, 0.12859577, 0.11093632, 0.1253693 , 0.10913935,\n",
      "       0.11872126, 0.1168302 , 0.13700223, 0.11188084, 0.07661627,\n",
      "       0.08028741, 0.1215434 , 0.15602938, 0.11795419, 0.11840733,\n",
      "       0.1219148 , 0.08417007, 0.07693469, 0.07893675, 0.1088544 ,\n",
      "       0.13392132, 0.10112098, 0.06036131, 0.04293022, 0.10563516,\n",
      "       0.13896376, 0.08922586, 0.12793688, 0.12220316, 0.04746696,\n",
      "       0.12991213, 0.10789704, 0.1180859 , 0.11389588, 0.06999578,\n",
      "       0.118835  , 0.07631222, 0.1165328 , 0.09524636, 0.10533507,\n",
      "       0.08236014, 0.13405867, 0.12503323, 0.09054955, 0.08955866,\n",
      "       0.15318651, 0.06824497, 0.12043743, 0.0991943 , 0.10904975,\n",
      "       0.06381591, 0.1317882 , 0.10529047, 0.05832544, 0.10221907,\n",
      "       0.11862427, 0.10432423, 0.093809  , 0.08375469, 0.10647755,\n",
      "       0.12485169, 0.12138283, 0.07425219, 0.1093223 , 0.07261455,\n",
      "       0.12586469, 0.13599537, 0.13538445, 0.13162752, 0.11768955,\n",
      "       0.08178789, 0.09447053, 0.10874618, 0.13047289, 0.13674497,\n",
      "       0.11273624, 0.1066848 , 0.11774675, 0.1321102 , 0.12066   ,\n",
      "       0.09580951, 0.07255671, 0.12503583, 0.13375282, 0.1290224 ,\n",
      "       0.07662818, 0.11753415, 0.08308364, 0.07558589, 0.1081669 ,\n",
      "       0.098752  , 0.0717267 , 0.08723493, 0.12171734, 0.11970685,\n",
      "       0.11262721, 0.12664868, 0.08785849, 0.07941229, 0.12181209,\n",
      "       0.08348815, 0.10893151, 0.07024891, 0.07518509, 0.12393961,\n",
      "       0.10739331, 0.11839889, 0.11044082, 0.12340505, 0.07147887,\n",
      "       0.12114209, 0.06264131, 0.0716679 , 0.07016468, 0.12911631,\n",
      "       0.06781789, 0.10064311, 0.12918458, 0.12642097, 0.12363748,\n",
      "       0.14228155, 0.1006349 , 0.07105855, 0.09532965, 0.12549554,\n",
      "       0.14029641, 0.11595844, 0.13673259, 0.10586632, 0.11438387,\n",
      "       0.13417032, 0.12916544, 0.06879299, 0.12141073, 0.13194147,\n",
      "       0.09790974, 0.11765447, 0.13700392, 0.11835344, 0.11910028,\n",
      "       0.10398779, 0.08564091, 0.13222744, 0.04786305, 0.12411676,\n",
      "       0.13102571, 0.11493084, 0.13445086, 0.12697459, 0.09421474,\n",
      "       0.1400465 , 0.15254858, 0.11886201, 0.07368648, 0.09157353,\n",
      "       0.09254519, 0.13406697, 0.12462721, 0.13005555, 0.12910428])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.1, 'min_child_weight': 66, 'max_depth': 47, 'gamma': 1.9192323232323232, 'eta': 0.0595353313081437} \n",
      "\n",
      "Best index/iterasi :  90\n",
      "Best AUC : 0.8242563760720285 ( std: 0.06381591199289659 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 55.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  12 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.71183392, 0.71338635, 0.7284385 , 0.58400405, 0.70611855,\n",
      "       0.77278138, 0.59970852, 0.48149445, 0.68362131, 0.6160835 ,\n",
      "       0.81316176, 0.7052693 , 0.71424892, 0.75665407, 0.76409603,\n",
      "       0.64613215, 0.56486789, 0.79188734, 0.79054963, 0.67002459,\n",
      "       0.72344733, 0.71974371, 0.74104528, 0.81782924, 0.53635057,\n",
      "       0.72269808, 0.71152594, 0.54417765, 0.78000207, 0.69349072,\n",
      "       0.60970061, 0.68077381, 0.75150597, 0.73064879, 0.71288947,\n",
      "       0.56571519, 0.76785516, 0.66606954, 0.75142572, 0.76912531,\n",
      "       0.65630301, 0.61633686, 0.72421911, 0.65899685, 0.52271224,\n",
      "       0.6066857 , 0.70122005, 0.71113171, 0.65713758, 0.78352448,\n",
      "       0.81560225, 0.58051213, 0.81346382, 0.6231893 , 0.6955692 ,\n",
      "       0.81572318, 0.76164486, 0.66444786, 0.66085182, 0.63617212,\n",
      "       0.67526929, 0.72694509, 0.66936268, 0.57566079, 0.69415137,\n",
      "       0.65654083, 0.68915039, 0.76722977, 0.52580756, 0.80993013,\n",
      "       0.71842874, 0.81286359, 0.55343368, 0.6988275 , 0.49553032,\n",
      "       0.5208561 , 0.6325654 , 0.57188034, 0.8165622 , 0.68877705,\n",
      "       0.61676662, 0.69300052, 0.69777698, 0.63075594, 0.68772993,\n",
      "       0.69001649, 0.72560996, 0.75223995, 0.65398045, 0.66310322,\n",
      "       0.73952351, 0.48350382, 0.8082816 , 0.71353544, 0.57632769,\n",
      "       0.56956454, 0.77690135, 0.60537034, 0.6979206 , 0.6176303 ,\n",
      "       0.62435714, 0.61999347, 0.75917482, 0.66235373, 0.81079552,\n",
      "       0.69073362, 0.76673891, 0.71554195, 0.69868136, 0.52561711,\n",
      "       0.53952594, 0.80708974, 0.52536232, 0.60188877, 0.68400178,\n",
      "       0.55625311, 0.55868991, 0.55253683, 0.67083735, 0.69065   ,\n",
      "       0.65640677, 0.52465679, 0.68487159, 0.67834656, 0.66471352,\n",
      "       0.77011455, 0.76321824, 0.69014259, 0.57168555, 0.72165496,\n",
      "       0.71362409, 0.77319274, 0.65200324, 0.71150682, 0.74198487,\n",
      "       0.67210321, 0.76231336, 0.76195536, 0.55191047, 0.49240131,\n",
      "       0.75782721, 0.72223935, 0.62697574, 0.60439065, 0.72591389,\n",
      "       0.6688266 , 0.7270454 , 0.65002586, 0.64744628, 0.60693848,\n",
      "       0.68170004, 0.57137935, 0.78498463, 0.56217531, 0.65168707,\n",
      "       0.70970731, 0.8106884 , 0.52747551, 0.79942919, 0.71783236,\n",
      "       0.7227272 , 0.7140641 , 0.77759669, 0.80350209, 0.76968661,\n",
      "       0.6890192 , 0.71327228, 0.77532173, 0.71444861, 0.62370588,\n",
      "       0.71227835, 0.7130816 , 0.57344195, 0.52235641, 0.77078698,\n",
      "       0.6986521 , 0.58259665, 0.75242104, 0.81105633, 0.63472236,\n",
      "       0.81616373, 0.63312476, 0.51400949, 0.77262565, 0.67025349,\n",
      "       0.75240752, 0.6574842 , 0.67425256, 0.69519652, 0.64451646,\n",
      "       0.76702953, 0.74335515, 0.61102479, 0.81599781, 0.71539953,\n",
      "       0.70669938, 0.72028046, 0.72210389, 0.69820612, 0.79881168])] \n",
      "\n",
      "mean AUC :  0.6829656899943096\n",
      "All std:  [array([0.13225754, 0.13013969, 0.11342294, 0.08719183, 0.13568073,\n",
      "       0.08852558, 0.11448274, 0.07888231, 0.13484747, 0.13588227,\n",
      "       0.07447778, 0.13780282, 0.12821989, 0.10712336, 0.08756659,\n",
      "       0.14366404, 0.1110606 , 0.09067936, 0.07557697, 0.1180853 ,\n",
      "       0.1259729 , 0.12270958, 0.12060782, 0.07222962, 0.10352383,\n",
      "       0.13203006, 0.12728713, 0.04995068, 0.09558721, 0.1477228 ,\n",
      "       0.11451685, 0.11828102, 0.11801364, 0.11962782, 0.11914369,\n",
      "       0.11688284, 0.10692519, 0.12494878, 0.10784339, 0.08771787,\n",
      "       0.12041432, 0.09431103, 0.12599324, 0.1339968 , 0.08360953,\n",
      "       0.11061872, 0.12203461, 0.11777446, 0.14037897, 0.0928779 ,\n",
      "       0.07263873, 0.06166901, 0.07818823, 0.11773484, 0.12522317,\n",
      "       0.07483812, 0.09926006, 0.12094285, 0.12208279, 0.09115799,\n",
      "       0.13397399, 0.12048299, 0.13103352, 0.0603276 , 0.14458289,\n",
      "       0.12294336, 0.12366156, 0.09913448, 0.05386659, 0.07251201,\n",
      "       0.11909987, 0.07496102, 0.119061  , 0.13006787, 0.09182557,\n",
      "       0.10037812, 0.11426088, 0.09848703, 0.0740262 , 0.14777456,\n",
      "       0.09337927, 0.1411397 , 0.13515649, 0.0964341 , 0.14241142,\n",
      "       0.14366569, 0.12570325, 0.09481048, 0.11602647, 0.1318257 ,\n",
      "       0.11173798, 0.08265358, 0.0710828 , 0.12401639, 0.09609125,\n",
      "       0.11682204, 0.09113008, 0.09013531, 0.14793144, 0.12267505,\n",
      "       0.1240778 , 0.13817203, 0.09222586, 0.11886464, 0.073254  ,\n",
      "       0.1397897 , 0.1003784 , 0.14381941, 0.13767617, 0.11636503,\n",
      "       0.12810029, 0.07524731, 0.06285028, 0.09134701, 0.12892985,\n",
      "       0.07172894, 0.0907061 , 0.11506277, 0.13671785, 0.1453787 ,\n",
      "       0.13752139, 0.09650237, 0.14500065, 0.11302093, 0.12503852,\n",
      "       0.09524325, 0.1001688 , 0.13350671, 0.10127793, 0.12458958,\n",
      "       0.13068753, 0.09273171, 0.12815054, 0.13251396, 0.10506548,\n",
      "       0.13811216, 0.09793146, 0.09096437, 0.11068697, 0.08156789,\n",
      "       0.09619623, 0.15418431, 0.12806057, 0.07290957, 0.12962335,\n",
      "       0.12575776, 0.11703691, 0.12261393, 0.1318065 , 0.10211904,\n",
      "       0.10292595, 0.08577063, 0.08494629, 0.10545605, 0.10479859,\n",
      "       0.13367055, 0.07937594, 0.08385482, 0.07636706, 0.13050518,\n",
      "       0.12878521, 0.11894465, 0.0885148 , 0.06990422, 0.09231812,\n",
      "       0.13652866, 0.11433527, 0.09073442, 0.13181932, 0.08769768,\n",
      "       0.12378709, 0.15968281, 0.13160281, 0.06117159, 0.0944624 ,\n",
      "       0.136983  , 0.09988098, 0.09799798, 0.07197535, 0.13700547,\n",
      "       0.07216301, 0.09756591, 0.09289196, 0.09079652, 0.12257775,\n",
      "       0.11241659, 0.13684388, 0.13489943, 0.15265536, 0.12413789,\n",
      "       0.084071  , 0.12166832, 0.11675207, 0.07129833, 0.12442553,\n",
      "       0.1355646 , 0.14498632, 0.13350015, 0.15445007, 0.07781664])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.1272727272727273, 'min_child_weight': 98, 'max_depth': 60, 'gamma': 1.2932828282828281, 'eta': 0.004838209664925958} \n",
      "\n",
      "Best index/iterasi :  23\n",
      "Best AUC : 0.8178292418424702 ( std: 0.07222961837145472 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 40.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 51.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  22 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.64291945, 0.63842843, 0.58539438, 0.79073014, 0.71026727,\n",
      "       0.7479071 , 0.68811833, 0.67450142, 0.68918563, 0.79895197,\n",
      "       0.7203975 , 0.72193667, 0.62821457, 0.7206776 , 0.66326727,\n",
      "       0.61884254, 0.80112957, 0.6022606 , 0.79271537, 0.73117195,\n",
      "       0.73170242, 0.8056791 , 0.80105936, 0.73939865, 0.64921129,\n",
      "       0.79799166, 0.63782029, 0.61365841, 0.5878705 , 0.72632594,\n",
      "       0.71453271, 0.72340314, 0.51972386, 0.66672469, 0.64634673,\n",
      "       0.53544662, 0.55126532, 0.71941034, 0.67638483, 0.75757771,\n",
      "       0.81628261, 0.68434594, 0.69151438, 0.52759258, 0.79974904,\n",
      "       0.68490984, 0.53694509, 0.76467884, 0.76105602, 0.61563813,\n",
      "       0.54391258, 0.72425828, 0.66758153, 0.70006296, 0.63213884,\n",
      "       0.58541983, 0.70906813, 0.75532256, 0.64256413, 0.71922361,\n",
      "       0.68828492, 0.74243104, 0.7779091 , 0.72584635, 0.7119236 ,\n",
      "       0.60120449, 0.68090853, 0.75583468, 0.62971156, 0.80641568,\n",
      "       0.76217297, 0.69026653, 0.6234606 , 0.66712704, 0.70539153,\n",
      "       0.81234482, 0.67052908, 0.73992724, 0.80730255, 0.73861917,\n",
      "       0.59873702, 0.77670569, 0.62105417, 0.75600967, 0.74805622,\n",
      "       0.77528547, 0.60846535, 0.63868795, 0.75295704, 0.60411762,\n",
      "       0.60520618, 0.57740979, 0.70770333, 0.69255651, 0.67774187,\n",
      "       0.71752753, 0.72954369, 0.75779223, 0.61717322, 0.79030656,\n",
      "       0.79270225, 0.73149695, 0.68072874, 0.73115041, 0.77571832,\n",
      "       0.78110846, 0.65980624, 0.60877446, 0.69796078, 0.65669764,\n",
      "       0.62310836, 0.78820097, 0.70512543, 0.80815261, 0.69816323,\n",
      "       0.81725395, 0.80322256, 0.51126209, 0.58497245, 0.77459263,\n",
      "       0.6771848 , 0.61262456, 0.81301909, 0.69494797, 0.76529613,\n",
      "       0.75175758, 0.75820823, 0.62146206, 0.57560858, 0.80543224,\n",
      "       0.65519263, 0.7138905 , 0.54081219, 0.68926988, 0.59264154,\n",
      "       0.66758325, 0.4999515 , 0.69539615, 0.70820868, 0.81917259,\n",
      "       0.67149586, 0.76429067, 0.72170545, 0.71839883, 0.61806423,\n",
      "       0.80934488, 0.75756033, 0.74712711, 0.66030749, 0.66040048,\n",
      "       0.64496594, 0.81627166, 0.66600568, 0.71499931, 0.60152458,\n",
      "       0.59545093, 0.63614637, 0.62943769, 0.61668909, 0.59454713,\n",
      "       0.79324958, 0.61779667, 0.75406353, 0.72340847, 0.81198848,\n",
      "       0.66462514, 0.77326528, 0.69055298, 0.7887806 , 0.7879003 ,\n",
      "       0.63113015, 0.7831005 , 0.55196259, 0.66572653, 0.76529675,\n",
      "       0.62086347, 0.68916182, 0.63549894, 0.71736784, 0.71239618,\n",
      "       0.71898175, 0.69127416, 0.67041098, 0.61345675, 0.55033879,\n",
      "       0.75636407, 0.58747086, 0.66967124, 0.7971822 , 0.71993642,\n",
      "       0.79657084, 0.53067212, 0.65143053, 0.75931472, 0.64017293,\n",
      "       0.72454517, 0.51777351, 0.72885812, 0.81251313, 0.60670574])] \n",
      "\n",
      "mean AUC :  0.6923791851116046\n",
      "All std:  [array([0.14473466, 0.0954901 , 0.0773883 , 0.05853377, 0.11406125,\n",
      "       0.10729733, 0.13915545, 0.13480363, 0.14711827, 0.07913957,\n",
      "       0.1204597 , 0.13126403, 0.12570868, 0.12401442, 0.13632862,\n",
      "       0.08829563, 0.07975336, 0.08352029, 0.08162607, 0.12515445,\n",
      "       0.12039871, 0.07506837, 0.07899767, 0.11321668, 0.10801047,\n",
      "       0.08208165, 0.13029442, 0.11810442, 0.11106839, 0.13648923,\n",
      "       0.11786311, 0.12548079, 0.06824581, 0.13617465, 0.1040824 ,\n",
      "       0.12786539, 0.0592396 , 0.12717608, 0.12672655, 0.09318516,\n",
      "       0.06866942, 0.13463278, 0.14133514, 0.08136531, 0.08104492,\n",
      "       0.1421536 , 0.10076134, 0.13126136, 0.09294422, 0.10228408,\n",
      "       0.14037254, 0.11849313, 0.12350033, 0.14032385, 0.10597579,\n",
      "       0.12546451, 0.11897329, 0.09233144, 0.13283613, 0.13244269,\n",
      "       0.14371406, 0.12288895, 0.07734764, 0.12197141, 0.13180239,\n",
      "       0.06496251, 0.12887112, 0.10281555, 0.14082731, 0.07913981,\n",
      "       0.09693811, 0.13044566, 0.10288144, 0.12595398, 0.12064322,\n",
      "       0.0704527 , 0.12502516, 0.11172033, 0.07558167, 0.11845014,\n",
      "       0.09054343, 0.10037095, 0.07668691, 0.09732173, 0.1040655 ,\n",
      "       0.08018898, 0.10906431, 0.1204654 , 0.11067723, 0.08427568,\n",
      "       0.11336233, 0.13134974, 0.12520404, 0.13490188, 0.13531298,\n",
      "       0.13389958, 0.12692199, 0.0960372 , 0.12052605, 0.08070551,\n",
      "       0.08606529, 0.12506383, 0.12225654, 0.11126621, 0.09092622,\n",
      "       0.09207602, 0.13063673, 0.12474636, 0.14851575, 0.14012936,\n",
      "       0.08024   , 0.09125306, 0.12680482, 0.07354627, 0.12354323,\n",
      "       0.07281327, 0.08026725, 0.08462626, 0.1115318 , 0.08084504,\n",
      "       0.12782569, 0.07021339, 0.07661257, 0.12543261, 0.0911746 ,\n",
      "       0.10055862, 0.10474021, 0.12377572, 0.11710082, 0.07562304,\n",
      "       0.13267187, 0.11553449, 0.11716871, 0.13435424, 0.12199158,\n",
      "       0.13336686, 0.09884534, 0.1317499 , 0.14346451, 0.06993692,\n",
      "       0.13815631, 0.12062123, 0.11189008, 0.12120059, 0.10204428,\n",
      "       0.07342828, 0.10633416, 0.1210881 , 0.11777851, 0.12134743,\n",
      "       0.10040858, 0.07145315, 0.12046862, 0.12147022, 0.08946916,\n",
      "       0.13372304, 0.1268357 , 0.10175274, 0.12809987, 0.13493875,\n",
      "       0.08088859, 0.08885345, 0.11447459, 0.11651938, 0.07180333,\n",
      "       0.124154  , 0.08732704, 0.14515413, 0.09558883, 0.07658704,\n",
      "       0.11642965, 0.09169761, 0.12820692, 0.11683226, 0.09593608,\n",
      "       0.1052297 , 0.1387956 , 0.12745427, 0.12248411, 0.1243947 ,\n",
      "       0.12394473, 0.12882704, 0.12020587, 0.10257058, 0.1410299 ,\n",
      "       0.10332963, 0.14029192, 0.12506943, 0.08186737, 0.12306572,\n",
      "       0.06587845, 0.07749195, 0.1071206 , 0.09318522, 0.12134647,\n",
      "       0.11992463, 0.09264566, 0.12246403, 0.07345486, 0.09655257])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.16363636363636364, 'min_child_weight': 95, 'max_depth': 35, 'gamma': 1.5961616161616161, 'eta': 0.047388796097176535} \n",
      "\n",
      "Best index/iterasi :  139\n",
      "Best AUC : 0.8191725914342005 ( std: 0.06993692303097096 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 40.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 52.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  32 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.71029455, 0.58691019, 0.7783862 , 0.54419935, 0.60222656,\n",
      "       0.72729336, 0.81407594, 0.54858354, 0.73249358, 0.67981754,\n",
      "       0.68758513, 0.73588617, 0.81454048, 0.75606403, 0.80828603,\n",
      "       0.51995303, 0.6086456 , 0.70948986, 0.55670404, 0.81510051,\n",
      "       0.71970075, 0.57668429, 0.73119432, 0.73264327, 0.59232439,\n",
      "       0.80803927, 0.66225077, 0.76760328, 0.77967003, 0.65528698,\n",
      "       0.56491567, 0.81385497, 0.672116  , 0.71137454, 0.69290455,\n",
      "       0.78250068, 0.73140677, 0.68116043, 0.76797652, 0.75910634,\n",
      "       0.75658324, 0.735123  , 0.77056534, 0.72833463, 0.60553416,\n",
      "       0.72722484, 0.81770281, 0.78535426, 0.778198  , 0.62277565,\n",
      "       0.79391334, 0.61726487, 0.71685485, 0.70856751, 0.72438096,\n",
      "       0.65788175, 0.56235343, 0.74422717, 0.5993135 , 0.81314349,\n",
      "       0.67610813, 0.57746585, 0.72340452, 0.63065524, 0.75898357,\n",
      "       0.5898083 , 0.76720849, 0.59108058, 0.81844283, 0.68196196,\n",
      "       0.78954557, 0.77504955, 0.75807634, 0.5558194 , 0.69885422,\n",
      "       0.81025081, 0.73794063, 0.61354997, 0.58580195, 0.72536331,\n",
      "       0.76484365, 0.57771825, 0.67902562, 0.62394103, 0.81638551,\n",
      "       0.68632533, 0.68175317, 0.67999572, 0.73298629, 0.80807969,\n",
      "       0.51717205, 0.81479932, 0.77100412, 0.56138922, 0.53062946,\n",
      "       0.699239  , 0.65145705, 0.70071858, 0.78477078, 0.59052582,\n",
      "       0.68111329, 0.64535757, 0.60073846, 0.61604875, 0.58686777,\n",
      "       0.71658122, 0.75551058, 0.69772983, 0.80760579, 0.7263549 ,\n",
      "       0.81939386, 0.55573827, 0.71792292, 0.76157555, 0.71047618,\n",
      "       0.81397364, 0.537435  , 0.64410448, 0.62750693, 0.64518306,\n",
      "       0.72097617, 0.60540441, 0.5940151 , 0.56311692, 0.67478173,\n",
      "       0.55060677, 0.61196145, 0.66405397, 0.55480142, 0.61560988,\n",
      "       0.68942321, 0.74748491, 0.78574106, 0.77555216, 0.68707976,\n",
      "       0.78298612, 0.68136755, 0.66103371, 0.78093199, 0.79243504,\n",
      "       0.81119756, 0.65631692, 0.57616242, 0.55175851, 0.72691137,\n",
      "       0.74049624, 0.56008388, 0.77878547, 0.55839136, 0.62712557,\n",
      "       0.63665016, 0.81753741, 0.71000125, 0.81917286, 0.50736293,\n",
      "       0.81379184, 0.69387144, 0.57938011, 0.58409709, 0.55474356,\n",
      "       0.57614156, 0.67064058, 0.68929732, 0.70083349, 0.7487017 ,\n",
      "       0.61086531, 0.79039106, 0.75311865, 0.68805144, 0.723522  ,\n",
      "       0.72521975, 0.55439399, 0.81171866, 0.54522744, 0.71097297,\n",
      "       0.49767669, 0.59658409, 0.71967279, 0.69635471, 0.57609205,\n",
      "       0.69504575, 0.79137297, 0.7491167 , 0.67502077, 0.75767451,\n",
      "       0.57148342, 0.68365113, 0.77491724, 0.66841509, 0.72248027,\n",
      "       0.82219687, 0.53789088, 0.57577555, 0.65194962, 0.80984439,\n",
      "       0.8136525 , 0.80389778, 0.8105778 , 0.68171641, 0.8188329 ])] \n",
      "\n",
      "mean AUC :  0.6902704263863515\n",
      "All std:  [array([0.12866554, 0.08627828, 0.09643715, 0.07805562, 0.12106823,\n",
      "       0.1274908 , 0.07152387, 0.04241659, 0.13003053, 0.12211978,\n",
      "       0.13851712, 0.11872437, 0.07273376, 0.11651138, 0.07203052,\n",
      "       0.0925816 , 0.10773556, 0.12135177, 0.11343827, 0.07328801,\n",
      "       0.12124911, 0.11238432, 0.12901851, 0.12652742, 0.12392942,\n",
      "       0.07483405, 0.12379218, 0.08096929, 0.09149582, 0.12598288,\n",
      "       0.05411358, 0.07088147, 0.12479881, 0.13797551, 0.12711106,\n",
      "       0.09095394, 0.12421929, 0.13404259, 0.08666054, 0.09845528,\n",
      "       0.09056085, 0.1247259 , 0.08298222, 0.11527353, 0.12316608,\n",
      "       0.12038265, 0.0717306 , 0.07849369, 0.07633395, 0.12113738,\n",
      "       0.08458552, 0.1164073 , 0.13400728, 0.12350421, 0.12211102,\n",
      "       0.11988027, 0.05815088, 0.10865871, 0.11139962, 0.07210632,\n",
      "       0.125915  , 0.10901855, 0.13049201, 0.09746591, 0.08870295,\n",
      "       0.09535925, 0.10687902, 0.07246463, 0.06827211, 0.13067828,\n",
      "       0.076402  , 0.08326608, 0.10146815, 0.09936598, 0.15098451,\n",
      "       0.0727045 , 0.11453807, 0.10816746, 0.08580377, 0.12760699,\n",
      "       0.12237263, 0.1065799 , 0.12658369, 0.0982944 , 0.07431881,\n",
      "       0.12897866, 0.12170408, 0.12229939, 0.09314037, 0.07867794,\n",
      "       0.08935532, 0.07344468, 0.09205558, 0.08140497, 0.05379344,\n",
      "       0.14521026, 0.1222391 , 0.13713951, 0.08146947, 0.12138297,\n",
      "       0.13789906, 0.11459534, 0.13071846, 0.13433588, 0.07994039,\n",
      "       0.13112072, 0.10375653, 0.11620617, 0.07391558, 0.14064391,\n",
      "       0.07208957, 0.10406377, 0.1189442 , 0.09298561, 0.13048321,\n",
      "       0.07200024, 0.115171  , 0.11688209, 0.12207465, 0.10269738,\n",
      "       0.12513914, 0.12976572, 0.09400723, 0.10456761, 0.12158574,\n",
      "       0.07294012, 0.12740301, 0.12302019, 0.12533121, 0.09502604,\n",
      "       0.14489866, 0.12247467, 0.10408468, 0.08750289, 0.12461361,\n",
      "       0.08597025, 0.14556765, 0.1252119 , 0.10586997, 0.08233484,\n",
      "       0.07894564, 0.11995915, 0.07079198, 0.12746235, 0.13025082,\n",
      "       0.11543187, 0.0737419 , 0.098731  , 0.12114221, 0.12884983,\n",
      "       0.08755362, 0.0695919 , 0.1139352 , 0.06751964, 0.07531603,\n",
      "       0.07259957, 0.134432  , 0.07818569, 0.12028955, 0.10205612,\n",
      "       0.10903084, 0.10838384, 0.12761226, 0.15664195, 0.11671943,\n",
      "       0.06904102, 0.08208373, 0.1107903 , 0.14246409, 0.12672934,\n",
      "       0.1317868 , 0.1195663 , 0.06879676, 0.0413341 , 0.11941782,\n",
      "       0.11414685, 0.08804357, 0.12306372, 0.11683421, 0.11173134,\n",
      "       0.14939973, 0.07989008, 0.10784018, 0.12583732, 0.09262934,\n",
      "       0.13434775, 0.12799825, 0.08946499, 0.1248918 , 0.13339862,\n",
      "       0.07382916, 0.0742524 , 0.09221845, 0.13246127, 0.07521391,\n",
      "       0.07214005, 0.07026982, 0.07107249, 0.12955527, 0.07017597])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.1090909090909091, 'min_child_weight': 88, 'max_depth': 20, 'gamma': 0.34426262626262627, 'eta': 0.014933932161242525} \n",
      "\n",
      "Best index/iterasi :  190\n",
      "Best AUC : 0.8221968657852461 ( std: 0.07382915852865032 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 43.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 54.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  42 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.75636778, 0.5256115 , 0.64632987, 0.53317301, 0.67781337,\n",
      "       0.72693585, 0.49317788, 0.8168664 , 0.72434114, 0.68249712,\n",
      "       0.80837922, 0.67175024, 0.5322994 , 0.6769362 , 0.68564408,\n",
      "       0.74018414, 0.68900483, 0.67493717, 0.64472805, 0.81514885,\n",
      "       0.6281311 , 0.60654579, 0.69672879, 0.81184783, 0.69379475,\n",
      "       0.75119038, 0.63173722, 0.69873323, 0.71973697, 0.68471374,\n",
      "       0.71923169, 0.68644061, 0.80631725, 0.81337019, 0.68160696,\n",
      "       0.80271798, 0.69009808, 0.57293061, 0.68759395, 0.56247752,\n",
      "       0.48984659, 0.58159009, 0.63246829, 0.79737159, 0.65216995,\n",
      "       0.61207598, 0.5709524 , 0.6807826 , 0.69302122, 0.74089423,\n",
      "       0.75313498, 0.76187489, 0.71169011, 0.64153365, 0.68001498,\n",
      "       0.68530621, 0.61336324, 0.75496159, 0.67758831, 0.59934476,\n",
      "       0.63587952, 0.72366385, 0.64719258, 0.59805769, 0.7798975 ,\n",
      "       0.69451972, 0.7217417 , 0.62340222, 0.71291209, 0.69664267,\n",
      "       0.80775848, 0.647419  , 0.72669937, 0.61772055, 0.7628976 ,\n",
      "       0.75623447, 0.51935016, 0.53145822, 0.7140369 , 0.81087596,\n",
      "       0.66831561, 0.55566503, 0.70573396, 0.62143039, 0.65891526,\n",
      "       0.7125107 , 0.64539578, 0.81597636, 0.81555283, 0.64633813,\n",
      "       0.81072242, 0.75857819, 0.64254658, 0.74880062, 0.63627699,\n",
      "       0.6171068 , 0.53371031, 0.67589391, 0.51376188, 0.81243696,\n",
      "       0.79985436, 0.70318632, 0.52176499, 0.55021034, 0.66059293,\n",
      "       0.65418059, 0.57159441, 0.62840047, 0.69790133, 0.58297311,\n",
      "       0.77316765, 0.72939639, 0.73400998, 0.59586679, 0.71068569,\n",
      "       0.63348208, 0.72190743, 0.70719174, 0.76092024, 0.70019002,\n",
      "       0.66248955, 0.79686305, 0.72090715, 0.63653317, 0.55448634,\n",
      "       0.64750418, 0.74596468, 0.5818734 , 0.80792062, 0.62195083,\n",
      "       0.59198296, 0.62800602, 0.66695674, 0.76966605, 0.6499094 ,\n",
      "       0.62475322, 0.81556599, 0.81505169, 0.75985063, 0.66092002,\n",
      "       0.81681535, 0.54590499, 0.75466426, 0.78294073, 0.80894591,\n",
      "       0.80945002, 0.7530578 , 0.82466014, 0.69820034, 0.69050773,\n",
      "       0.63571414, 0.7096289 , 0.69604768, 0.50252497, 0.5950767 ,\n",
      "       0.71453054, 0.64813847, 0.77134187, 0.61068003, 0.74743188,\n",
      "       0.64718569, 0.70786076, 0.68021812, 0.72783866, 0.52938383,\n",
      "       0.78687262, 0.71477989, 0.65172558, 0.7608745 , 0.58497734,\n",
      "       0.62037714, 0.59409971, 0.70634779, 0.72658628, 0.53729863,\n",
      "       0.54162479, 0.67411741, 0.81510809, 0.59385192, 0.62304927,\n",
      "       0.71447197, 0.59781861, 0.62938819, 0.72682462, 0.51779801,\n",
      "       0.64857206, 0.71968608, 0.68506981, 0.53725685, 0.80710275,\n",
      "       0.63200513, 0.77314907, 0.80982143, 0.77182395, 0.74683071,\n",
      "       0.62396998, 0.76918976, 0.61459514, 0.55878837, 0.5923492 ])] \n",
      "\n",
      "mean AUC :  0.6806783500808143\n",
      "All std:  [array([0.09395774, 0.03455529, 0.10905123, 0.0984042 , 0.14427807,\n",
      "       0.11816657, 0.08763275, 0.07588345, 0.13067958, 0.13447381,\n",
      "       0.06376277, 0.10772558, 0.10071581, 0.13055607, 0.1197374 ,\n",
      "       0.11200513, 0.12696257, 0.1300327 , 0.1298    , 0.07276595,\n",
      "       0.11935206, 0.12177342, 0.14624087, 0.07118338, 0.12176097,\n",
      "       0.11066847, 0.12345096, 0.12643782, 0.11732587, 0.13733105,\n",
      "       0.12400057, 0.13454506, 0.0701285 , 0.0734742 , 0.13705245,\n",
      "       0.07569939, 0.14339383, 0.12647293, 0.14821097, 0.0553491 ,\n",
      "       0.07387642, 0.0710547 , 0.12633744, 0.07741678, 0.12863068,\n",
      "       0.10646089, 0.12615959, 0.13821221, 0.12920313, 0.11212896,\n",
      "       0.099664  , 0.13196243, 0.12710039, 0.1345093 , 0.12051411,\n",
      "       0.14078715, 0.09314871, 0.09932987, 0.14182888, 0.10161231,\n",
      "       0.12334801, 0.12815509, 0.13135328, 0.1405634 , 0.07852803,\n",
      "       0.14242535, 0.14230965, 0.09693074, 0.12534165, 0.13025304,\n",
      "       0.07837758, 0.12138513, 0.11825506, 0.08822019, 0.11423295,\n",
      "       0.09472929, 0.09379993, 0.11847117, 0.136196  , 0.07485307,\n",
      "       0.12034888, 0.11558802, 0.11438232, 0.08380104, 0.11861842,\n",
      "       0.13042512, 0.09914459, 0.07163222, 0.07293252, 0.1306699 ,\n",
      "       0.07631648, 0.08880162, 0.11193667, 0.10391063, 0.09217741,\n",
      "       0.11950093, 0.05284523, 0.13282966, 0.10283107, 0.07035935,\n",
      "       0.08394749, 0.12673744, 0.08842352, 0.09444666, 0.13055947,\n",
      "       0.1574922 , 0.09014863, 0.1280123 , 0.14296172, 0.11269554,\n",
      "       0.09166657, 0.12667575, 0.10712177, 0.09078842, 0.13051108,\n",
      "       0.08265504, 0.13011074, 0.1279202 , 0.09603233, 0.13169214,\n",
      "       0.1194747 , 0.07460532, 0.14160662, 0.13384099, 0.11454266,\n",
      "       0.10499771, 0.11287834, 0.1140313 , 0.0678114 , 0.1162337 ,\n",
      "       0.09703509, 0.13095806, 0.11849498, 0.08291864, 0.12537402,\n",
      "       0.08255858, 0.07647717, 0.07178284, 0.08646687, 0.12606177,\n",
      "       0.07341004, 0.04625136, 0.10035393, 0.07733563, 0.06595365,\n",
      "       0.0739029 , 0.10239676, 0.06423005, 0.13536529, 0.11210165,\n",
      "       0.11053289, 0.11389799, 0.14328535, 0.10727889, 0.12367548,\n",
      "       0.13124258, 0.13033113, 0.08030764, 0.06985181, 0.09255793,\n",
      "       0.11716504, 0.12954703, 0.12688143, 0.13562141, 0.09855783,\n",
      "       0.08338004, 0.12105063, 0.12818742, 0.09169614, 0.095832  ,\n",
      "       0.11545908, 0.12358037, 0.11643868, 0.11977547, 0.08585281,\n",
      "       0.10869457, 0.12359973, 0.07562895, 0.13079645, 0.13050811,\n",
      "       0.12894754, 0.11608294, 0.09340348, 0.12311888, 0.06624926,\n",
      "       0.10759949, 0.13300273, 0.12859573, 0.12348772, 0.06814261,\n",
      "       0.09338621, 0.09910061, 0.07486978, 0.09446526, 0.11712432,\n",
      "       0.12041504, 0.09334108, 0.11284028, 0.12269604, 0.13917434])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.1090909090909091, 'min_child_weight': 65, 'max_depth': 97, 'gamma': 0.4856060606060606, 'eta': 0.19966424501097935} \n",
      "\n",
      "Best index/iterasi :  147\n",
      "Best AUC : 0.8246601354220109 ( std: 0.06423005043994298 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 41.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 53.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  52 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.61648198, 0.78204692, 0.81313498, 0.81173167, 0.77300928,\n",
      "       0.81308552, 0.60413224, 0.57065265, 0.67594623, 0.56510228,\n",
      "       0.68283732, 0.67558723, 0.55019916, 0.56658461, 0.71453011,\n",
      "       0.67379398, 0.62842588, 0.6489546 , 0.79703037, 0.61585037,\n",
      "       0.4815217 , 0.67725894, 0.75167979, 0.60034248, 0.53334266,\n",
      "       0.48456662, 0.67314194, 0.74691292, 0.70473857, 0.76669426,\n",
      "       0.65194642, 0.70047239, 0.68288303, 0.72536547, 0.72483661,\n",
      "       0.76533574, 0.61943074, 0.75391398, 0.7558675 , 0.81032375,\n",
      "       0.70196862, 0.72424629, 0.72318607, 0.74579427, 0.69344948,\n",
      "       0.82183287, 0.55536804, 0.72528679, 0.58886505, 0.61589818,\n",
      "       0.54701473, 0.69481331, 0.76384853, 0.61862115, 0.67953366,\n",
      "       0.77416015, 0.82290597, 0.65097267, 0.56092178, 0.64295412,\n",
      "       0.64296207, 0.57592512, 0.62297687, 0.55702549, 0.58722422,\n",
      "       0.59231669, 0.7848145 , 0.82564104, 0.60512437, 0.75390228,\n",
      "       0.67989322, 0.71802594, 0.57376687, 0.66205389, 0.75740012,\n",
      "       0.69763296, 0.70735708, 0.73704394, 0.715801  , 0.6995498 ,\n",
      "       0.64230452, 0.6783396 , 0.63877426, 0.68053991, 0.81364424,\n",
      "       0.81107991, 0.6136972 , 0.51817894, 0.80171916, 0.65376682,\n",
      "       0.76227291, 0.73195315, 0.63282044, 0.5767423 , 0.68522121,\n",
      "       0.60388147, 0.75553849, 0.70360222, 0.8068793 , 0.57850832,\n",
      "       0.68433923, 0.81635515, 0.74822429, 0.64132858, 0.75741924,\n",
      "       0.60980991, 0.79972151, 0.70826418, 0.80752982, 0.69866819,\n",
      "       0.48921528, 0.5626611 , 0.65130736, 0.71508481, 0.80197693,\n",
      "       0.68410306, 0.79482117, 0.81723074, 0.55074671, 0.78087572,\n",
      "       0.70570847, 0.70642761, 0.76289063, 0.80966759, 0.64943842,\n",
      "       0.82138297, 0.79126895, 0.55271983, 0.66951018, 0.63575157,\n",
      "       0.69698407, 0.72248232, 0.6172117 , 0.66279075, 0.70952722,\n",
      "       0.55932848, 0.60425928, 0.60463798, 0.78834915, 0.67038934,\n",
      "       0.79814089, 0.72619323, 0.78821424, 0.63269069, 0.75640838,\n",
      "       0.61742133, 0.56615467, 0.7225944 , 0.67686988, 0.50599609,\n",
      "       0.63124658, 0.54463135, 0.76623867, 0.66235834, 0.81301629,\n",
      "       0.50808535, 0.70810347, 0.62260347, 0.80169184, 0.70989731,\n",
      "       0.55512715, 0.77575169, 0.6487452 , 0.61997943, 0.54927124,\n",
      "       0.63967416, 0.78352158, 0.67845985, 0.5657043 , 0.53193802,\n",
      "       0.55706105, 0.59994533, 0.80315388, 0.64215629, 0.72258482,\n",
      "       0.64417294, 0.66917392, 0.54591224, 0.58534231, 0.73000416,\n",
      "       0.68048245, 0.57743322, 0.7872554 , 0.60533508, 0.53053135,\n",
      "       0.67819968, 0.73907644, 0.7046091 , 0.76522761, 0.62610226,\n",
      "       0.73132578, 0.76266939, 0.56393434, 0.65215194, 0.60560356,\n",
      "       0.51787391, 0.76672294, 0.81289049, 0.80642513, 0.78398854])] \n",
      "\n",
      "mean AUC :  0.6799586030002963\n",
      "All std:  [array([0.12169367, 0.09568369, 0.07384903, 0.07383258, 0.08144822,\n",
      "       0.07783266, 0.0933765 , 0.084505  , 0.11768944, 0.12065534,\n",
      "       0.13070637, 0.12561123, 0.11294909, 0.08937045, 0.11844564,\n",
      "       0.13389666, 0.08283007, 0.10865203, 0.07432901, 0.10058229,\n",
      "       0.09191642, 0.12408582, 0.09576316, 0.1221996 , 0.08134584,\n",
      "       0.07243733, 0.11823588, 0.08107567, 0.12046519, 0.08722114,\n",
      "       0.12362953, 0.11045068, 0.14083885, 0.11645542, 0.1374338 ,\n",
      "       0.10002362, 0.07929555, 0.10071446, 0.12773357, 0.07489294,\n",
      "       0.12195937, 0.12004257, 0.12369829, 0.12439056, 0.14994735,\n",
      "       0.06330585, 0.11878237, 0.13038419, 0.10737994, 0.10891615,\n",
      "       0.07716094, 0.1420942 , 0.09385921, 0.13690845, 0.13109074,\n",
      "       0.08239375, 0.06172288, 0.12971724, 0.04909308, 0.11419469,\n",
      "       0.13820642, 0.15735054, 0.08304426, 0.05879024, 0.11930192,\n",
      "       0.12114212, 0.08676729, 0.06132769, 0.12276141, 0.11989476,\n",
      "       0.13166972, 0.12893224, 0.12179536, 0.11712285, 0.08952477,\n",
      "       0.12773535, 0.1245272 , 0.10665769, 0.12530652, 0.1508778 ,\n",
      "       0.09820331, 0.1320462 , 0.12384319, 0.13406401, 0.07608749,\n",
      "       0.06827902, 0.12613924, 0.0816311 , 0.0714329 , 0.12604128,\n",
      "       0.09439385, 0.12099291, 0.10400693, 0.11611927, 0.13025174,\n",
      "       0.07448385, 0.10543096, 0.13059636, 0.07502888, 0.09443473,\n",
      "       0.1412915 , 0.07257932, 0.11797501, 0.12474934, 0.09357892,\n",
      "       0.10686531, 0.08498421, 0.14347042, 0.07629699, 0.14140651,\n",
      "       0.09435643, 0.10389744, 0.12408601, 0.1378567 , 0.07983348,\n",
      "       0.12448372, 0.07531994, 0.06959295, 0.11542782, 0.04796639,\n",
      "       0.12341645, 0.11423534, 0.09078267, 0.08100057, 0.11612045,\n",
      "       0.06561339, 0.08821939, 0.05849239, 0.12353412, 0.12244354,\n",
      "       0.13918058, 0.12467   , 0.0870133 , 0.10759624, 0.12738513,\n",
      "       0.06864666, 0.14065112, 0.13914974, 0.08658192, 0.11625319,\n",
      "       0.07701828, 0.11771163, 0.09771699, 0.13494969, 0.08941723,\n",
      "       0.11374001, 0.11374234, 0.12629308, 0.12551223, 0.08050032,\n",
      "       0.08636814, 0.12785715, 0.10245564, 0.11128895, 0.06916694,\n",
      "       0.09289943, 0.10572887, 0.10077285, 0.07499929, 0.11289727,\n",
      "       0.09992381, 0.10005985, 0.12663726, 0.11287056, 0.06952346,\n",
      "       0.12402199, 0.08765406, 0.12335273, 0.09080727, 0.03627333,\n",
      "       0.12675901, 0.07195093, 0.06809852, 0.09339063, 0.12044336,\n",
      "       0.12962749, 0.13310281, 0.12310463, 0.12183964, 0.11585721,\n",
      "       0.14167858, 0.10150855, 0.07976596, 0.12438882, 0.10815733,\n",
      "       0.13638462, 0.11494002, 0.12858641, 0.08861841, 0.13853443,\n",
      "       0.12989425, 0.08959945, 0.11912314, 0.11794386, 0.11279089,\n",
      "       0.07457015, 0.10678746, 0.0710565 , 0.07362708, 0.08481259])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.14545454545454545, 'min_child_weight': 97, 'max_depth': 94, 'gamma': 1.4144343434343434, 'eta': 0.08529644499741021} \n",
      "\n",
      "Best index/iterasi :  67\n",
      "Best AUC : 0.8256410362023278 ( std: 0.061327688616697434 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 43.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 57.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  62 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.62957742, 0.60411847, 0.76568639, 0.67469898, 0.80240781,\n",
      "       0.56999574, 0.56887787, 0.68103862, 0.48746804, 0.75747651,\n",
      "       0.79890258, 0.72660879, 0.72528944, 0.67030672, 0.75737018,\n",
      "       0.75872132, 0.68219713, 0.8172953 , 0.75329647, 0.56851031,\n",
      "       0.59197322, 0.62917898, 0.76153799, 0.69328344, 0.69677729,\n",
      "       0.62268288, 0.76269474, 0.57363941, 0.80163689, 0.51098779,\n",
      "       0.75664371, 0.53446069, 0.78093534, 0.51066974, 0.71053452,\n",
      "       0.72430706, 0.50746792, 0.81603832, 0.61561854, 0.68392611,\n",
      "       0.65393498, 0.63712524, 0.73495649, 0.66834595, 0.75865126,\n",
      "       0.70311245, 0.65911425, 0.76177795, 0.58518243, 0.58526647,\n",
      "       0.77912432, 0.60138099, 0.72730231, 0.71166003, 0.7076221 ,\n",
      "       0.70160513, 0.66603263, 0.6755692 , 0.53363144, 0.54628177,\n",
      "       0.69867518, 0.62650322, 0.71280709, 0.652946  , 0.80533548,\n",
      "       0.61479629, 0.72601208, 0.69562518, 0.75731897, 0.53287762,\n",
      "       0.76767672, 0.81224707, 0.67472256, 0.67235922, 0.75730787,\n",
      "       0.66806269, 0.64857228, 0.71247249, 0.74830176, 0.71293332,\n",
      "       0.49633819, 0.72404417, 0.71387834, 0.58067765, 0.60158347,\n",
      "       0.61654154, 0.56318475, 0.59950061, 0.66076253, 0.71640231,\n",
      "       0.71817711, 0.72351986, 0.6592175 , 0.60433322, 0.62740852,\n",
      "       0.68453307, 0.67103289, 0.70532205, 0.72393929, 0.54163121,\n",
      "       0.63407675, 0.72755812, 0.69994507, 0.79019243, 0.55212144,\n",
      "       0.53331127, 0.80816427, 0.62591607, 0.61340576, 0.75752032,\n",
      "       0.70313714, 0.52972705, 0.71579786, 0.80581028, 0.81568532,\n",
      "       0.81997288, 0.78830409, 0.73049694, 0.61627478, 0.75999529,\n",
      "       0.5828118 , 0.54572549, 0.80108689, 0.74631769, 0.67702804,\n",
      "       0.76854348, 0.81889038, 0.68208285, 0.72312334, 0.75659756,\n",
      "       0.67858393, 0.62605526, 0.80282287, 0.58249692, 0.64915267,\n",
      "       0.70725894, 0.79856845, 0.70570763, 0.8099437 , 0.5232493 ,\n",
      "       0.81783181, 0.65545759, 0.6060275 , 0.72065854, 0.66222844,\n",
      "       0.57566657, 0.5482456 , 0.6587793 , 0.74825585, 0.71315568,\n",
      "       0.49368544, 0.81394843, 0.70769011, 0.70976209, 0.66030755,\n",
      "       0.71945819, 0.4848721 , 0.6888539 , 0.5745894 , 0.6859426 ,\n",
      "       0.56392914, 0.6355341 , 0.52221684, 0.51464561, 0.76657018,\n",
      "       0.70627947, 0.63108505, 0.64021485, 0.52777967, 0.75588153,\n",
      "       0.70794506, 0.5441654 , 0.54279233, 0.72023972, 0.68268281,\n",
      "       0.5939442 , 0.65476379, 0.81504396, 0.63533627, 0.4995757 ,\n",
      "       0.81228957, 0.65142083, 0.76762278, 0.81433256, 0.62758616,\n",
      "       0.66037908, 0.71895371, 0.81451018, 0.81450358, 0.67090607,\n",
      "       0.74331872, 0.57145762, 0.66473246, 0.57737996, 0.56070956,\n",
      "       0.74733284, 0.48828982, 0.59626579, 0.67178961, 0.81317051])] \n",
      "\n",
      "mean AUC :  0.6755927578277959\n",
      "All std:  [array([0.11318397, 0.1153072 , 0.09165157, 0.12025955, 0.06851273,\n",
      "       0.07886945, 0.12366995, 0.12540416, 0.09107729, 0.098611  ,\n",
      "       0.08165192, 0.13024434, 0.12955923, 0.12614708, 0.10487261,\n",
      "       0.0984606 , 0.13189438, 0.07462464, 0.11034938, 0.13471657,\n",
      "       0.06333877, 0.08900207, 0.09557958, 0.12872639, 0.15129402,\n",
      "       0.12369726, 0.11010438, 0.12279609, 0.06821376, 0.07734324,\n",
      "       0.10461092, 0.08302466, 0.07736495, 0.0891163 , 0.1299264 ,\n",
      "       0.13131602, 0.07879334, 0.07036137, 0.12814101, 0.1342271 ,\n",
      "       0.13604942, 0.13678526, 0.13105017, 0.11921576, 0.09929537,\n",
      "       0.14712609, 0.12137007, 0.0943939 , 0.11224654, 0.06714263,\n",
      "       0.08653066, 0.15031153, 0.13330063, 0.11455862, 0.13439714,\n",
      "       0.14550849, 0.12399528, 0.13516166, 0.10731232, 0.11492878,\n",
      "       0.13179231, 0.08311189, 0.13390882, 0.12743244, 0.07780004,\n",
      "       0.09225721, 0.11710104, 0.13967223, 0.10030506, 0.08912883,\n",
      "       0.10120254, 0.07480745, 0.12492459, 0.12574413, 0.10196146,\n",
      "       0.12633836, 0.11632174, 0.1416721 , 0.11980845, 0.12607883,\n",
      "       0.08935647, 0.12880536, 0.13238026, 0.05432609, 0.13718053,\n",
      "       0.1247123 , 0.12617771, 0.07281592, 0.1461752 , 0.13388688,\n",
      "       0.12517763, 0.12158153, 0.12253681, 0.12820539, 0.08508277,\n",
      "       0.12824916, 0.11878258, 0.11877407, 0.12837554, 0.12791004,\n",
      "       0.12393587, 0.12797735, 0.15385624, 0.0791143 , 0.08590174,\n",
      "       0.08320698, 0.07380344, 0.1115793 , 0.11439192, 0.10712396,\n",
      "       0.12419299, 0.08223307, 0.1305003 , 0.07248608, 0.07349513,\n",
      "       0.0705215 , 0.09005583, 0.12483642, 0.12497483, 0.09842167,\n",
      "       0.11248361, 0.10101091, 0.08030079, 0.08743435, 0.13035358,\n",
      "       0.08631032, 0.06351107, 0.1358726 , 0.13173838, 0.11564231,\n",
      "       0.12438005, 0.11923779, 0.0775635 , 0.11761475, 0.13366165,\n",
      "       0.11417636, 0.07873826, 0.12142023, 0.07020896, 0.10518217,\n",
      "       0.07019309, 0.11113821, 0.14148885, 0.135464  , 0.13208967,\n",
      "       0.11197582, 0.11375827, 0.11521036, 0.12152351, 0.13687689,\n",
      "       0.08492237, 0.07433245, 0.12946973, 0.11472301, 0.12063976,\n",
      "       0.11201887, 0.0556505 , 0.1350445 , 0.11728426, 0.12844852,\n",
      "       0.10217831, 0.10493836, 0.06247496, 0.09902703, 0.0982876 ,\n",
      "       0.13360154, 0.09377346, 0.09738794, 0.03859823, 0.11600928,\n",
      "       0.12653616, 0.10392595, 0.06383983, 0.13163185, 0.13552173,\n",
      "       0.0585397 , 0.10788461, 0.07068799, 0.12281232, 0.06988247,\n",
      "       0.07262059, 0.11134951, 0.08686526, 0.07266374, 0.08722098,\n",
      "       0.1247506 , 0.12378971, 0.07140941, 0.0746739 , 0.12662465,\n",
      "       0.11475477, 0.13542704, 0.12357148, 0.1196224 , 0.12060746,\n",
      "       0.11715515, 0.08358256, 0.12196224, 0.1381924 , 0.07212336])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.1, 'min_child_weight': 71, 'max_depth': 78, 'gamma': 1.2528989898989897, 'eta': 0.013556017853293682} \n",
      "\n",
      "Best index/iterasi :  115\n",
      "Best AUC : 0.819972883193207 ( std: 0.07052149856282482 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 50.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  72 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.50501672, 0.81096942, 0.73341085, 0.80149083, 0.70339821,\n",
      "       0.7023771 , 0.62087928, 0.66224302, 0.74607229, 0.6984814 ,\n",
      "       0.79620231, 0.50392334, 0.80805388, 0.66182938, 0.64830104,\n",
      "       0.73040447, 0.81341193, 0.62014865, 0.73640502, 0.81847315,\n",
      "       0.656284  , 0.65945767, 0.69593218, 0.6886031 , 0.61280767,\n",
      "       0.73931637, 0.72516022, 0.70347515, 0.72377236, 0.69215692,\n",
      "       0.62090824, 0.54874412, 0.81773535, 0.6875873 , 0.61298872,\n",
      "       0.72158298, 0.81675712, 0.73766467, 0.80241728, 0.51972405,\n",
      "       0.68429237, 0.77484006, 0.7208256 , 0.76797288, 0.61657011,\n",
      "       0.52895066, 0.68095462, 0.81336124, 0.72902319, 0.53815591,\n",
      "       0.62227033, 0.67451288, 0.59020104, 0.603486  , 0.73129619,\n",
      "       0.74324838, 0.58355748, 0.64621957, 0.73161425, 0.71938479,\n",
      "       0.81516762, 0.72735287, 0.7533393 , 0.66643358, 0.52789702,\n",
      "       0.58866287, 0.69539095, 0.70748484, 0.59325488, 0.71413574,\n",
      "       0.69717648, 0.80555599, 0.65245468, 0.67634868, 0.81956575,\n",
      "       0.69790776, 0.75334897, 0.7731288 , 0.77366482, 0.7643849 ,\n",
      "       0.68014278, 0.76189059, 0.61598279, 0.75855281, 0.5979686 ,\n",
      "       0.64383843, 0.61072944, 0.66349405, 0.78486689, 0.68041597,\n",
      "       0.76524287, 0.69254578, 0.79048525, 0.6388959 , 0.8170892 ,\n",
      "       0.75534183, 0.57983745, 0.47039951, 0.82456444, 0.78286097,\n",
      "       0.75830458, 0.60274319, 0.66967176, 0.70229349, 0.80729375,\n",
      "       0.60823491, 0.70938658, 0.71952781, 0.73549969, 0.82221933,\n",
      "       0.56809321, 0.79491445, 0.66682422, 0.81765888, 0.55998017,\n",
      "       0.76797821, 0.68677613, 0.61663945, 0.75128443, 0.58157591,\n",
      "       0.81736781, 0.7296241 , 0.61656682, 0.81019157, 0.7360908 ,\n",
      "       0.72643971, 0.5873156 , 0.60550553, 0.79146624, 0.77390683,\n",
      "       0.54786286, 0.81142748, 0.55206587, 0.71651688, 0.63901851,\n",
      "       0.66937667, 0.65509218, 0.73817692, 0.5971238 , 0.63094868,\n",
      "       0.68239971, 0.69100654, 0.71353371, 0.6808798 , 0.67455985,\n",
      "       0.61924806, 0.76517211, 0.71985389, 0.68904771, 0.81953636,\n",
      "       0.74465675, 0.61713083, 0.72648471, 0.62754528, 0.66867192,\n",
      "       0.76095604, 0.61180717, 0.47099118, 0.72200905, 0.72500746,\n",
      "       0.60596495, 0.71251554, 0.73970527, 0.62843963, 0.57911742,\n",
      "       0.69031308, 0.75952818, 0.67171735, 0.70798829, 0.54914219,\n",
      "       0.75860307, 0.65121755, 0.69158043, 0.54580706, 0.69213362,\n",
      "       0.64846297, 0.80485552, 0.73360978, 0.81426346, 0.68654085,\n",
      "       0.78268479, 0.62890225, 0.80913678, 0.79464936, 0.6594879 ,\n",
      "       0.57427409, 0.81245699, 0.81296238, 0.55836404, 0.81573174,\n",
      "       0.72230682, 0.66097733, 0.57265577, 0.63836131, 0.81548585,\n",
      "       0.57302717, 0.57806646, 0.52333279, 0.57771556, 0.81112998])] \n",
      "\n",
      "mean AUC :  0.6917290302789243\n",
      "All std:  [array([0.07346338, 0.07384755, 0.1309708 , 0.07484179, 0.11744956,\n",
      "       0.13997504, 0.12697245, 0.11349857, 0.10686292, 0.12769393,\n",
      "       0.08101469, 0.09119777, 0.07246835, 0.13059349, 0.13468592,\n",
      "       0.12397606, 0.06216994, 0.09497054, 0.120586  , 0.06984987,\n",
      "       0.11936764, 0.13158612, 0.14757177, 0.13176334, 0.118365  ,\n",
      "       0.10592116, 0.13022983, 0.13048967, 0.1226794 , 0.14546836,\n",
      "       0.08296401, 0.05309319, 0.07023027, 0.12775692, 0.1134778 ,\n",
      "       0.10872572, 0.07108761, 0.13946576, 0.07174092, 0.09996918,\n",
      "       0.13944068, 0.09602915, 0.13338162, 0.11099609, 0.06898283,\n",
      "       0.05300909, 0.1329902 , 0.07429091, 0.11438699, 0.0705444 ,\n",
      "       0.08358304, 0.13793336, 0.09961848, 0.09734082, 0.11610075,\n",
      "       0.12051331, 0.07664678, 0.13312782, 0.11733606, 0.12936431,\n",
      "       0.07590952, 0.11807751, 0.12221566, 0.12618291, 0.06202866,\n",
      "       0.07686157, 0.14816321, 0.1450448 , 0.10699648, 0.12425144,\n",
      "       0.15160034, 0.07211905, 0.12199883, 0.13291709, 0.07024854,\n",
      "       0.14815537, 0.10436719, 0.08153586, 0.08604584, 0.0933758 ,\n",
      "       0.12479245, 0.08657188, 0.13612083, 0.10278151, 0.12019875,\n",
      "       0.13499383, 0.11928549, 0.12817025, 0.09364408, 0.12776377,\n",
      "       0.08526212, 0.14282953, 0.08350134, 0.13111847, 0.07581381,\n",
      "       0.10035266, 0.12375283, 0.09685637, 0.06807235, 0.0772174 ,\n",
      "       0.12640101, 0.1135256 , 0.11391988, 0.12708518, 0.07652786,\n",
      "       0.10787525, 0.12701932, 0.1238731 , 0.10832646, 0.06198129,\n",
      "       0.0605765 , 0.07983845, 0.13435463, 0.07150907, 0.05407568,\n",
      "       0.0926592 , 0.12743086, 0.13728633, 0.10726871, 0.12337783,\n",
      "       0.07409146, 0.12424993, 0.09472596, 0.07064553, 0.12875765,\n",
      "       0.12804835, 0.10711913, 0.119109  , 0.08890892, 0.07895842,\n",
      "       0.05433382, 0.07002703, 0.11456302, 0.12290077, 0.09093796,\n",
      "       0.12577554, 0.12707034, 0.12493968, 0.1228912 , 0.09906709,\n",
      "       0.12865213, 0.13392553, 0.12248585, 0.12871257, 0.13143538,\n",
      "       0.09659357, 0.08743487, 0.12422145, 0.13680356, 0.06729117,\n",
      "       0.1198086 , 0.12055738, 0.12003713, 0.12642889, 0.12518626,\n",
      "       0.11428637, 0.08482692, 0.07695304, 0.1255141 , 0.12064565,\n",
      "       0.08030669, 0.13234146, 0.1245535 , 0.11188549, 0.10961034,\n",
      "       0.11030469, 0.09784915, 0.12996074, 0.13855768, 0.09593774,\n",
      "       0.10179793, 0.12331947, 0.13397588, 0.15425478, 0.13901282,\n",
      "       0.12914579, 0.07020414, 0.12392365, 0.06952847, 0.13969412,\n",
      "       0.09661928, 0.11528571, 0.07439367, 0.07450923, 0.10618427,\n",
      "       0.05453553, 0.06880965, 0.05893274, 0.12452869, 0.07901474,\n",
      "       0.12498232, 0.11849648, 0.11328612, 0.10552993, 0.07440878,\n",
      "       0.14267639, 0.05177933, 0.10193425, 0.11815968, 0.07992609])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.1272727272727273, 'min_child_weight': 70, 'max_depth': 19, 'gamma': 0.74810101010101, 'eta': 0.11562801312073753} \n",
      "\n",
      "Best index/iterasi :  98\n",
      "Best AUC : 0.824564440288413 ( std: 0.06807235214861866 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 43.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 56.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  82 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.71280489, 0.61706936, 0.80317335, 0.53080531, 0.6478795 ,\n",
      "       0.54734503, 0.77515796, 0.64546349, 0.71359006, 0.71090382,\n",
      "       0.61440656, 0.75388576, 0.57892701, 0.54208913, 0.56130838,\n",
      "       0.81484197, 0.77115532, 0.60368284, 0.69411136, 0.58331283,\n",
      "       0.65129555, 0.66698431, 0.63320535, 0.68488555, 0.60977267,\n",
      "       0.78884962, 0.69403551, 0.67599079, 0.67470533, 0.72311961,\n",
      "       0.71490926, 0.53340958, 0.64095877, 0.61511575, 0.53067974,\n",
      "       0.55658149, 0.71829978, 0.5590093 , 0.66069766, 0.71934105,\n",
      "       0.6234319 , 0.80726446, 0.81714877, 0.78763806, 0.68226207,\n",
      "       0.52547338, 0.68644057, 0.55015934, 0.68084573, 0.68885366,\n",
      "       0.7964765 , 0.75654442, 0.81054585, 0.82341309, 0.81492896,\n",
      "       0.51434018, 0.70713985, 0.5108923 , 0.71873358, 0.82219826,\n",
      "       0.69983905, 0.6152524 , 0.76675108, 0.63563579, 0.62988441,\n",
      "       0.56265624, 0.54945628, 0.61376915, 0.77881398, 0.74874667,\n",
      "       0.68927579, 0.8120979 , 0.67574821, 0.72502088, 0.7558797 ,\n",
      "       0.64717648, 0.72589829, 0.68853591, 0.69403344, 0.57579971,\n",
      "       0.80814706, 0.71926749, 0.75467925, 0.6943816 , 0.56313746,\n",
      "       0.70533773, 0.73397197, 0.65166395, 0.78622223, 0.65971789,\n",
      "       0.63365617, 0.74486213, 0.76966215, 0.70851167, 0.53721714,\n",
      "       0.7758041 , 0.66228158, 0.68229697, 0.60722825, 0.65371659,\n",
      "       0.7005506 , 0.60965884, 0.73740278, 0.55590847, 0.77378466,\n",
      "       0.79358319, 0.54020649, 0.65715207, 0.81225765, 0.76023162,\n",
      "       0.71628718, 0.55592772, 0.80320422, 0.71374597, 0.69762418,\n",
      "       0.6413468 , 0.68693679, 0.66890759, 0.71041766, 0.78022311,\n",
      "       0.57833603, 0.54489716, 0.76229377, 0.49776532, 0.76210965,\n",
      "       0.81511166, 0.81055293, 0.52206951, 0.81244383, 0.81812787,\n",
      "       0.58592569, 0.60703664, 0.72197813, 0.68960093, 0.70247466,\n",
      "       0.54668299, 0.80581766, 0.61629771, 0.80044421, 0.768334  ,\n",
      "       0.49058819, 0.75712329, 0.68756823, 0.73842039, 0.67716199,\n",
      "       0.73882228, 0.74559603, 0.61688494, 0.68701638, 0.64525296,\n",
      "       0.60604598, 0.70309046, 0.71980981, 0.53122631, 0.61280699,\n",
      "       0.69115924, 0.54964348, 0.69692052, 0.76650558, 0.54792002,\n",
      "       0.55125182, 0.62447307, 0.67849934, 0.58962726, 0.61842134,\n",
      "       0.80477591, 0.75395332, 0.68942174, 0.61153694, 0.72713709,\n",
      "       0.72705914, 0.51511117, 0.67891567, 0.67589642, 0.7816864 ,\n",
      "       0.65574194, 0.75843476, 0.816271  , 0.58264219, 0.59917812,\n",
      "       0.54047919, 0.71482925, 0.4795686 , 0.70102309, 0.69447597,\n",
      "       0.77981626, 0.631921  , 0.64314704, 0.69890268, 0.583635  ,\n",
      "       0.80968116, 0.75152347, 0.69046644, 0.67601443, 0.58953337,\n",
      "       0.78303945, 0.81447328, 0.5913727 , 0.71741807, 0.58363797])] \n",
      "\n",
      "mean AUC :  0.6782437016439979\n",
      "All std:  [array([0.11296764, 0.10820024, 0.07941176, 0.10748991, 0.09705199,\n",
      "       0.08966627, 0.10067795, 0.12161865, 0.11718222, 0.12280244,\n",
      "       0.13828236, 0.11001059, 0.07772496, 0.10192886, 0.08262449,\n",
      "       0.06955188, 0.0974176 , 0.06310044, 0.12800534, 0.0946584 ,\n",
      "       0.10711812, 0.12695306, 0.14295062, 0.12662602, 0.11481755,\n",
      "       0.08829511, 0.14676115, 0.14295146, 0.13624133, 0.12413695,\n",
      "       0.13613087, 0.08265684, 0.09941688, 0.13454274, 0.10384566,\n",
      "       0.04641748, 0.13345396, 0.12411854, 0.11465578, 0.11827321,\n",
      "       0.09376334, 0.06188058, 0.07479437, 0.05298729, 0.13118722,\n",
      "       0.07245296, 0.13597386, 0.10111025, 0.14584518, 0.11679909,\n",
      "       0.07107737, 0.11404825, 0.07030511, 0.06656124, 0.07295515,\n",
      "       0.08328032, 0.12540723, 0.08336103, 0.12759257, 0.0726581 ,\n",
      "       0.12188077, 0.07540482, 0.08768369, 0.09424997, 0.10812839,\n",
      "       0.11297043, 0.06176132, 0.10239452, 0.09498893, 0.10126639,\n",
      "       0.13574849, 0.07277049, 0.12737678, 0.12484129, 0.09780362,\n",
      "       0.11585398, 0.10635125, 0.13913621, 0.14747456, 0.14390144,\n",
      "       0.07307628, 0.13390165, 0.09163994, 0.1408146 , 0.11442809,\n",
      "       0.15534346, 0.12933497, 0.12698519, 0.09561905, 0.13043273,\n",
      "       0.11882705, 0.12330555, 0.12211642, 0.1402438 , 0.06056563,\n",
      "       0.10113878, 0.12081804, 0.13327115, 0.1417634 , 0.13812471,\n",
      "       0.13716818, 0.11949514, 0.12782865, 0.09555934, 0.08724392,\n",
      "       0.08181266, 0.11467725, 0.12688309, 0.07172073, 0.10719255,\n",
      "       0.11984209, 0.12028754, 0.07639443, 0.10668859, 0.1355995 ,\n",
      "       0.12444427, 0.1345394 , 0.12138057, 0.11652926, 0.08379364,\n",
      "       0.09783864, 0.11831637, 0.09522106, 0.07060535, 0.09513628,\n",
      "       0.07319488, 0.07205506, 0.11584472, 0.06837563, 0.0738482 ,\n",
      "       0.08733814, 0.09650394, 0.13355759, 0.12882354, 0.11647654,\n",
      "       0.06926464, 0.07841326, 0.10897962, 0.08003713, 0.08678223,\n",
      "       0.08953717, 0.08683211, 0.13396293, 0.12109166, 0.13909166,\n",
      "       0.09868212, 0.10653339, 0.11575879, 0.11079563, 0.12781081,\n",
      "       0.06411133, 0.15262051, 0.14693838, 0.06645424, 0.11287448,\n",
      "       0.12499022, 0.11663501, 0.12533708, 0.10209618, 0.11000298,\n",
      "       0.0875701 , 0.1311035 , 0.1310948 , 0.0893026 , 0.12633872,\n",
      "       0.07330897, 0.1134565 , 0.13933068, 0.08971235, 0.15316062,\n",
      "       0.12159505, 0.02987011, 0.12760523, 0.13535883, 0.08762278,\n",
      "       0.12446796, 0.09024034, 0.07629468, 0.09647548, 0.08036849,\n",
      "       0.11519641, 0.13411696, 0.09281509, 0.13258819, 0.13365169,\n",
      "       0.08804584, 0.10650994, 0.11864648, 0.14168837, 0.14323875,\n",
      "       0.07279449, 0.10404804, 0.10735406, 0.11911371, 0.06503838,\n",
      "       0.08670616, 0.07201282, 0.13121903, 0.11766808, 0.12634535])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.16363636363636364, 'min_child_weight': 93, 'max_depth': 36, 'gamma': 1.172131313131313, 'eta': 0.07636298261282246} \n",
      "\n",
      "Best index/iterasi :  53\n",
      "Best AUC : 0.8234130884160942 ( std: 0.06656123620100753 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 52.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  92 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.70923547, 0.80826552, 0.65713609, 0.61018024, 0.72370915,\n",
      "       0.81628129, 0.81065753, 0.67576463, 0.54742628, 0.63238126,\n",
      "       0.6568032 , 0.81214037, 0.71073347, 0.81233593, 0.64986455,\n",
      "       0.69678304, 0.6578312 , 0.7830102 , 0.5819656 , 0.56888022,\n",
      "       0.66568617, 0.64102205, 0.71553608, 0.72322058, 0.69313297,\n",
      "       0.75919494, 0.49668437, 0.70127456, 0.66396219, 0.72486702,\n",
      "       0.72479424, 0.6928546 , 0.71143517, 0.59541591, 0.67133754,\n",
      "       0.61113671, 0.58485663, 0.70423446, 0.5847558 , 0.74758254,\n",
      "       0.81783803, 0.54197347, 0.48665049, 0.68038201, 0.61116178,\n",
      "       0.81045181, 0.66515175, 0.66144507, 0.69480626, 0.76044472,\n",
      "       0.60398592, 0.55181944, 0.75739171, 0.68189197, 0.71515552,\n",
      "       0.81985349, 0.81087479, 0.75485742, 0.65626003, 0.67830525,\n",
      "       0.63991234, 0.58204965, 0.7542689 , 0.80237506, 0.71390956,\n",
      "       0.74764123, 0.80250044, 0.76265348, 0.59013427, 0.69213333,\n",
      "       0.71266473, 0.73733779, 0.71404149, 0.59261288, 0.65270069,\n",
      "       0.75479658, 0.50134544, 0.72332412, 0.76215662, 0.68684087,\n",
      "       0.60905935, 0.60201597, 0.77523155, 0.69693069, 0.79312368,\n",
      "       0.76811787, 0.58085196, 0.67046224, 0.5768923 , 0.71325022,\n",
      "       0.72281025, 0.50181324, 0.73385315, 0.73371915, 0.63701811,\n",
      "       0.63839899, 0.6901931 , 0.70011605, 0.70661346, 0.61933726,\n",
      "       0.66367496, 0.7928499 , 0.7201441 , 0.66273579, 0.71326022,\n",
      "       0.6853448 , 0.68810626, 0.61533959, 0.8083449 , 0.56636502,\n",
      "       0.80978542, 0.62997633, 0.57135745, 0.5858431 , 0.73228249,\n",
      "       0.68505694, 0.59775366, 0.76929365, 0.66298267, 0.48122024,\n",
      "       0.72299662, 0.7754956 , 0.64372612, 0.81499989, 0.6281153 ,\n",
      "       0.64721538, 0.72178451, 0.76305062, 0.57372297, 0.55628877,\n",
      "       0.81038758, 0.56436941, 0.77318155, 0.76708136, 0.66892171,\n",
      "       0.64374975, 0.71021565, 0.7186151 , 0.71300623, 0.67681583,\n",
      "       0.68825281, 0.70053663, 0.68320092, 0.81228964, 0.54946699,\n",
      "       0.77907783, 0.62216545, 0.69996594, 0.65647945, 0.72183072,\n",
      "       0.81400209, 0.70236658, 0.73534246, 0.52245479, 0.73182806,\n",
      "       0.7112035 , 0.60050878, 0.75971101, 0.55029165, 0.63964238,\n",
      "       0.73505271, 0.75201846, 0.62922819, 0.66599946, 0.65882876,\n",
      "       0.79167946, 0.64965995, 0.60476616, 0.62708265, 0.75685277,\n",
      "       0.72147658, 0.74197761, 0.81698257, 0.5828326 , 0.72263147,\n",
      "       0.63882582, 0.57904245, 0.75655442, 0.6180321 , 0.57599009,\n",
      "       0.72455136, 0.62025846, 0.53796351, 0.58412182, 0.57861561,\n",
      "       0.63498635, 0.71586946, 0.7279876 , 0.65360371, 0.78845911,\n",
      "       0.50534297, 0.68816559, 0.66145674, 0.69885267, 0.57480663,\n",
      "       0.72109898, 0.81105993, 0.56981696, 0.80171275, 0.68884814])] \n",
      "\n",
      "mean AUC :  0.6820972325885407\n",
      "All std:  [array([0.1165328 , 0.07915878, 0.12368054, 0.09638883, 0.12319557,\n",
      "       0.07566841, 0.07484244, 0.12059232, 0.07499341, 0.08908229,\n",
      "       0.12982576, 0.07768273, 0.11705179, 0.07518598, 0.13813309,\n",
      "       0.12704235, 0.1109132 , 0.09400829, 0.10383715, 0.10886934,\n",
      "       0.12662358, 0.10104376, 0.1334961 , 0.1273372 , 0.13169219,\n",
      "       0.09783405, 0.08360533, 0.12842662, 0.14830848, 0.12351532,\n",
      "       0.12902465, 0.13395299, 0.11907376, 0.08300646, 0.11094382,\n",
      "       0.09733663, 0.09766002, 0.14699395, 0.10376413, 0.11876625,\n",
      "       0.06834563, 0.09522215, 0.09331714, 0.14002435, 0.09067692,\n",
      "       0.07694636, 0.12868049, 0.11119281, 0.14536671, 0.0874835 ,\n",
      "       0.12399582, 0.08444175, 0.09188432, 0.13720529, 0.11103222,\n",
      "       0.06899124, 0.07038749, 0.11551517, 0.12906683, 0.14467899,\n",
      "       0.08946418, 0.11897101, 0.09226066, 0.08112015, 0.13090073,\n",
      "       0.10679873, 0.07919206, 0.10017532, 0.05796197, 0.1389822 ,\n",
      "       0.12983759, 0.11016622, 0.14029501, 0.12553793, 0.11462945,\n",
      "       0.0803502 , 0.09342718, 0.11779067, 0.0972865 , 0.13351485,\n",
      "       0.11897864, 0.08714133, 0.08515259, 0.12610293, 0.08600705,\n",
      "       0.09035267, 0.08426137, 0.12915468, 0.08911108, 0.16110931,\n",
      "       0.1282628 , 0.09209688, 0.12631881, 0.12279545, 0.11936628,\n",
      "       0.13011984, 0.1287599 , 0.15804256, 0.1434179 , 0.12673887,\n",
      "       0.12110588, 0.07024665, 0.13120773, 0.12935399, 0.13303606,\n",
      "       0.14730753, 0.12559165, 0.13473904, 0.07534533, 0.16719527,\n",
      "       0.07741796, 0.12825922, 0.10594064, 0.13347967, 0.10146829,\n",
      "       0.14268609, 0.12559511, 0.08334281, 0.13104523, 0.08153663,\n",
      "       0.12625407, 0.08528823, 0.11943376, 0.07167986, 0.11591976,\n",
      "       0.09918789, 0.12540471, 0.08683601, 0.13717184, 0.10522565,\n",
      "       0.07505749, 0.11657662, 0.09754207, 0.09242895, 0.11714902,\n",
      "       0.11967496, 0.1193881 , 0.12871893, 0.11707553, 0.12936902,\n",
      "       0.15103843, 0.13892825, 0.11624639, 0.07815785, 0.05584393,\n",
      "       0.08093396, 0.08770529, 0.1242954 , 0.11804911, 0.1234057 ,\n",
      "       0.0717144 , 0.15004701, 0.11069303, 0.12170999, 0.10805587,\n",
      "       0.11849924, 0.08826987, 0.10538187, 0.05864377, 0.10012405,\n",
      "       0.1091007 , 0.1277076 , 0.08450676, 0.12151104, 0.12067279,\n",
      "       0.08002598, 0.11884429, 0.13127026, 0.11933606, 0.13266473,\n",
      "       0.13099196, 0.11958542, 0.07164757, 0.12909564, 0.14499251,\n",
      "       0.1307319 , 0.0930876 , 0.09661247, 0.09397535, 0.08769762,\n",
      "       0.11647253, 0.07831552, 0.08945906, 0.11138724, 0.09783802,\n",
      "       0.12384123, 0.12320402, 0.11207515, 0.11875885, 0.08281317,\n",
      "       0.0863019 , 0.13464215, 0.14050392, 0.130705  , 0.07372956,\n",
      "       0.12216334, 0.07571266, 0.11303629, 0.07950615, 0.12138077])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.1, 'min_child_weight': 33, 'max_depth': 5, 'gamma': 0.32407070707070706, 'eta': 0.0021248453524988827} \n",
      "\n",
      "Best index/iterasi :  55\n",
      "Best AUC : 0.8198534850443236 ( std: 0.0689912397160393 ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataset 1 \n",
    "\n",
    "seeds=[1,12,22,32,42,52,62,72,82,92]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    auc,std,best_index,best_param=random_search(X_bank,y_bank,model_x,hyper_space_2,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dataset 2 (Credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:29:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.78120145, 0.77241264, 0.78238978, 0.75526435, 0.75657096,\n",
      "       0.76220854, 0.7525148 , 0.77847731, 0.75413348, 0.76214465,\n",
      "       0.78213862, 0.77603421, 0.75823803, 0.78311534, 0.77085718,\n",
      "       0.77077741, 0.78016369, 0.70400238, 0.77965861, 0.78136595,\n",
      "       0.77995384, 0.77718816, 0.78072231, 0.71341742, 0.77559685,\n",
      "       0.75732043, 0.78066321, 0.72045796, 0.77239356, 0.7831656 ,\n",
      "       0.76772713, 0.77734109, 0.76582857, 0.67801715, 0.780044  ,\n",
      "       0.78114355, 0.77632918, 0.67725786, 0.78065547, 0.7808653 ,\n",
      "       0.7358585 , 0.78157426, 0.77477169, 0.73940657, 0.71948337,\n",
      "       0.78106015, 0.77979527, 0.75849182, 0.77799412, 0.77425401,\n",
      "       0.73823488, 0.78224263, 0.78251375, 0.72062264, 0.7803158 ,\n",
      "       0.76409291, 0.77660535, 0.74230557, 0.77954764, 0.78143481,\n",
      "       0.78143369, 0.77154635, 0.75613428, 0.78051005, 0.76938464,\n",
      "       0.78151001, 0.71991355, 0.78055998, 0.78254479, 0.72153304,\n",
      "       0.7790514 , 0.78045982, 0.77986904, 0.78080518, 0.77675138,\n",
      "       0.74620863, 0.78152224, 0.7805507 , 0.71006262, 0.76186184,\n",
      "       0.75856471, 0.74341019, 0.75618202, 0.78171194, 0.69727015,\n",
      "       0.77826088, 0.70656941, 0.78117621, 0.75465417, 0.77866537,\n",
      "       0.73130278, 0.77808361, 0.77646381, 0.77515116, 0.77490749,\n",
      "       0.77882782, 0.78027148, 0.68563266, 0.77710723, 0.75326722,\n",
      "       0.76347952, 0.77311343, 0.77592841, 0.76901317, 0.7824651 ,\n",
      "       0.77571238, 0.77111603, 0.77924163, 0.78268796, 0.70114813,\n",
      "       0.77443159, 0.73947277, 0.76455395, 0.77698849, 0.75959089,\n",
      "       0.78327896, 0.77036615, 0.77584274, 0.71736497, 0.77064347,\n",
      "       0.73428218, 0.77873018, 0.7791892 , 0.76204215, 0.77882565,\n",
      "       0.74879947, 0.70348574, 0.77407734, 0.77663218, 0.77895999,\n",
      "       0.78138915, 0.74474597, 0.77346424, 0.7807346 , 0.78215816,\n",
      "       0.77546622, 0.76185934, 0.77567294, 0.78227513, 0.77424031,\n",
      "       0.74428641, 0.78003923, 0.7534107 , 0.68954943, 0.78053849,\n",
      "       0.78155919, 0.74843104, 0.7409549 , 0.78230756, 0.65969253,\n",
      "       0.65470395, 0.75423452, 0.77918749, 0.7763959 , 0.76616879,\n",
      "       0.775641  , 0.77785668, 0.77000027, 0.77901819, 0.69605046,\n",
      "       0.72780702, 0.7782393 , 0.77783988, 0.78012225, 0.75857205,\n",
      "       0.77826724, 0.76638689, 0.77765289, 0.78326134, 0.77060695,\n",
      "       0.78289693, 0.7562853 , 0.76637307, 0.77516491, 0.77529919,\n",
      "       0.77983038, 0.76526513, 0.76981063, 0.77859883, 0.77693296,\n",
      "       0.78325557, 0.688631  , 0.78252987, 0.72033125, 0.6954924 ,\n",
      "       0.74233877, 0.78220932, 0.77993542, 0.74986747, 0.6954456 ,\n",
      "       0.7267503 , 0.77892971, 0.76919764, 0.71570727, 0.77857887,\n",
      "       0.77898186, 0.78062829, 0.78176073, 0.7803734 , 0.78247969])] \n",
      "\n",
      "mean AUC :  0.7622609574725172\n",
      "All std:  [array([0.02196317, 0.0140021 , 0.02061786, 0.01844103, 0.02099808,\n",
      "       0.01031845, 0.02155114, 0.02129926, 0.01429779, 0.01383275,\n",
      "       0.02168871, 0.02059017, 0.01531623, 0.02065225, 0.02201526,\n",
      "       0.01654564, 0.02024157, 0.02483666, 0.02054981, 0.02231978,\n",
      "       0.01839428, 0.01763183, 0.02227598, 0.03230634, 0.02298747,\n",
      "       0.01546265, 0.01887418, 0.02580822, 0.01975043, 0.02222005,\n",
      "       0.01616326, 0.02265603, 0.01327117, 0.02414494, 0.02015533,\n",
      "       0.02079907, 0.02126684, 0.03014346, 0.02248802, 0.02238528,\n",
      "       0.01982942, 0.02148237, 0.02280581, 0.03526702, 0.04043569,\n",
      "       0.02183202, 0.01894271, 0.01931836, 0.02167141, 0.01672273,\n",
      "       0.0148182 , 0.02104441, 0.02077462, 0.01149712, 0.02271726,\n",
      "       0.01907996, 0.01730268, 0.0143754 , 0.02275046, 0.02130313,\n",
      "       0.02185876, 0.01645226, 0.01491712, 0.01822653, 0.01834777,\n",
      "       0.02075398, 0.03233767, 0.01866952, 0.02167281, 0.02398776,\n",
      "       0.02052085, 0.01876207, 0.02281051, 0.02177077, 0.0242833 ,\n",
      "       0.01641101, 0.02159036, 0.0221512 , 0.02866129, 0.01918949,\n",
      "       0.01348902, 0.01888433, 0.01900546, 0.02153696, 0.04067772,\n",
      "       0.02320951, 0.01900857, 0.02119544, 0.01875164, 0.01945545,\n",
      "       0.02023805, 0.01896026, 0.01977131, 0.01837192, 0.01871106,\n",
      "       0.02336274, 0.02281356, 0.03079112, 0.01784675, 0.02026904,\n",
      "       0.01471063, 0.01742563, 0.01746996, 0.0139102 , 0.02190057,\n",
      "       0.0231261 , 0.02117593, 0.01797254, 0.02123837, 0.03023166,\n",
      "       0.02459294, 0.01731016, 0.01443759, 0.01964207, 0.01660513,\n",
      "       0.02176085, 0.01595514, 0.02272541, 0.03185551, 0.01561194,\n",
      "       0.01375017, 0.01775879, 0.0200318 , 0.01974452, 0.01693677,\n",
      "       0.01580053, 0.02015074, 0.02234885, 0.01876229, 0.02264746,\n",
      "       0.02168508, 0.01752898, 0.0214788 , 0.02165534, 0.02214642,\n",
      "       0.0179896 , 0.0133728 , 0.02324818, 0.02199538, 0.0197544 ,\n",
      "       0.02745186, 0.02210948, 0.01715636, 0.02424741, 0.02133699,\n",
      "       0.01868131, 0.02695264, 0.02174498, 0.02099331, 0.04672312,\n",
      "       0.03300648, 0.01696957, 0.02171549, 0.01682111, 0.01709136,\n",
      "       0.01983382, 0.01920335, 0.01580067, 0.02010939, 0.01179406,\n",
      "       0.02432059, 0.02321874, 0.01811   , 0.02301367, 0.01498903,\n",
      "       0.02090625, 0.01640941, 0.02380488, 0.0212853 , 0.01733249,\n",
      "       0.02092858, 0.01262806, 0.01875686, 0.02282574, 0.02285758,\n",
      "       0.01891362, 0.01987425, 0.0159724 , 0.01859182, 0.02282826,\n",
      "       0.02146491, 0.03156298, 0.02150455, 0.02404699, 0.03528097,\n",
      "       0.0249405 , 0.02129192, 0.02280601, 0.01320875, 0.04352634,\n",
      "       0.01794839, 0.02097984, 0.01955247, 0.02238576, 0.02259797,\n",
      "       0.01955478, 0.02127616, 0.02154915, 0.02273783, 0.02204112])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.6454545454545454, 'min_child_weight': 48, 'max_depth': 88, 'gamma': 1.49520202020202, 'eta': 0.02560993100258458} \n",
      "\n",
      "Best index/iterasi :  115\n",
      "Best AUC : 0.7832789571361415 ( std: 0.02176084528936761 ) \n",
      "\n",
      "running time:  4166.585553646088  detik. Dalam menit:  69.44309256076812  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:34] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  12 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.78266234, 0.78162472, 0.76797253, 0.77890643, 0.74875787,\n",
      "       0.7179963 , 0.73656264, 0.7720488 , 0.78013375, 0.67470897,\n",
      "       0.76953242, 0.78130907, 0.76161372, 0.7799086 , 0.75297401,\n",
      "       0.75801397, 0.74937918, 0.77937236, 0.78101971, 0.77864184,\n",
      "       0.77996674, 0.78100063, 0.78285821, 0.77912734, 0.68168039,\n",
      "       0.78106962, 0.78174256, 0.78299252, 0.78198283, 0.78123033,\n",
      "       0.77885637, 0.74329852, 0.67504902, 0.78064198, 0.78027803,\n",
      "       0.77928427, 0.71971598, 0.77922376, 0.74247213, 0.77766124,\n",
      "       0.76696389, 0.76133138, 0.77491096, 0.78047682, 0.72936889,\n",
      "       0.72578505, 0.76218104, 0.76301954, 0.75236657, 0.77975498,\n",
      "       0.77622906, 0.77999354, 0.78186766, 0.77944522, 0.77072237,\n",
      "       0.7795025 , 0.77229226, 0.77528944, 0.70200496, 0.7536614 ,\n",
      "       0.77134452, 0.7830541 , 0.78074634, 0.78264597, 0.78136913,\n",
      "       0.76856993, 0.78015249, 0.73944142, 0.78331324, 0.76477138,\n",
      "       0.7715771 , 0.77401157, 0.77523976, 0.78165693, 0.6832733 ,\n",
      "       0.78002593, 0.74463692, 0.6909299 , 0.73504351, 0.6925417 ,\n",
      "       0.77536851, 0.78016088, 0.78113685, 0.77348763, 0.77664802,\n",
      "       0.78081315, 0.78015518, 0.78066415, 0.78085027, 0.77083387,\n",
      "       0.7779597 , 0.77458646, 0.78009362, 0.76366502, 0.75705622,\n",
      "       0.75625883, 0.74198496, 0.71177676, 0.776209  , 0.77920703,\n",
      "       0.77949312, 0.75691167, 0.67268975, 0.70720563, 0.6761032 ,\n",
      "       0.78058081, 0.74519462, 0.77556411, 0.78129804, 0.78110344,\n",
      "       0.77796032, 0.77855486, 0.69134209, 0.70759894, 0.78008505,\n",
      "       0.72579153, 0.77688866, 0.77224298, 0.76885069, 0.76035368,\n",
      "       0.7126199 , 0.67362008, 0.75584514, 0.77853893, 0.74969594,\n",
      "       0.686635  , 0.760657  , 0.77989213, 0.73836754, 0.77048477,\n",
      "       0.77810876, 0.77708946, 0.75749952, 0.76663791, 0.78294151,\n",
      "       0.76932461, 0.71898866, 0.78213885, 0.78183959, 0.75826911,\n",
      "       0.76586359, 0.78206432, 0.68965911, 0.74988744, 0.78138054,\n",
      "       0.78037943, 0.75516624, 0.78056266, 0.77414335, 0.75170049,\n",
      "       0.76880859, 0.77004381, 0.76434332, 0.78238821, 0.77822704,\n",
      "       0.77995548, 0.7810999 , 0.69772593, 0.77327801, 0.78235604,\n",
      "       0.78049732, 0.73812053, 0.78135621, 0.78323588, 0.77083448,\n",
      "       0.77835065, 0.77016956, 0.77581225, 0.75482895, 0.7773967 ,\n",
      "       0.72036249, 0.76586483, 0.77660681, 0.77993194, 0.78163074,\n",
      "       0.78182759, 0.69340636, 0.78198961, 0.69695382, 0.76803138,\n",
      "       0.74995666, 0.78098396, 0.77569728, 0.7564058 , 0.7819696 ,\n",
      "       0.77595931, 0.6725693 , 0.77540375, 0.77754274, 0.78051017,\n",
      "       0.73710965, 0.78268695, 0.7826729 , 0.74899558, 0.77943732,\n",
      "       0.78243155, 0.73595058, 0.76591523, 0.78226073, 0.75037552])] \n",
      "\n",
      "mean AUC :  0.7611489212705854\n",
      "All std:  [array([0.02175303, 0.02249203, 0.01697409, 0.02318743, 0.00944618,\n",
      "       0.01672186, 0.0216379 , 0.01778367, 0.02215554, 0.01323938,\n",
      "       0.0216548 , 0.02048195, 0.01484218, 0.02302105, 0.01825722,\n",
      "       0.01559046, 0.02882479, 0.02028383, 0.02201926, 0.02071288,\n",
      "       0.02229007, 0.0222152 , 0.02175235, 0.02034675, 0.02453645,\n",
      "       0.02114666, 0.02036732, 0.02189899, 0.02149925, 0.02239123,\n",
      "       0.02194849, 0.01788981, 0.03491328, 0.01920672, 0.02232364,\n",
      "       0.02323313, 0.017452  , 0.02191209, 0.01489185, 0.01717576,\n",
      "       0.01553478, 0.02097078, 0.01935174, 0.02236665, 0.03041093,\n",
      "       0.03599394, 0.0133696 , 0.02024628, 0.01873375, 0.02157773,\n",
      "       0.01944827, 0.02170719, 0.02253908, 0.0221559 , 0.01501511,\n",
      "       0.01803943, 0.02151543, 0.02135796, 0.01509115, 0.0147208 ,\n",
      "       0.01613078, 0.02090955, 0.02233173, 0.02188266, 0.02201482,\n",
      "       0.01768522, 0.02278427, 0.01463874, 0.02146118, 0.01777792,\n",
      "       0.01743979, 0.02206808, 0.01901319, 0.02179374, 0.04515032,\n",
      "       0.02212499, 0.03005327, 0.03252957, 0.02540808, 0.06905526,\n",
      "       0.01889601, 0.02302198, 0.02154934, 0.02032634, 0.02263689,\n",
      "       0.02067151, 0.02205814, 0.02246042, 0.01977604, 0.01292211,\n",
      "       0.02118938, 0.01619833, 0.02275305, 0.01772784, 0.01809897,\n",
      "       0.01521795, 0.02338124, 0.0304401 , 0.02288248, 0.01740391,\n",
      "       0.02199584, 0.01395368, 0.03278914, 0.03853751, 0.0200221 ,\n",
      "       0.02115308, 0.01822491, 0.02145606, 0.0218921 , 0.02077671,\n",
      "       0.02324337, 0.02303597, 0.03260082, 0.01196112, 0.02213368,\n",
      "       0.02326884, 0.01617468, 0.01514728, 0.0169033 , 0.01800665,\n",
      "       0.02278019, 0.032203  , 0.01537012, 0.0222614 , 0.02093798,\n",
      "       0.03077076, 0.01577098, 0.01756205, 0.03271466, 0.01849289,\n",
      "       0.02250253, 0.02359152, 0.01633128, 0.01870737, 0.02202642,\n",
      "       0.01784417, 0.03356041, 0.02114703, 0.02167446, 0.0180629 ,\n",
      "       0.01745265, 0.0226101 , 0.04386604, 0.01538516, 0.02096369,\n",
      "       0.02290022, 0.0152815 , 0.02116803, 0.02116889, 0.01851388,\n",
      "       0.01380159, 0.01560632, 0.01641516, 0.02187181, 0.02317335,\n",
      "       0.02262681, 0.02204708, 0.0297589 , 0.02278633, 0.0210819 ,\n",
      "       0.02270859, 0.0187674 , 0.02113604, 0.02205147, 0.02208372,\n",
      "       0.0207846 , 0.01619325, 0.02215928, 0.01365414, 0.01958256,\n",
      "       0.02621873, 0.02032233, 0.02023766, 0.02249636, 0.0217666 ,\n",
      "       0.0219575 , 0.03212674, 0.02150956, 0.01629889, 0.01469579,\n",
      "       0.01887741, 0.0223971 , 0.02214453, 0.02263762, 0.02127241,\n",
      "       0.02183565, 0.02525795, 0.02268198, 0.02330957, 0.01945403,\n",
      "       0.02204265, 0.02169903, 0.02125972, 0.02072378, 0.02008817,\n",
      "       0.02168237, 0.02024253, 0.02060012, 0.02094385, 0.01465123])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.8999999999999999, 'min_child_weight': 80, 'max_depth': 86, 'gamma': 1.9798080808080807, 'eta': 0.029004304938639917} \n",
      "\n",
      "Best index/iterasi :  68\n",
      "Best AUC : 0.7833132438649552 ( std: 0.021461183645861692 ) \n",
      "\n",
      "running time:  4439.835237979889  detik. Dalam menit:  73.99725396633148  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:52:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  22 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.67457019, 0.78238246, 0.7746615 , 0.65933663, 0.71667036,\n",
      "       0.75630042, 0.73817691, 0.78235373, 0.78228061, 0.78173386,\n",
      "       0.78106637, 0.7807495 , 0.73396492, 0.7801016 , 0.69464057,\n",
      "       0.78059977, 0.7824849 , 0.77884674, 0.77893641, 0.66114199,\n",
      "       0.77859456, 0.77455734, 0.78102471, 0.77129326, 0.77726391,\n",
      "       0.78190812, 0.77900469, 0.71648702, 0.69422703, 0.72365585,\n",
      "       0.78287037, 0.71189885, 0.77811457, 0.729817  , 0.7807411 ,\n",
      "       0.68696956, 0.70587576, 0.77611931, 0.78282035, 0.78109816,\n",
      "       0.77751828, 0.7753346 , 0.78014315, 0.77893155, 0.77076186,\n",
      "       0.76365259, 0.77694047, 0.7322244 , 0.7805354 , 0.78140876,\n",
      "       0.78056895, 0.69319015, 0.78083696, 0.78038804, 0.73016468,\n",
      "       0.78163393, 0.72482233, 0.77934955, 0.78176983, 0.77763036,\n",
      "       0.78126772, 0.78291188, 0.77296688, 0.73556053, 0.7770335 ,\n",
      "       0.77873433, 0.77925113, 0.67891593, 0.78050749, 0.76081869,\n",
      "       0.78188596, 0.77585883, 0.75967443, 0.66734245, 0.78250226,\n",
      "       0.7607158 , 0.78140155, 0.77698368, 0.78138445, 0.77418564,\n",
      "       0.76557397, 0.77957525, 0.77967872, 0.77329069, 0.77986752,\n",
      "       0.78113656, 0.77296374, 0.77345633, 0.69912076, 0.75981079,\n",
      "       0.78134807, 0.78070254, 0.72393117, 0.69293936, 0.7789584 ,\n",
      "       0.78143134, 0.70355588, 0.7752487 , 0.78017431, 0.78192149,\n",
      "       0.70390719, 0.757095  , 0.77688667, 0.78185303, 0.71156823,\n",
      "       0.78082175, 0.78133016, 0.76853129, 0.76415597, 0.73896556,\n",
      "       0.77011733, 0.74365376, 0.78155381, 0.78194559, 0.72004478,\n",
      "       0.77424221, 0.77667342, 0.73682884, 0.77799429, 0.77708898,\n",
      "       0.69879224, 0.73877611, 0.77795989, 0.76908   , 0.76990708,\n",
      "       0.78199927, 0.77262998, 0.78112138, 0.77040939, 0.77268845,\n",
      "       0.71855871, 0.72951024, 0.78096881, 0.68352287, 0.75860319,\n",
      "       0.72103399, 0.70828288, 0.77907158, 0.7187656 , 0.74579252,\n",
      "       0.72773667, 0.76841048, 0.78070517, 0.78041354, 0.71200677,\n",
      "       0.78151306, 0.76792363, 0.7826106 , 0.71233854, 0.76162043,\n",
      "       0.77988293, 0.77993399, 0.76346241, 0.7261466 , 0.77968003,\n",
      "       0.77526908, 0.67393346, 0.78205807, 0.7796351 , 0.69025171,\n",
      "       0.70297996, 0.75837885, 0.74761428, 0.69909241, 0.78250576,\n",
      "       0.77916584, 0.78093163, 0.77729744, 0.77260449, 0.76168823,\n",
      "       0.76490355, 0.77526656, 0.78316156, 0.78179896, 0.75371323,\n",
      "       0.7732503 , 0.71554117, 0.77860358, 0.7754554 , 0.73928309,\n",
      "       0.77650138, 0.74669871, 0.77952793, 0.7805544 , 0.78176273,\n",
      "       0.77915628, 0.75266991, 0.75283607, 0.68124406, 0.77565173,\n",
      "       0.66846436, 0.69606166, 0.7816025 , 0.78094826, 0.69988218,\n",
      "       0.74129316, 0.74818115, 0.75707442, 0.7644718 , 0.78215298])] \n",
      "\n",
      "mean AUC :  0.7572798591048644\n",
      "All std:  [array([0.01614378, 0.01960699, 0.01928544, 0.01527598, 0.00716034,\n",
      "       0.01769797, 0.01898397, 0.02097939, 0.02184075, 0.02081538,\n",
      "       0.02156996, 0.02222317, 0.0204042 , 0.02265217, 0.02624059,\n",
      "       0.02113673, 0.02119554, 0.01946759, 0.01940432, 0.00936734,\n",
      "       0.02129898, 0.01708155, 0.02131026, 0.01982989, 0.02047868,\n",
      "       0.02037575, 0.02122601, 0.01814447, 0.02713964, 0.0206389 ,\n",
      "       0.02162405, 0.01755873, 0.02321935, 0.03298865, 0.02129042,\n",
      "       0.00632267, 0.03545235, 0.01675242, 0.02121636, 0.02140215,\n",
      "       0.02209066, 0.01974858, 0.02300377, 0.02283068, 0.01885865,\n",
      "       0.01652726, 0.02271019, 0.02454837, 0.02294327, 0.02233509,\n",
      "       0.02191177, 0.0385825 , 0.02243359, 0.02249265, 0.03210051,\n",
      "       0.02247091, 0.02030903, 0.02281167, 0.0226642 , 0.02127279,\n",
      "       0.02232899, 0.02175353, 0.02114455, 0.01526123, 0.02403933,\n",
      "       0.01814283, 0.02217467, 0.03934007, 0.02249161, 0.01706563,\n",
      "       0.02191772, 0.0231035 , 0.01587749, 0.00959955, 0.02211435,\n",
      "       0.01734024, 0.02137574, 0.02319303, 0.02223695, 0.02184113,\n",
      "       0.01595564, 0.02290183, 0.02154111, 0.0165807 , 0.02249098,\n",
      "       0.02215488, 0.02107213, 0.01467165, 0.0147652 , 0.01743227,\n",
      "       0.02207816, 0.02238041, 0.01406205, 0.03595932, 0.02188317,\n",
      "       0.02067673, 0.01386293, 0.02268752, 0.02268773, 0.02208026,\n",
      "       0.04440962, 0.01511622, 0.02121197, 0.02162738, 0.03554643,\n",
      "       0.02205265, 0.0218972 , 0.0211381 , 0.01627281, 0.02466182,\n",
      "       0.0223784 , 0.01525276, 0.02193355, 0.02071016, 0.01684533,\n",
      "       0.01531626, 0.02211247, 0.01246919, 0.02051093, 0.02174778,\n",
      "       0.04162881, 0.02806411, 0.02319359, 0.01726271, 0.0158514 ,\n",
      "       0.02175557, 0.0169891 , 0.02138519, 0.0188786 , 0.02152068,\n",
      "       0.01449464, 0.02081337, 0.02187891, 0.01804687, 0.01891402,\n",
      "       0.01894806, 0.03566429, 0.01935793, 0.03105274, 0.02492888,\n",
      "       0.03240961, 0.01923545, 0.02213056, 0.02067802, 0.01555263,\n",
      "       0.02149069, 0.01739917, 0.0219307 , 0.01637167, 0.01985229,\n",
      "       0.01849445, 0.02119828, 0.01902641, 0.0234765 , 0.022598  ,\n",
      "       0.02186628, 0.01250968, 0.02226464, 0.02316925, 0.04330531,\n",
      "       0.02815609, 0.01159838, 0.0159106 , 0.04154661, 0.02194293,\n",
      "       0.02272089, 0.02143895, 0.02349511, 0.02122038, 0.01611239,\n",
      "       0.01609992, 0.02236052, 0.02161655, 0.02266406, 0.01713351,\n",
      "       0.01872216, 0.03911085, 0.0227997 , 0.0215999 , 0.0232274 ,\n",
      "       0.02224483, 0.02082725, 0.02251256, 0.01917884, 0.02213583,\n",
      "       0.02337523, 0.01745275, 0.02088702, 0.03308316, 0.02186977,\n",
      "       0.02120829, 0.02774609, 0.02024651, 0.02306354, 0.00960512,\n",
      "       0.02992555, 0.01616226, 0.01602738, 0.01582557, 0.02183687])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.2909090909090909, 'min_child_weight': 21, 'max_depth': 50, 'gamma': 0.7682929292929292, 'eta': 0.014426439512181581} \n",
      "\n",
      "Best index/iterasi :  172\n",
      "Best AUC : 0.7831615574611245 ( std: 0.021616554067828912 ) \n",
      "\n",
      "running time:  4109.787564277649  detik. Dalam menit:  68.49645940462749  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:56:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  32 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.66478752, 0.77952885, 0.77791076, 0.78032138, 0.78037103,\n",
      "       0.7359673 , 0.77564419, 0.76852334, 0.77361001, 0.78345147,\n",
      "       0.70809338, 0.77823697, 0.77883059, 0.76626065, 0.78295941,\n",
      "       0.77859882, 0.75110261, 0.77735985, 0.75595684, 0.69434765,\n",
      "       0.77120681, 0.75284796, 0.67595039, 0.7819322 , 0.78312564,\n",
      "       0.69412343, 0.77986144, 0.73478659, 0.75919111, 0.76065108,\n",
      "       0.77419413, 0.77850224, 0.76086949, 0.74693785, 0.70835794,\n",
      "       0.78282081, 0.7359757 , 0.78192917, 0.77086298, 0.77642951,\n",
      "       0.77446408, 0.78086635, 0.76449163, 0.77905279, 0.78113915,\n",
      "       0.74954946, 0.75596345, 0.77793696, 0.75740587, 0.77947112,\n",
      "       0.74650773, 0.77724064, 0.77752021, 0.72479469, 0.78255711,\n",
      "       0.77958916, 0.76808673, 0.76514643, 0.78165286, 0.77820033,\n",
      "       0.78138325, 0.7777743 , 0.76653228, 0.73277345, 0.78116821,\n",
      "       0.77798455, 0.78007344, 0.76745456, 0.78184422, 0.74753492,\n",
      "       0.770363  , 0.77682964, 0.78244833, 0.77602863, 0.78272572,\n",
      "       0.74638913, 0.77149684, 0.7800192 , 0.75325268, 0.74651518,\n",
      "       0.77546374, 0.77967819, 0.78271815, 0.72756865, 0.77728126,\n",
      "       0.77622985, 0.76214989, 0.78101542, 0.77093807, 0.77623756,\n",
      "       0.74122874, 0.7771207 , 0.74022874, 0.78058983, 0.77999608,\n",
      "       0.77506619, 0.78140955, 0.77929114, 0.72188107, 0.68148315,\n",
      "       0.78078948, 0.71953552, 0.78141249, 0.76784114, 0.71971633,\n",
      "       0.73101877, 0.77894076, 0.78260168, 0.78224257, 0.74663707,\n",
      "       0.76880488, 0.76073358, 0.76059945, 0.6991164 , 0.77840253,\n",
      "       0.78093438, 0.77986502, 0.76216197, 0.73847778, 0.76550819,\n",
      "       0.73125041, 0.78138355, 0.77984033, 0.71107663, 0.69945387,\n",
      "       0.69142545, 0.77166952, 0.77364826, 0.73579136, 0.77761923,\n",
      "       0.69541378, 0.77574862, 0.78053916, 0.78076268, 0.77921954,\n",
      "       0.73851776, 0.73746384, 0.77787944, 0.76872485, 0.76318115,\n",
      "       0.77757982, 0.7792807 , 0.77712669, 0.70944021, 0.78026024,\n",
      "       0.69775663, 0.78287328, 0.77964552, 0.77635509, 0.77868196,\n",
      "       0.67891599, 0.70790207, 0.77368017, 0.76423871, 0.75825424,\n",
      "       0.77668738, 0.7637437 , 0.71356063, 0.77700773, 0.78185074,\n",
      "       0.78004442, 0.75611873, 0.73993251, 0.74595661, 0.78253315,\n",
      "       0.7791254 , 0.77498774, 0.78324757, 0.78188998, 0.78255551,\n",
      "       0.76440688, 0.77862966, 0.77927384, 0.77313791, 0.72824405,\n",
      "       0.77577295, 0.78186014, 0.77794457, 0.68344332, 0.69211348,\n",
      "       0.78112767, 0.7428704 , 0.71254414, 0.67207393, 0.78078777,\n",
      "       0.78135838, 0.78019076, 0.72563366, 0.78244656, 0.70746373,\n",
      "       0.78034327, 0.77518973, 0.74625137, 0.77079977, 0.759979  ,\n",
      "       0.75524451, 0.78041561, 0.6822613 , 0.77682412, 0.78031207])] \n",
      "\n",
      "mean AUC :  0.7600917519315182\n",
      "All std:  [array([0.03930235, 0.02049775, 0.02338553, 0.02181065, 0.02251707,\n",
      "       0.0282265 , 0.022946  , 0.02033955, 0.01719956, 0.02148229,\n",
      "       0.0251071 , 0.02017443, 0.02338175, 0.02131724, 0.02067846,\n",
      "       0.01973332, 0.01899821, 0.02001683, 0.02634343, 0.02677432,\n",
      "       0.02063353, 0.01415814, 0.05235823, 0.02156545, 0.02114699,\n",
      "       0.04309953, 0.02123368, 0.01444912, 0.01589549, 0.01462708,\n",
      "       0.01747852, 0.01800073, 0.01943287, 0.01962444, 0.01512669,\n",
      "       0.02133125, 0.02973141, 0.02179126, 0.02227164, 0.01752435,\n",
      "       0.02309537, 0.02259993, 0.01630888, 0.01892986, 0.02229468,\n",
      "       0.01744141, 0.01491154, 0.02317851, 0.01971635, 0.02263222,\n",
      "       0.02162685, 0.02260841, 0.02160123, 0.03098793, 0.0211465 ,\n",
      "       0.02317922, 0.02064197, 0.01632061, 0.01993173, 0.01936352,\n",
      "       0.02048015, 0.0209973 , 0.01682769, 0.01225161, 0.02226029,\n",
      "       0.01883839, 0.02268801, 0.01633101, 0.02050176, 0.01683035,\n",
      "       0.02005954, 0.01835193, 0.02117452, 0.01984931, 0.02207621,\n",
      "       0.01532453, 0.02242467, 0.02159072, 0.01573695, 0.02540851,\n",
      "       0.01989009, 0.02279694, 0.0214454 , 0.03518636, 0.01964087,\n",
      "       0.02308883, 0.02072781, 0.02209142, 0.01544746, 0.0163528 ,\n",
      "       0.01883365, 0.02077541, 0.02921514, 0.02173016, 0.02139629,\n",
      "       0.0182928 , 0.02200539, 0.02265311, 0.0288061 , 0.03440104,\n",
      "       0.02258744, 0.01786915, 0.0224307 , 0.01543762, 0.05097922,\n",
      "       0.02863489, 0.02253608, 0.0213958 , 0.02247879, 0.0191119 ,\n",
      "       0.02100055, 0.01260324, 0.01994802, 0.01961164, 0.02314294,\n",
      "       0.02211182, 0.02247402, 0.0208131 , 0.01453919, 0.01544661,\n",
      "       0.02501478, 0.02163675, 0.01926296, 0.0227359 , 0.01461362,\n",
      "       0.01804433, 0.01441616, 0.01609505, 0.02037639, 0.01729765,\n",
      "       0.04009512, 0.02320279, 0.02122559, 0.02081699, 0.01844946,\n",
      "       0.01840231, 0.01464847, 0.01898383, 0.01752344, 0.01318243,\n",
      "       0.01840645, 0.01944466, 0.02210711, 0.01726294, 0.02196661,\n",
      "       0.03791493, 0.02123011, 0.02136204, 0.01872272, 0.01796686,\n",
      "       0.05112652, 0.03520365, 0.02156481, 0.01713645, 0.01918695,\n",
      "       0.02194142, 0.01921714, 0.02194455, 0.02170908, 0.02185988,\n",
      "       0.02295856, 0.01415757, 0.01985837, 0.0264199 , 0.02042514,\n",
      "       0.02277815, 0.02128426, 0.02163225, 0.02059215, 0.02179593,\n",
      "       0.02060369, 0.02153634, 0.02276832, 0.02040094, 0.01982956,\n",
      "       0.02130489, 0.02131117, 0.02360115, 0.02744999, 0.02940506,\n",
      "       0.02229676, 0.02038804, 0.02913629, 0.01288623, 0.0223256 ,\n",
      "       0.02179984, 0.02074511, 0.03364695, 0.02213112, 0.03009701,\n",
      "       0.01894874, 0.02190448, 0.01587509, 0.02224616, 0.01894614,\n",
      "       0.02426971, 0.02229799, 0.01811295, 0.02036223, 0.020833  ])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.7181818181818181, 'min_child_weight': 57, 'max_depth': 76, 'gamma': 1.8586565656565655, 'eta': 0.024911300260677886} \n",
      "\n",
      "Best index/iterasi :  9\n",
      "Best AUC : 0.7834514747569667 ( std: 0.021482285148471916 ) \n",
      "\n",
      "running time:  3875.9608085155487  detik. Dalam menit:  64.59934680859247  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:10:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  42 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.77750596, 0.75519139, 0.77241674, 0.69612405, 0.78214089,\n",
      "       0.76223235, 0.70944186, 0.76409848, 0.78089844, 0.78079866,\n",
      "       0.74525107, 0.75995309, 0.69394386, 0.78305618, 0.76736004,\n",
      "       0.78086916, 0.77541744, 0.77672329, 0.7291746 , 0.68988248,\n",
      "       0.78031182, 0.75285389, 0.70553621, 0.78036132, 0.7708314 ,\n",
      "       0.76474794, 0.78221947, 0.755035  , 0.74803708, 0.77777026,\n",
      "       0.77964325, 0.77961615, 0.77849432, 0.7715946 , 0.76785985,\n",
      "       0.77805698, 0.77469021, 0.77605654, 0.69488921, 0.7761425 ,\n",
      "       0.7671426 , 0.72253393, 0.7800005 , 0.6976546 , 0.76269549,\n",
      "       0.7526242 , 0.73224732, 0.69360362, 0.78044579, 0.77816184,\n",
      "       0.7773931 , 0.77960719, 0.7803086 , 0.67596477, 0.78253879,\n",
      "       0.76934065, 0.77968117, 0.77404411, 0.77925326, 0.7771128 ,\n",
      "       0.77104181, 0.7807611 , 0.7764401 , 0.78056022, 0.76047449,\n",
      "       0.65974036, 0.77573003, 0.77873264, 0.75357611, 0.78064122,\n",
      "       0.76726074, 0.77922202, 0.78051354, 0.76425176, 0.77973913,\n",
      "       0.77588114, 0.78192043, 0.78199366, 0.73044924, 0.68287055,\n",
      "       0.78212525, 0.77640384, 0.77930333, 0.69149866, 0.77523277,\n",
      "       0.78060476, 0.77746361, 0.78289612, 0.78163023, 0.77766643,\n",
      "       0.75577733, 0.67925067, 0.77702477, 0.78145924, 0.78084367,\n",
      "       0.78017436, 0.77803084, 0.74311891, 0.7745499 , 0.7738841 ,\n",
      "       0.71175899, 0.7831206 , 0.77597241, 0.77430863, 0.72417257,\n",
      "       0.77903892, 0.7641861 , 0.77406603, 0.73019514, 0.77374786,\n",
      "       0.77770906, 0.71629348, 0.770088  , 0.77847019, 0.76530122,\n",
      "       0.78009113, 0.78128427, 0.78001372, 0.78269306, 0.75216338,\n",
      "       0.77931652, 0.77282169, 0.77476063, 0.77300884, 0.7770173 ,\n",
      "       0.69670705, 0.75206947, 0.77965089, 0.70019802, 0.7171506 ,\n",
      "       0.77254534, 0.72134939, 0.77645951, 0.67303243, 0.7756357 ,\n",
      "       0.78026219, 0.74724214, 0.78214648, 0.78014478, 0.7808773 ,\n",
      "       0.77815538, 0.73547896, 0.7678165 , 0.78250516, 0.78223273,\n",
      "       0.77774098, 0.7527382 , 0.77084097, 0.77777177, 0.75665705,\n",
      "       0.65143629, 0.74702186, 0.78104949, 0.77617573, 0.77830665,\n",
      "       0.69555797, 0.68418115, 0.77997661, 0.75921376, 0.78049194,\n",
      "       0.74553589, 0.76414334, 0.76489061, 0.76083339, 0.77918632,\n",
      "       0.78250807, 0.71352346, 0.77821596, 0.77882305, 0.68278029,\n",
      "       0.77757497, 0.766293  , 0.77315406, 0.70767354, 0.77104966,\n",
      "       0.77742879, 0.74782012, 0.70241281, 0.77900722, 0.76951939,\n",
      "       0.70448829, 0.66562609, 0.78128052, 0.68546347, 0.73459576,\n",
      "       0.7791478 , 0.77730005, 0.76894303, 0.77946895, 0.78256892,\n",
      "       0.75356434, 0.6906757 , 0.77791635, 0.77787026, 0.7663621 ,\n",
      "       0.755095  , 0.77240285, 0.78223819, 0.69116916, 0.77218916])] \n",
      "\n",
      "mean AUC :  0.7585674081294633\n",
      "All std:  [array([0.02225721, 0.01991001, 0.01857721, 0.03504018, 0.02079086,\n",
      "       0.0231417 , 0.03706171, 0.02009974, 0.01977912, 0.02084353,\n",
      "       0.02064283, 0.01241747, 0.03165155, 0.02084585, 0.01657687,\n",
      "       0.02141427, 0.01618798, 0.01706478, 0.02333145, 0.02002327,\n",
      "       0.02044588, 0.01612814, 0.03693414, 0.02217237, 0.02119629,\n",
      "       0.01584064, 0.02174316, 0.01117263, 0.01590708, 0.01782816,\n",
      "       0.02262316, 0.01874521, 0.01717477, 0.02258405, 0.01666917,\n",
      "       0.02351391, 0.02207715, 0.02175529, 0.02670199, 0.02241572,\n",
      "       0.01714781, 0.03598017, 0.02337571, 0.02284125, 0.01549046,\n",
      "       0.01970639, 0.02568001, 0.04146211, 0.02175342, 0.01772662,\n",
      "       0.02341033, 0.02267283, 0.01947382, 0.04205323, 0.02152572,\n",
      "       0.0170753 , 0.02092583, 0.02450717, 0.02068499, 0.02193703,\n",
      "       0.01959168, 0.02091067, 0.02139351, 0.02072344, 0.01378545,\n",
      "       0.01527147, 0.02285325, 0.02037632, 0.01951472, 0.02055381,\n",
      "       0.01679809, 0.02227643, 0.02223354, 0.01569349, 0.01879041,\n",
      "       0.01839087, 0.02003438, 0.02228469, 0.02916721, 0.0193926 ,\n",
      "       0.01991886, 0.02028433, 0.02320272, 0.03161909, 0.02346896,\n",
      "       0.01948113, 0.02239245, 0.02162103, 0.02136737, 0.01998463,\n",
      "       0.01811618, 0.01542793, 0.02102194, 0.0219813 , 0.02251836,\n",
      "       0.02208021, 0.02311233, 0.02613918, 0.01754073, 0.01541106,\n",
      "       0.02952084, 0.02116604, 0.01820652, 0.01698803, 0.01586793,\n",
      "       0.02252269, 0.01408837, 0.01736447, 0.03211857, 0.01771645,\n",
      "       0.02323007, 0.01626545, 0.02085236, 0.02338954, 0.01555371,\n",
      "       0.02189486, 0.02030718, 0.02248193, 0.02162154, 0.01177767,\n",
      "       0.02177975, 0.0171653 , 0.01564857, 0.02265314, 0.02265841,\n",
      "       0.03346942, 0.01717156, 0.02280176, 0.02922162, 0.02674694,\n",
      "       0.02226361, 0.02238967, 0.02259889, 0.02279864, 0.02306623,\n",
      "       0.02242719, 0.02164637, 0.01993646, 0.02209551, 0.02101435,\n",
      "       0.02309273, 0.0234584 , 0.02035572, 0.0211544 , 0.02170021,\n",
      "       0.02256256, 0.01766877, 0.02163896, 0.02363551, 0.01664703,\n",
      "       0.01608697, 0.01970878, 0.02107561, 0.02080014, 0.02352931,\n",
      "       0.03841125, 0.03891942, 0.02239661, 0.01710898, 0.02199347,\n",
      "       0.02240138, 0.01565229, 0.01429527, 0.01807784, 0.02335949,\n",
      "       0.02101429, 0.01932172, 0.02171303, 0.02295696, 0.03790755,\n",
      "       0.02315266, 0.01506311, 0.01665175, 0.02176659, 0.02038794,\n",
      "       0.01950399, 0.0238173 , 0.02405402, 0.02319639, 0.02181574,\n",
      "       0.01777681, 0.01825264, 0.02223613, 0.023742  , 0.01567601,\n",
      "       0.02067152, 0.02056207, 0.01677255, 0.02217909, 0.02134609,\n",
      "       0.01551389, 0.0237947 , 0.02280234, 0.01764173, 0.0166129 ,\n",
      "       0.01952751, 0.01815512, 0.01951718, 0.02275793, 0.02227914])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.3090909090909091, 'min_child_weight': 16, 'max_depth': 21, 'gamma': 1.8990404040404039, 'eta': 0.012052609368708425} \n",
      "\n",
      "Best index/iterasi :  101\n",
      "Best AUC : 0.7831206028126143 ( std: 0.02116604491212642 ) \n",
      "\n",
      "running time:  4431.668111562729  detik. Dalam menit:  73.86113519271215  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:24:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  52 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.73132094, 0.78204907, 0.78102537, 0.77638823, 0.77800673,\n",
      "       0.77317051, 0.77890274, 0.75266476, 0.7831755 , 0.68560086,\n",
      "       0.78198747, 0.77958995, 0.70589879, 0.67123399, 0.78019451,\n",
      "       0.77680711, 0.78244161, 0.72378032, 0.77202856, 0.7436139 ,\n",
      "       0.73157748, 0.76572353, 0.73296723, 0.77841275, 0.76313983,\n",
      "       0.74941594, 0.771852  , 0.68611322, 0.7668149 , 0.77421552,\n",
      "       0.7535324 , 0.74815846, 0.77974556, 0.7698002 , 0.78137974,\n",
      "       0.76999904, 0.78175397, 0.78058708, 0.78151638, 0.78012195,\n",
      "       0.74493315, 0.77246362, 0.78268856, 0.7823416 , 0.77270499,\n",
      "       0.77520624, 0.68544442, 0.77764728, 0.70218194, 0.7389594 ,\n",
      "       0.78166831, 0.78120544, 0.75823275, 0.71661749, 0.78070805,\n",
      "       0.7790195 , 0.77648348, 0.74998321, 0.78264393, 0.76047603,\n",
      "       0.72831786, 0.70482481, 0.75562638, 0.77764803, 0.76668945,\n",
      "       0.75450914, 0.78207715, 0.7750252 , 0.74210173, 0.78179738,\n",
      "       0.77664165, 0.75979138, 0.7471425 , 0.77508829, 0.68329454,\n",
      "       0.78132048, 0.78167483, 0.77801564, 0.77868681, 0.70090506,\n",
      "       0.78165863, 0.77542844, 0.73450015, 0.77886601, 0.77888684,\n",
      "       0.77801777, 0.76454238, 0.71231274, 0.78201702, 0.75763312,\n",
      "       0.77788165, 0.77858879, 0.77575777, 0.68027761, 0.78101975,\n",
      "       0.78052659, 0.77273412, 0.74826591, 0.6753945 , 0.77587911,\n",
      "       0.77820693, 0.78117932, 0.78055833, 0.73721977, 0.77939211,\n",
      "       0.74908205, 0.77898557, 0.77841155, 0.77493616, 0.78204393,\n",
      "       0.68859293, 0.71092465, 0.75805822, 0.7770755 , 0.75373114,\n",
      "       0.78247687, 0.77596583, 0.77359621, 0.69257818, 0.71923269,\n",
      "       0.77711825, 0.77756437, 0.77676159, 0.7812328 , 0.76901874,\n",
      "       0.762902  , 0.77140406, 0.76396438, 0.77044049, 0.7195869 ,\n",
      "       0.78172651, 0.7789332 , 0.78200418, 0.77910454, 0.78176254,\n",
      "       0.76516154, 0.73251493, 0.71668053, 0.78013819, 0.7608645 ,\n",
      "       0.77906994, 0.77413824, 0.78242688, 0.75393002, 0.78115814,\n",
      "       0.75631506, 0.66250849, 0.77673024, 0.76362092, 0.73879086,\n",
      "       0.77178255, 0.69436067, 0.7732161 , 0.77788225, 0.7749068 ,\n",
      "       0.75986787, 0.70850037, 0.69912359, 0.77146649, 0.73918581,\n",
      "       0.68564767, 0.76873838, 0.70374515, 0.768275  , 0.69370672,\n",
      "       0.72272698, 0.77199788, 0.76725244, 0.76319313, 0.78033496,\n",
      "       0.78134916, 0.69238092, 0.75972727, 0.78226766, 0.77886551,\n",
      "       0.66359031, 0.77753351, 0.74338663, 0.77105053, 0.70456667,\n",
      "       0.71554095, 0.78239141, 0.77933512, 0.7082766 , 0.78210833,\n",
      "       0.71674843, 0.70540801, 0.75611614, 0.77057241, 0.78182352,\n",
      "       0.77418657, 0.7336381 , 0.78340385, 0.77899413, 0.77295817,\n",
      "       0.77731878, 0.77235911, 0.77332879, 0.78298909, 0.76081874])] \n",
      "\n",
      "mean AUC :  0.7575922542969868\n",
      "All std:  [array([0.01643658, 0.02086921, 0.02140404, 0.02088775, 0.01988396,\n",
      "       0.02189932, 0.02313479, 0.01984235, 0.02153479, 0.01945605,\n",
      "       0.02160238, 0.02041655, 0.0185015 , 0.01739934, 0.02207663,\n",
      "       0.023178  , 0.02063313, 0.01489725, 0.02202744, 0.02168959,\n",
      "       0.03451316, 0.01503595, 0.01520121, 0.02229659, 0.01422994,\n",
      "       0.02458941, 0.01834593, 0.02193146, 0.01786881, 0.02246024,\n",
      "       0.01977887, 0.01801991, 0.02136885, 0.01656378, 0.02142966,\n",
      "       0.01798859, 0.01952592, 0.0221224 , 0.02256943, 0.02045577,\n",
      "       0.02157114, 0.01392456, 0.02200429, 0.02029554, 0.02271758,\n",
      "       0.01926909, 0.04173   , 0.02351123, 0.03027568, 0.03031406,\n",
      "       0.02212016, 0.02131341, 0.01861898, 0.03853991, 0.02247369,\n",
      "       0.02269369, 0.0191667 , 0.01884169, 0.02085338, 0.01676353,\n",
      "       0.01738194, 0.02672146, 0.01578258, 0.0192708 , 0.01716845,\n",
      "       0.01833204, 0.01995575, 0.01949377, 0.01908545, 0.02134708,\n",
      "       0.01681003, 0.01961548, 0.01779303, 0.01774754, 0.01030037,\n",
      "       0.02017693, 0.02208986, 0.01818634, 0.02287988, 0.01570869,\n",
      "       0.02125388, 0.01904546, 0.01758922, 0.01864098, 0.0212291 ,\n",
      "       0.02131043, 0.01440673, 0.03770802, 0.02195598, 0.01842166,\n",
      "       0.02316337, 0.02285488, 0.01886393, 0.02512058, 0.02201751,\n",
      "       0.01849444, 0.01622672, 0.01758415, 0.01759699, 0.02109397,\n",
      "       0.02140271, 0.02107768, 0.02138059, 0.02382631, 0.02276798,\n",
      "       0.02017019, 0.01966186, 0.01786626, 0.02049464, 0.02234525,\n",
      "       0.04154303, 0.01172465, 0.02070511, 0.01680838, 0.01978161,\n",
      "       0.02156182, 0.02307972, 0.02116923, 0.03212206, 0.02546928,\n",
      "       0.02234273, 0.0229389 , 0.02383107, 0.02236073, 0.01523827,\n",
      "       0.02061561, 0.02057954, 0.01759629, 0.01823203, 0.03662221,\n",
      "       0.01917888, 0.02272275, 0.02169441, 0.01838364, 0.02258959,\n",
      "       0.01583892, 0.01477226, 0.02863399, 0.02169595, 0.01326626,\n",
      "       0.02077087, 0.01879079, 0.01987966, 0.01674851, 0.02150823,\n",
      "       0.01994201, 0.01687068, 0.01951147, 0.01466226, 0.02908512,\n",
      "       0.01876026, 0.02835129, 0.02173334, 0.02311787, 0.02144662,\n",
      "       0.01481929, 0.00721354, 0.03312607, 0.02227503, 0.01628364,\n",
      "       0.04031039, 0.01978081, 0.01574238, 0.01515747, 0.02791203,\n",
      "       0.04073344, 0.02117812, 0.01644738, 0.01763551, 0.02287402,\n",
      "       0.02066281, 0.0320297 , 0.02209729, 0.0212233 , 0.02265066,\n",
      "       0.01597235, 0.02015055, 0.01933844, 0.0146659 , 0.02604954,\n",
      "       0.01587029, 0.02209901, 0.02254043, 0.0236496 , 0.02157141,\n",
      "       0.02742161, 0.01682963, 0.01954911, 0.02079081, 0.02202723,\n",
      "       0.02306374, 0.01894664, 0.02141451, 0.02320637, 0.01647617,\n",
      "       0.01908719, 0.01708653, 0.01571939, 0.02159955, 0.01982448])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.4363636363636364, 'min_child_weight': 38, 'max_depth': 8, 'gamma': 1.1317474747474745, 'eta': 0.02245697995539774} \n",
      "\n",
      "Best index/iterasi :  192\n",
      "Best AUC : 0.783403853542169 ( std: 0.021414506709395736 ) \n",
      "\n",
      "running time:  4452.36111998558  detik. Dalam menit:  74.20601866642635  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:44:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  62 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.74765484, 0.75806818, 0.72433823, 0.74182632, 0.78211072,\n",
      "       0.78050472, 0.69004669, 0.77677169, 0.73211586, 0.75170257,\n",
      "       0.78238531, 0.78077015, 0.77670965, 0.74745262, 0.77907079,\n",
      "       0.77992023, 0.776625  , 0.77398819, 0.7758458 , 0.71972491,\n",
      "       0.78109904, 0.78020758, 0.77860348, 0.7760124 , 0.77943148,\n",
      "       0.74538237, 0.77634161, 0.69500029, 0.77906026, 0.76340971,\n",
      "       0.77997844, 0.7497267 , 0.7797289 , 0.69820866, 0.76954368,\n",
      "       0.7754534 , 0.75386584, 0.78139114, 0.70763038, 0.77918093,\n",
      "       0.77255375, 0.73861183, 0.78094048, 0.7800057 , 0.77987652,\n",
      "       0.77993783, 0.6725196 , 0.77843287, 0.70310545, 0.78084521,\n",
      "       0.7708396 , 0.68945401, 0.77612077, 0.76804758, 0.78191438,\n",
      "       0.78089217, 0.73631938, 0.77120524, 0.73850752, 0.72801203,\n",
      "       0.77861453, 0.77946202, 0.77816617, 0.74954647, 0.77785211,\n",
      "       0.77665632, 0.77887555, 0.78067913, 0.77519922, 0.69693245,\n",
      "       0.78188955, 0.77765441, 0.74773004, 0.74669307, 0.69900883,\n",
      "       0.78230864, 0.69190034, 0.78191715, 0.78224102, 0.77936527,\n",
      "       0.71736374, 0.72710436, 0.78199665, 0.78333341, 0.78257943,\n",
      "       0.75758642, 0.72081434, 0.65761312, 0.77984916, 0.73046559,\n",
      "       0.77729624, 0.78187692, 0.77857694, 0.78086593, 0.69632546,\n",
      "       0.7823615 , 0.78296979, 0.77816639, 0.76524911, 0.7794932 ,\n",
      "       0.69878943, 0.77627124, 0.78039704, 0.76947742, 0.77640802,\n",
      "       0.78093134, 0.69853522, 0.78152747, 0.7266963 , 0.75471667,\n",
      "       0.77739229, 0.78058259, 0.76263154, 0.77886483, 0.76332069,\n",
      "       0.77125726, 0.77103072, 0.77980956, 0.78100642, 0.73787232,\n",
      "       0.77509366, 0.73476019, 0.70415873, 0.71195446, 0.70472523,\n",
      "       0.6655542 , 0.77866894, 0.76922734, 0.78323958, 0.77545599,\n",
      "       0.77396465, 0.77419626, 0.75582331, 0.7794581 , 0.68643857,\n",
      "       0.76841258, 0.71869855, 0.77902226, 0.7799532 , 0.77842674,\n",
      "       0.70263185, 0.751201  , 0.77783182, 0.68461621, 0.78157728,\n",
      "       0.78163991, 0.75193536, 0.76537208, 0.77864532, 0.7809943 ,\n",
      "       0.75074988, 0.75357965, 0.76060457, 0.78135629, 0.77697641,\n",
      "       0.75714793, 0.77596824, 0.78139204, 0.77985976, 0.71127627,\n",
      "       0.78000695, 0.75844626, 0.78071425, 0.78044545, 0.72633186,\n",
      "       0.77228407, 0.78090555, 0.7476032 , 0.78192422, 0.78215541,\n",
      "       0.78055713, 0.78086682, 0.72201089, 0.76962422, 0.77792193,\n",
      "       0.77825742, 0.78173086, 0.78019029, 0.75894315, 0.77842245,\n",
      "       0.7530047 , 0.77365575, 0.7772518 , 0.77626723, 0.77818323,\n",
      "       0.78236182, 0.77598617, 0.78079738, 0.77624435, 0.7561798 ,\n",
      "       0.77501058, 0.7735285 , 0.67607526, 0.69728037, 0.70251769,\n",
      "       0.64561652, 0.73308763, 0.78118876, 0.77480953, 0.7602355 ])] \n",
      "\n",
      "mean AUC :  0.758891713500421\n",
      "All std:  [array([0.01231483, 0.01691665, 0.01378615, 0.02311797, 0.02143064,\n",
      "       0.02084313, 0.02777117, 0.01998522, 0.02730398, 0.01613898,\n",
      "       0.02206508, 0.02274338, 0.02372136, 0.01841368, 0.02283671,\n",
      "       0.02260604, 0.01987528, 0.02213956, 0.02155096, 0.02535551,\n",
      "       0.02121246, 0.02155191, 0.02050129, 0.02444424, 0.02262614,\n",
      "       0.01489432, 0.02029756, 0.02294094, 0.02251079, 0.01541936,\n",
      "       0.02052254, 0.01390777, 0.02316672, 0.03171051, 0.01755441,\n",
      "       0.0225629 , 0.02342075, 0.02054904, 0.04168088, 0.02333617,\n",
      "       0.01797674, 0.01896307, 0.02026994, 0.02317654, 0.02300306,\n",
      "       0.023635  , 0.01436462, 0.02216758, 0.02427753, 0.02210528,\n",
      "       0.02186221, 0.0216814 , 0.01676812, 0.01961257, 0.02110056,\n",
      "       0.02238215, 0.02241887, 0.0221987 , 0.02068864, 0.02232529,\n",
      "       0.01772878, 0.0227036 , 0.0187156 , 0.01296597, 0.0203407 ,\n",
      "       0.02002008, 0.01801825, 0.02255153, 0.02169356, 0.01754905,\n",
      "       0.02166106, 0.02158633, 0.01855832, 0.01476915, 0.01314826,\n",
      "       0.02173943, 0.02504745, 0.02209834, 0.02208412, 0.02094168,\n",
      "       0.01927757, 0.0343336 , 0.02210908, 0.02109364, 0.02036752,\n",
      "       0.0140352 , 0.02649958, 0.02073756, 0.02041528, 0.01572365,\n",
      "       0.01805398, 0.02152332, 0.02329467, 0.02228509, 0.02057797,\n",
      "       0.02083698, 0.02037766, 0.01877223, 0.01938049, 0.02314428,\n",
      "       0.03592981, 0.02308881, 0.02078089, 0.02187408, 0.02287544,\n",
      "       0.02110327, 0.04498225, 0.01979188, 0.0292429 , 0.01686021,\n",
      "       0.0228477 , 0.02244738, 0.01583306, 0.02304682, 0.02110169,\n",
      "       0.02078284, 0.02106797, 0.0206857 , 0.02122052, 0.01983076,\n",
      "       0.01986539, 0.02942955, 0.0344824 , 0.01688689, 0.01522419,\n",
      "       0.01789944, 0.02333104, 0.01882464, 0.02183708, 0.01974125,\n",
      "       0.02140274, 0.01883729, 0.01949368, 0.022284  , 0.01628593,\n",
      "       0.01523316, 0.01646251, 0.01989784, 0.02287244, 0.02200864,\n",
      "       0.02966315, 0.0188137 , 0.020699  , 0.04684782, 0.02085504,\n",
      "       0.0215427 , 0.01476659, 0.01905415, 0.02277189, 0.02081827,\n",
      "       0.02081152, 0.02176584, 0.01975081, 0.0223507 , 0.02321757,\n",
      "       0.01451519, 0.02185483, 0.01972093, 0.02265   , 0.03096665,\n",
      "       0.02242919, 0.01556928, 0.02023927, 0.02205847, 0.01314011,\n",
      "       0.02255789, 0.01922004, 0.02723902, 0.02032046, 0.02067494,\n",
      "       0.02115996, 0.02202213, 0.01814712, 0.01433832, 0.01940093,\n",
      "       0.02207503, 0.01992797, 0.02239984, 0.01901925, 0.02258485,\n",
      "       0.0190718 , 0.02107768, 0.01689886, 0.02325959, 0.02184511,\n",
      "       0.02093109, 0.02256325, 0.02260446, 0.02113933, 0.01999199,\n",
      "       0.01597561, 0.01774337, 0.05127082, 0.01319735, 0.02709031,\n",
      "       0.0104    , 0.02571662, 0.02153032, 0.0159651 , 0.01461675])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.3, 'min_child_weight': 20, 'max_depth': 84, 'gamma': 1.798080808080808, 'eta': 0.019023011886689447} \n",
      "\n",
      "Best index/iterasi :  83\n",
      "Best AUC : 0.7833334103484685 ( std: 0.021093639186703577 ) \n",
      "\n",
      "running time:  4771.977291345596  detik. Dalam menit:  79.53295485575994  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:03:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  72 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.77081145, 0.75925192, 0.77978937, 0.78190093, 0.73883409,\n",
      "       0.7813225 , 0.7127086 , 0.77502615, 0.78179304, 0.78225973,\n",
      "       0.7799047 , 0.70887688, 0.78123112, 0.76850095, 0.74928114,\n",
      "       0.77651527, 0.75890207, 0.77835268, 0.77977207, 0.78059653,\n",
      "       0.77740562, 0.77339314, 0.77047598, 0.75309061, 0.75584319,\n",
      "       0.76810346, 0.78007907, 0.78202889, 0.78030305, 0.78101626,\n",
      "       0.77334035, 0.76445086, 0.78159482, 0.77823836, 0.76855494,\n",
      "       0.77838295, 0.77625808, 0.77925474, 0.77867027, 0.68637033,\n",
      "       0.77899211, 0.7787463 , 0.77875656, 0.78013751, 0.77765998,\n",
      "       0.78304133, 0.77810148, 0.77340319, 0.78093485, 0.7311593 ,\n",
      "       0.77875257, 0.75091665, 0.74144976, 0.780333  , 0.76728983,\n",
      "       0.78241023, 0.77176476, 0.77173523, 0.77733753, 0.77832647,\n",
      "       0.77682322, 0.77988698, 0.78283108, 0.76635635, 0.7586114 ,\n",
      "       0.78009439, 0.78163348, 0.7704312 , 0.70949917, 0.77805352,\n",
      "       0.78283308, 0.7810989 , 0.74622598, 0.7818391 , 0.75167005,\n",
      "       0.77859303, 0.78061062, 0.77513707, 0.77010185, 0.7797457 ,\n",
      "       0.73958234, 0.77848247, 0.69155207, 0.77643889, 0.73300745,\n",
      "       0.70523879, 0.73422129, 0.77940562, 0.78150925, 0.77247383,\n",
      "       0.77878206, 0.78267608, 0.78127838, 0.76524982, 0.77906752,\n",
      "       0.78171871, 0.73011818, 0.70486974, 0.76457728, 0.77848138,\n",
      "       0.77224711, 0.74138333, 0.7826445 , 0.77325514, 0.78201132,\n",
      "       0.70430222, 0.77866023, 0.68299239, 0.77719602, 0.77541781,\n",
      "       0.76286046, 0.7817969 , 0.74808316, 0.77866232, 0.75673852,\n",
      "       0.78210706, 0.71804657, 0.77976751, 0.69470078, 0.78024173,\n",
      "       0.73176276, 0.77782379, 0.77965304, 0.76151045, 0.76269537,\n",
      "       0.78163019, 0.77954478, 0.77411913, 0.7433554 , 0.77520962,\n",
      "       0.77744277, 0.7417113 , 0.77979117, 0.69119898, 0.78079992,\n",
      "       0.77763107, 0.77943585, 0.77932693, 0.78180897, 0.69349864,\n",
      "       0.78007716, 0.76996393, 0.77683527, 0.77516239, 0.76848448,\n",
      "       0.78135488, 0.77747265, 0.73533404, 0.78045656, 0.77459187,\n",
      "       0.7756393 , 0.77481821, 0.71418909, 0.78228229, 0.74618053,\n",
      "       0.77235785, 0.78313813, 0.77795522, 0.67684512, 0.78139002,\n",
      "       0.78066548, 0.7763173 , 0.7821833 , 0.78203345, 0.77201559,\n",
      "       0.71430896, 0.70018471, 0.78179274, 0.74923137, 0.78277999,\n",
      "       0.70701645, 0.78058274, 0.77012514, 0.77898557, 0.67501846,\n",
      "       0.78212598, 0.72884081, 0.78211148, 0.78316099, 0.77189545,\n",
      "       0.67617215, 0.77342734, 0.77401417, 0.7104442 , 0.77525905,\n",
      "       0.77987255, 0.68509654, 0.77692404, 0.78129862, 0.64951279,\n",
      "       0.69640349, 0.78099283, 0.78240899, 0.75638755, 0.73613418,\n",
      "       0.76524743, 0.7569267 , 0.68830067, 0.77699961, 0.70754099])] \n",
      "\n",
      "mean AUC :  0.7621143811204726\n",
      "All std:  [array([0.01634687, 0.01993927, 0.02219214, 0.02209065, 0.01878264,\n",
      "       0.02012575, 0.03885354, 0.01934922, 0.0215699 , 0.0204168 ,\n",
      "       0.02155979, 0.02013017, 0.0222735 , 0.01525908, 0.01749909,\n",
      "       0.0214041 , 0.01919553, 0.02384377, 0.02269083, 0.02065932,\n",
      "       0.02205397, 0.01763438, 0.0207676 , 0.01718904, 0.01727686,\n",
      "       0.01905863, 0.02040507, 0.02067519, 0.02240486, 0.02228681,\n",
      "       0.0159132 , 0.01771123, 0.01842717, 0.02006736, 0.01529471,\n",
      "       0.02209336, 0.02162119, 0.02331601, 0.02242605, 0.02906408,\n",
      "       0.01681276, 0.01893439, 0.02287886, 0.01822399, 0.01880347,\n",
      "       0.02172034, 0.01750516, 0.01907695, 0.02218333, 0.03104779,\n",
      "       0.02289095, 0.01614991, 0.0269851 , 0.02217545, 0.01506306,\n",
      "       0.02019038, 0.01529843, 0.02091538, 0.02262906, 0.01897103,\n",
      "       0.02194102, 0.02016583, 0.02134457, 0.01569852, 0.01677391,\n",
      "       0.02312072, 0.02214161, 0.02216651, 0.0149148 , 0.0167417 ,\n",
      "       0.02167023, 0.02190107, 0.02594778, 0.02180914, 0.01885242,\n",
      "       0.02240584, 0.02211984, 0.02248048, 0.01912508, 0.02232254,\n",
      "       0.01367013, 0.02301705, 0.02308837, 0.02306657, 0.01500394,\n",
      "       0.01483654, 0.02792859, 0.02169133, 0.02022654, 0.0178393 ,\n",
      "       0.02317994, 0.02158319, 0.02017213, 0.01555199, 0.02103883,\n",
      "       0.02169811, 0.03610448, 0.02996111, 0.01845191, 0.02251455,\n",
      "       0.02123144, 0.01643962, 0.02051433, 0.01931107, 0.02118107,\n",
      "       0.0351231 , 0.01958002, 0.02912927, 0.02380344, 0.02066416,\n",
      "       0.0174967 , 0.02208061, 0.01535578, 0.01900114, 0.02053329,\n",
      "       0.02169831, 0.01916073, 0.02264919, 0.03901374, 0.02165251,\n",
      "       0.03465623, 0.02155022, 0.02251021, 0.01330246, 0.02001407,\n",
      "       0.02034714, 0.02309264, 0.02404695, 0.01215859, 0.01698169,\n",
      "       0.02302498, 0.02355461, 0.02087316, 0.03702432, 0.02216976,\n",
      "       0.02203466, 0.01973826, 0.01826811, 0.02170106, 0.04151603,\n",
      "       0.01889165, 0.01948206, 0.01982751, 0.02061347, 0.01599868,\n",
      "       0.02240529, 0.01890633, 0.01897189, 0.02229633, 0.0201869 ,\n",
      "       0.01663234, 0.02155009, 0.01211723, 0.01986558, 0.01342694,\n",
      "       0.01624093, 0.02083811, 0.01736246, 0.03509429, 0.0213149 ,\n",
      "       0.02225722, 0.01909248, 0.02153101, 0.01913848, 0.01566614,\n",
      "       0.01002237, 0.01058029, 0.02209478, 0.02338822, 0.02150636,\n",
      "       0.01851426, 0.02045001, 0.01482657, 0.02299124, 0.0328176 ,\n",
      "       0.02029228, 0.02408681, 0.02122381, 0.0216899 , 0.01873599,\n",
      "       0.02300284, 0.01902384, 0.01793221, 0.03174429, 0.02122461,\n",
      "       0.02222468, 0.01370214, 0.01674847, 0.02153117, 0.01831269,\n",
      "       0.01113446, 0.0222489 , 0.02190061, 0.01626576, 0.01388464,\n",
      "       0.02026991, 0.01948882, 0.03252433, 0.01775776, 0.03314891])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.7454545454545454, 'min_child_weight': 65, 'max_depth': 46, 'gamma': 0.727909090909091, 'eta': 0.021248453524988827} \n",
      "\n",
      "Best index/iterasi :  178\n",
      "Best AUC : 0.7831609939220592 ( std: 0.021689900419901646 ) \n",
      "\n",
      "running time:  4774.044758558273  detik. Dalam menit:  79.56741264263789  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-16113ea06dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_credit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_credit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper_space_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterasi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Seed: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint_hasil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterasi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-07659aed5790>\u001b[0m in \u001b[0;36mrandom_search\u001b[0;34m(X, y, model, parameter, iterasi, evalscore, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m                    verbose= 1)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbest_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dataset 2 \n",
    "\n",
    "seeds=[1,12,22,32,42,52,62,72]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=random_search(X_credit,y_credit,model_x,hyper_space_2,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  82 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.77843551, 0.75046759, 0.77912647, 0.67789192, 0.77918119,\n",
      "       0.70365757, 0.78018064, 0.76568575, 0.77856038, 0.76724351,\n",
      "       0.75762449, 0.77389159, 0.78123732, 0.72522634, 0.7751078 ,\n",
      "       0.77532205, 0.76118605, 0.78186979, 0.77867673, 0.78206004,\n",
      "       0.77995814, 0.78243203, 0.72967321, 0.77643713, 0.7590562 ,\n",
      "       0.7757463 , 0.77962827, 0.78224484, 0.78294354, 0.77949818,\n",
      "       0.77870656, 0.75113977, 0.77332071, 0.74901566, 0.71354296,\n",
      "       0.78271807, 0.78301125, 0.68843333, 0.77418735, 0.76481422,\n",
      "       0.77838522, 0.72376558, 0.77130329, 0.72568715, 0.78073792,\n",
      "       0.77323951, 0.77943057, 0.7328431 , 0.78148261, 0.76903555,\n",
      "       0.7790542 , 0.77706477, 0.77841636, 0.77344818, 0.77305492,\n",
      "       0.74492499, 0.78125012, 0.74954575, 0.78195989, 0.75988491,\n",
      "       0.77656387, 0.76249562, 0.78142124, 0.78294516, 0.78208002,\n",
      "       0.7101896 , 0.73096412, 0.71318665, 0.77219506, 0.69091518,\n",
      "       0.77422276, 0.78017829, 0.77665052, 0.71227209, 0.77640169,\n",
      "       0.78044651, 0.77320006, 0.75143512, 0.77202338, 0.78188428,\n",
      "       0.68923717, 0.7725174 , 0.78210684, 0.7816738 , 0.77958894,\n",
      "       0.69436449, 0.77890813, 0.7771623 , 0.7748215 , 0.78166686,\n",
      "       0.75687649, 0.70554918, 0.78279973, 0.78245795, 0.78224555,\n",
      "       0.76321168, 0.78046928, 0.75826561, 0.77763628, 0.73192782,\n",
      "       0.75018141, 0.78314823, 0.73950273, 0.77857189, 0.68186881,\n",
      "       0.77651893, 0.77342445, 0.69502921, 0.77792106, 0.7562916 ,\n",
      "       0.77702667, 0.77573257, 0.68831019, 0.7767285 , 0.71583358,\n",
      "       0.78086798, 0.70553355, 0.7532444 , 0.78106182, 0.76360351,\n",
      "       0.78063696, 0.76701579, 0.69713793, 0.78059481, 0.77684563,\n",
      "       0.75238479, 0.76494726, 0.77925713, 0.68281506, 0.78289441,\n",
      "       0.75840633, 0.77792048, 0.71422826, 0.78051929, 0.77740943,\n",
      "       0.77613211, 0.76125971, 0.77889249, 0.70518243, 0.74482128,\n",
      "       0.77762306, 0.75443444, 0.77862904, 0.77601454, 0.70090506,\n",
      "       0.78278716, 0.73712285, 0.73079327, 0.67259199, 0.68274576,\n",
      "       0.74261626, 0.77947905, 0.77479223, 0.77997979, 0.77313539,\n",
      "       0.77258507, 0.75806105, 0.72461899, 0.76903844, 0.78079218,\n",
      "       0.72768715, 0.75118001, 0.75632721, 0.77842107, 0.77802821,\n",
      "       0.70570869, 0.78030777, 0.77551852, 0.78129175, 0.77908824,\n",
      "       0.76926383, 0.7758764 , 0.7816047 , 0.7791043 , 0.78073225,\n",
      "       0.78168566, 0.77501088, 0.78078319, 0.78009645, 0.70616001,\n",
      "       0.68403381, 0.75334925, 0.7782071 , 0.68704398, 0.76283075,\n",
      "       0.68458332, 0.77467321, 0.78239643, 0.77549595, 0.72454027,\n",
      "       0.75788772, 0.78088073, 0.67982897, 0.77656005, 0.71685622,\n",
      "       0.7692683 , 0.76284696, 0.77951732, 0.77474636, 0.77306983])] \n",
      "\n",
      "mean AUC :  0.758948771770407\n",
      "All std:  [array([0.02335817, 0.01491721, 0.01909291, 0.03132844, 0.02138683,\n",
      "       0.03403412, 0.0212253 , 0.01757175, 0.02256978, 0.0157384 ,\n",
      "       0.01718577, 0.02163102, 0.02102179, 0.02548417, 0.01759481,\n",
      "       0.02093389, 0.02019658, 0.02002469, 0.01791999, 0.02232336,\n",
      "       0.0225966 , 0.02165586, 0.01739013, 0.01893064, 0.01448434,\n",
      "       0.01977393, 0.02249813, 0.02119896, 0.02173243, 0.02257681,\n",
      "       0.02156422, 0.01820629, 0.01522214, 0.03377581, 0.01137523,\n",
      "       0.02208954, 0.02152485, 0.03294657, 0.0229884 , 0.01963322,\n",
      "       0.02351499, 0.01610137, 0.02140491, 0.01277835, 0.02267874,\n",
      "       0.01549911, 0.02271883, 0.01708805, 0.02189255, 0.01560131,\n",
      "       0.02291775, 0.01817839, 0.02114449, 0.01833571, 0.02109318,\n",
      "       0.02076354, 0.02263182, 0.02396103, 0.02145357, 0.01980077,\n",
      "       0.01742192, 0.01514287, 0.02185365, 0.02153769, 0.0203802 ,\n",
      "       0.04656976, 0.01386039, 0.03595568, 0.02063449, 0.01629025,\n",
      "       0.01792856, 0.01868986, 0.01982229, 0.03464395, 0.01922527,\n",
      "       0.02220499, 0.01838194, 0.01726009, 0.01590386, 0.02235989,\n",
      "       0.03994669, 0.018765  , 0.02057267, 0.02163063, 0.02293356,\n",
      "       0.02621849, 0.02119811, 0.02108283, 0.0181565 , 0.02151995,\n",
      "       0.01676089, 0.04186129, 0.02111287, 0.02212326, 0.02092455,\n",
      "       0.0188796 , 0.02032774, 0.01764522, 0.02345972, 0.02081104,\n",
      "       0.01343699, 0.0209174 , 0.02488062, 0.02131622, 0.01696478,\n",
      "       0.02204945, 0.01612639, 0.03998091, 0.02273651, 0.02001792,\n",
      "       0.02029685, 0.01898661, 0.03473201, 0.02266586, 0.0185457 ,\n",
      "       0.02017902, 0.0391017 , 0.02047599, 0.02146975, 0.01553051,\n",
      "       0.02227579, 0.01758168, 0.03890965, 0.02248502, 0.01689134,\n",
      "       0.01252099, 0.01741604, 0.02056816, 0.04507814, 0.02199509,\n",
      "       0.01976407, 0.02200065, 0.0170455 , 0.02222696, 0.02282138,\n",
      "       0.0205456 , 0.01735039, 0.01940834, 0.04451462, 0.01227622,\n",
      "       0.02349329, 0.01779357, 0.02371322, 0.02372931, 0.01570869,\n",
      "       0.02210936, 0.01138528, 0.01403713, 0.01443255, 0.01413296,\n",
      "       0.01738709, 0.02042776, 0.02141269, 0.0228488 , 0.01518543,\n",
      "       0.01563256, 0.0187349 , 0.03543885, 0.01574232, 0.020373  ,\n",
      "       0.02210284, 0.01878505, 0.01451343, 0.01800036, 0.02203041,\n",
      "       0.01873553, 0.02193905, 0.02107963, 0.02236076, 0.02283603,\n",
      "       0.01827563, 0.0244716 , 0.02145055, 0.02219935, 0.02102083,\n",
      "       0.02195658, 0.0165921 , 0.02246184, 0.02089861, 0.03097726,\n",
      "       0.00532214, 0.01480439, 0.01811152, 0.03511588, 0.01549442,\n",
      "       0.04354007, 0.02092107, 0.01994854, 0.01886283, 0.01882626,\n",
      "       0.02446746, 0.0224905 , 0.03457571, 0.02140137, 0.01987471,\n",
      "       0.01620761, 0.01572246, 0.02112675, 0.01902283, 0.02192404])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.7, 'min_child_weight': 86, 'max_depth': 79, 'gamma': 0.9096363636363636, 'eta': 0.044529585099426554} \n",
      "\n",
      "Best index/iterasi :  101\n",
      "Best AUC : 0.7831482297913993 ( std: 0.02091740289226582 ) \n",
      "\n",
      "running time:  3816.7054584026337  detik. Dalam menit:  63.6117576400439  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:38:32] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  92 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.77523144, 0.78055466, 0.77140819, 0.6772358 , 0.77686658,\n",
      "       0.77829374, 0.77965438, 0.74387088, 0.78273471, 0.76344215,\n",
      "       0.78097812, 0.76512188, 0.77144341, 0.77609935, 0.77809367,\n",
      "       0.66298077, 0.78076987, 0.78244373, 0.65702003, 0.78054291,\n",
      "       0.74823205, 0.73318579, 0.76577636, 0.73776309, 0.77582275,\n",
      "       0.76752194, 0.74074785, 0.77756771, 0.73815684, 0.77792044,\n",
      "       0.72921199, 0.77987388, 0.78118029, 0.77853803, 0.71583843,\n",
      "       0.74876505, 0.69837972, 0.77873338, 0.70438599, 0.77729547,\n",
      "       0.74382192, 0.77968561, 0.75288315, 0.77700603, 0.68902358,\n",
      "       0.77589469, 0.77853425, 0.6757981 , 0.68849513, 0.77806275,\n",
      "       0.76091063, 0.70324974, 0.78215878, 0.77825507, 0.7573892 ,\n",
      "       0.74535807, 0.78035103, 0.77386561, 0.77869163, 0.76885456,\n",
      "       0.77540438, 0.78258209, 0.74968287, 0.7760438 , 0.7787334 ,\n",
      "       0.68079912, 0.77998026, 0.77323589, 0.78252458, 0.78169761,\n",
      "       0.77877037, 0.77984663, 0.7828987 , 0.7709789 , 0.78331958,\n",
      "       0.77363946, 0.78274859, 0.73275938, 0.75496412, 0.72339107,\n",
      "       0.72250988, 0.75189248, 0.77756458, 0.78003922, 0.74887889,\n",
      "       0.77647428, 0.75727264, 0.75640191, 0.77439591, 0.65124219,\n",
      "       0.77401221, 0.75052574, 0.78208654, 0.77846367, 0.7738469 ,\n",
      "       0.69364868, 0.7813173 , 0.71228151, 0.78272337, 0.78132747,\n",
      "       0.76809459, 0.7448292 , 0.75719945, 0.78243039, 0.78074724,\n",
      "       0.72143686, 0.77439167, 0.72544941, 0.77389476, 0.74611945,\n",
      "       0.78079183, 0.77484853, 0.7750907 , 0.73244816, 0.76645624,\n",
      "       0.69367484, 0.78209186, 0.70650958, 0.75545754, 0.72431706,\n",
      "       0.70243258, 0.78225931, 0.67015203, 0.77816593, 0.67130399,\n",
      "       0.70966669, 0.75904879, 0.77587696, 0.78034525, 0.76799437,\n",
      "       0.77862979, 0.73498481, 0.78244588, 0.78055751, 0.77978788,\n",
      "       0.7048045 , 0.67283477, 0.77489202, 0.68524556, 0.76622724,\n",
      "       0.77424229, 0.78017358, 0.75057278, 0.77999114, 0.78172607,\n",
      "       0.7776534 , 0.780083  , 0.77774033, 0.77597165, 0.7041257 ,\n",
      "       0.78030112, 0.7811397 , 0.78169812, 0.77891233, 0.7498834 ,\n",
      "       0.76364889, 0.78058478, 0.7801891 , 0.77962597, 0.781225  ,\n",
      "       0.71845908, 0.72635705, 0.78127858, 0.71875573, 0.77874483,\n",
      "       0.75017639, 0.7766933 , 0.77467014, 0.78310499, 0.77602793,\n",
      "       0.77514882, 0.76004933, 0.78069266, 0.74387676, 0.67653068,\n",
      "       0.77880368, 0.77963447, 0.77197413, 0.77972656, 0.75992449,\n",
      "       0.7213665 , 0.69142561, 0.77573247, 0.77827991, 0.78204744,\n",
      "       0.7800046 , 0.76169439, 0.78018965, 0.77809654, 0.71066544,\n",
      "       0.723173  , 0.70474851, 0.75526918, 0.77511305, 0.77619385,\n",
      "       0.7807589 , 0.76523011, 0.77194184, 0.77875624, 0.77403205])] \n",
      "\n",
      "mean AUC :  0.7571882572973088\n",
      "All std:  [array([0.02287273, 0.01906986, 0.01505591, 0.03307726, 0.0158604 ,\n",
      "       0.02021097, 0.02195544, 0.01606852, 0.02196633, 0.01649256,\n",
      "       0.01991232, 0.01394052, 0.02200392, 0.01677854, 0.02041519,\n",
      "       0.009261  , 0.02000317, 0.02039782, 0.00605218, 0.01847081,\n",
      "       0.02336938, 0.02611168, 0.01435887, 0.01694324, 0.02039759,\n",
      "       0.02045348, 0.01449596, 0.01871383, 0.01722458, 0.0199949 ,\n",
      "       0.0185635 , 0.0225006 , 0.02149804, 0.02330895, 0.02824793,\n",
      "       0.01808619, 0.01975147, 0.02308273, 0.04373972, 0.02200447,\n",
      "       0.01362768, 0.02124206, 0.01840906, 0.02019947, 0.05377848,\n",
      "       0.02232907, 0.02288045, 0.02289097, 0.02486431, 0.01888048,\n",
      "       0.01713071, 0.02431929, 0.02187411, 0.02306221, 0.01397523,\n",
      "       0.02443545, 0.02267209, 0.01914183, 0.02069996, 0.01957728,\n",
      "       0.02111163, 0.02094434, 0.02510717, 0.02015329, 0.02338758,\n",
      "       0.02819649, 0.02239071, 0.02106577, 0.02187811, 0.02121047,\n",
      "       0.02178453, 0.02215489, 0.02182793, 0.02007962, 0.02171981,\n",
      "       0.019437  , 0.02108775, 0.02888528, 0.01390539, 0.02043211,\n",
      "       0.03882908, 0.0150553 , 0.02278705, 0.02001402, 0.01755271,\n",
      "       0.0174521 , 0.01343333, 0.01523013, 0.0202015 , 0.01568836,\n",
      "       0.01592633, 0.01371866, 0.02043211, 0.02296905, 0.02162272,\n",
      "       0.0318662 , 0.02242115, 0.04087056, 0.02116351, 0.0210676 ,\n",
      "       0.01538248, 0.01935244, 0.02051449, 0.0213433 , 0.02219418,\n",
      "       0.01942005, 0.01594568, 0.01681427, 0.02284378, 0.02039948,\n",
      "       0.02094392, 0.02305343, 0.01819589, 0.01517159, 0.01723193,\n",
      "       0.03914327, 0.0207945 , 0.01460155, 0.01236544, 0.03502033,\n",
      "       0.00828944, 0.02245733, 0.02489082, 0.02314474, 0.01684248,\n",
      "       0.0173074 , 0.01850561, 0.02302876, 0.02155865, 0.01640302,\n",
      "       0.02170148, 0.02950198, 0.02046014, 0.02204162, 0.02238603,\n",
      "       0.02122659, 0.02982353, 0.02163497, 0.04207029, 0.01750966,\n",
      "       0.02259783, 0.02048751, 0.01404485, 0.0227381 , 0.02191089,\n",
      "       0.02089342, 0.01862175, 0.02239989, 0.01786015, 0.02450069,\n",
      "       0.0224792 , 0.02173767, 0.02251572, 0.02226898, 0.0179762 ,\n",
      "       0.01609727, 0.02292026, 0.02160751, 0.02073772, 0.0223566 ,\n",
      "       0.03538868, 0.02309655, 0.0219218 , 0.03829016, 0.02050169,\n",
      "       0.02128126, 0.02214443, 0.01881975, 0.02089524, 0.01760231,\n",
      "       0.02018496, 0.01813861, 0.020336  , 0.01810834, 0.05066192,\n",
      "       0.02261326, 0.01880496, 0.02153241, 0.01992472, 0.01994462,\n",
      "       0.02337711, 0.04389557, 0.02237897, 0.02223837, 0.02192965,\n",
      "       0.02200182, 0.01519749, 0.02263403, 0.0180582 , 0.0382182 ,\n",
      "       0.02535269, 0.02191679, 0.01513915, 0.0189164 , 0.01685644,\n",
      "       0.02200812, 0.01909064, 0.01823819, 0.02335734, 0.01717205])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.7272727272727272, 'min_child_weight': 60, 'max_depth': 45, 'gamma': 1.2327070707070706, 'eta': 0.02940820170587062} \n",
      "\n",
      "Best index/iterasi :  74\n",
      "Best AUC : 0.7833195846909181 ( std: 0.02171981116197053 ) \n",
      "\n",
      "running time:  3946.294355869293  detik. Dalam menit:  65.77157259782156  menit\n"
     ]
    }
   ],
   "source": [
    "seeds=[82,92]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=random_search(X_credit,y_credit,model_x,hyper_space_2,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3 (income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:45:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.87700586, 0.86426787, 0.87243598, 0.87197738, 0.88169377,\n",
      "       0.82668368, 0.848152  , 0.86801266, 0.89291097, 0.89203666,\n",
      "       0.88875042, 0.86989341, 0.88901752, 0.87836332, 0.86345988,\n",
      "       0.87553063, 0.86753639, 0.87985594, 0.86190326, 0.86924378,\n",
      "       0.87859163, 0.89523473, 0.87333473, 0.87136627, 0.87121708,\n",
      "       0.88032324, 0.87912558, 0.86983393, 0.87363289, 0.87914795,\n",
      "       0.88751875, 0.87300649, 0.87965542, 0.84633234, 0.86269597,\n",
      "       0.87246683, 0.87077824, 0.84623358, 0.87328476, 0.87408748,\n",
      "       0.87532459, 0.87418684, 0.87183045, 0.85932471, 0.87322845,\n",
      "       0.88389296, 0.89538837, 0.88998208, 0.86491446, 0.87284884,\n",
      "       0.88693567, 0.87143574, 0.88867145, 0.88547095, 0.87627788,\n",
      "       0.86016283, 0.87106189, 0.89085878, 0.87686935, 0.87717187,\n",
      "       0.87362064, 0.89194158, 0.88977705, 0.8832902 , 0.87885589,\n",
      "       0.87139421, 0.87516978, 0.88160093, 0.87045872, 0.8569129 ,\n",
      "       0.86379373, 0.88021912, 0.87405414, 0.88492253, 0.86909219,\n",
      "       0.88029941, 0.87505343, 0.87678283, 0.84101085, 0.88441916,\n",
      "       0.88350735, 0.88842202, 0.87572121, 0.87305476, 0.81711774,\n",
      "       0.8705746 , 0.86504336, 0.87519916, 0.85483834, 0.88139243,\n",
      "       0.88036114, 0.86386498, 0.89242499, 0.86050041, 0.85606252,\n",
      "       0.87161112, 0.87246086, 0.83218355, 0.87850031, 0.87945535,\n",
      "       0.87850678, 0.85652648, 0.87545034, 0.89077202, 0.86699085,\n",
      "       0.87197364, 0.86261379, 0.89404675, 0.88395077, 0.86475512,\n",
      "       0.86832446, 0.89016898, 0.88673764, 0.85389044, 0.87290356,\n",
      "       0.87235223, 0.87416797, 0.87288251, 0.87779615, 0.89313557,\n",
      "       0.83698851, 0.85990091, 0.87021514, 0.86822035, 0.88468269,\n",
      "       0.8898698 , 0.88157359, 0.87064596, 0.88652532, 0.87260182,\n",
      "       0.87642593, 0.89223055, 0.86301809, 0.87791085, 0.87594877,\n",
      "       0.89644489, 0.88949752, 0.86797594, 0.87818914, 0.85380706,\n",
      "       0.85205464, 0.87565349, 0.88370403, 0.85467157, 0.88077298,\n",
      "       0.88200946, 0.87512144, 0.87321332, 0.88080993, 0.806016  ,\n",
      "       0.80754567, 0.88173169, 0.87872995, 0.89423007, 0.87735805,\n",
      "       0.87068886, 0.87974178, 0.88229943, 0.88118155, 0.84770658,\n",
      "       0.86408033, 0.87203752, 0.86499958, 0.87254968, 0.83740522,\n",
      "       0.87611886, 0.886996  , 0.86881157, 0.87631318, 0.86127887,\n",
      "       0.87181038, 0.88760897, 0.83728342, 0.87120135, 0.87202135,\n",
      "       0.87158095, 0.84957894, 0.88374266, 0.89504295, 0.86989845,\n",
      "       0.87251071, 0.85033702, 0.86855226, 0.87536904, 0.86311886,\n",
      "       0.87429412, 0.87070436, 0.87217341, 0.8653868 , 0.8452524 ,\n",
      "       0.88583576, 0.86616695, 0.8815678 , 0.86901901, 0.8743881 ,\n",
      "       0.88351687, 0.87640928, 0.88047506, 0.87301072, 0.87368077])] \n",
      "\n",
      "mean AUC :  0.872476959078154\n",
      "All std:  [array([0.01920147, 0.04672   , 0.02363952, 0.03019846, 0.01382922,\n",
      "       0.11115346, 0.08162905, 0.02391132, 0.01515226, 0.01507711,\n",
      "       0.01460146, 0.00949415, 0.01146569, 0.01894996, 0.01147435,\n",
      "       0.024823  , 0.02754142, 0.00577406, 0.03216846, 0.02329713,\n",
      "       0.01869217, 0.01337309, 0.02608533, 0.018851  , 0.00837884,\n",
      "       0.01408332, 0.01653962, 0.02222993, 0.00941365, 0.01865974,\n",
      "       0.01184747, 0.00909894, 0.01702531, 0.03682168, 0.03081826,\n",
      "       0.02066018, 0.00918528, 0.04529279, 0.0235216 , 0.02606473,\n",
      "       0.01634734, 0.0184617 , 0.00782573, 0.05817033, 0.01998955,\n",
      "       0.01381998, 0.01437687, 0.00916622, 0.02477055, 0.02852131,\n",
      "       0.01267395, 0.02351505, 0.01421192, 0.01397844, 0.0188704 ,\n",
      "       0.01123297, 0.03204806, 0.01451944, 0.01192691, 0.0171211 ,\n",
      "       0.02548471, 0.01526039, 0.01093611, 0.01316917, 0.00657556,\n",
      "       0.0244675 , 0.01518238, 0.01386736, 0.02113586, 0.04791632,\n",
      "       0.02693556, 0.01509216, 0.01512546, 0.01493904, 0.02715233,\n",
      "       0.01288336, 0.02120714, 0.01867405, 0.06427706, 0.01199822,\n",
      "       0.01022169, 0.01197147, 0.02314796, 0.02336011, 0.11073645,\n",
      "       0.02678782, 0.01426972, 0.02557023, 0.01136282, 0.00677485,\n",
      "       0.01028604, 0.03817662, 0.01191185, 0.04297028, 0.04530956,\n",
      "       0.02593752, 0.02585057, 0.06574227, 0.01932241, 0.01495409,\n",
      "       0.01914487, 0.04937538, 0.02350574, 0.01133114, 0.02500142,\n",
      "       0.00798675, 0.01106714, 0.01445791, 0.01413661, 0.02278633,\n",
      "       0.02693636, 0.01398466, 0.00947356, 0.04323894, 0.00741305,\n",
      "       0.02005845, 0.02648158, 0.00782006, 0.0124092 , 0.0154944 ,\n",
      "       0.01185088, 0.05141795, 0.02911237, 0.01023773, 0.01147031,\n",
      "       0.01314532, 0.00313448, 0.00863697, 0.00767464, 0.02060433,\n",
      "       0.02068451, 0.01149827, 0.01042547, 0.0142037 , 0.02159551,\n",
      "       0.01367946, 0.00824235, 0.02571286, 0.0182367 , 0.04480464,\n",
      "       0.069132  , 0.02685646, 0.00992814, 0.02954925, 0.00943209,\n",
      "       0.01408773, 0.02284972, 0.02383804, 0.01490116, 0.08722101,\n",
      "       0.07724551, 0.01283353, 0.01190119, 0.01208629, 0.02135121,\n",
      "       0.02522894, 0.00733207, 0.0134098 , 0.00723853, 0.03591577,\n",
      "       0.03485623, 0.02694933, 0.0414434 , 0.02534725, 0.01202804,\n",
      "       0.0089802 , 0.00977601, 0.02532721, 0.01693097, 0.04012011,\n",
      "       0.02416274, 0.01193953, 0.06725557, 0.00852499, 0.00799585,\n",
      "       0.02812395, 0.05097443, 0.01233065, 0.01516091, 0.02501557,\n",
      "       0.01991976, 0.04001888, 0.0229782 , 0.00532488, 0.02857954,\n",
      "       0.0221811 , 0.02685495, 0.02637315, 0.03858589, 0.06462795,\n",
      "       0.01478711, 0.02436665, 0.00549352, 0.01583819, 0.00995027,\n",
      "       0.00708298, 0.02125811, 0.01327088, 0.02608711, 0.02432813])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.34545454545454546, 'min_child_weight': 62, 'max_depth': 74, 'gamma': 2.0, 'eta': 0.10715933998226711} \n",
      "\n",
      "Best index/iterasi :  135\n",
      "Best AUC : 0.8964448908577005 ( std: 0.013679455200587887 ) \n",
      "\n",
      "running time:  7470.085138320923  detik. Dalam menit:  124.50141897201539  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  12 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.88680307, 0.87922614, 0.89038444, 0.87291441, 0.83807475,\n",
      "       0.87388304, 0.88603681, 0.87593165, 0.87241176, 0.85229696,\n",
      "       0.86126421, 0.87383866, 0.85789381, 0.87792974, 0.89159727,\n",
      "       0.8945282 , 0.88666721, 0.8791772 , 0.8748068 , 0.85949066,\n",
      "       0.87176744, 0.87620131, 0.88178867, 0.87949049, 0.82335077,\n",
      "       0.87407243, 0.8692971 , 0.8786924 , 0.87554101, 0.8749466 ,\n",
      "       0.87607395, 0.88112061, 0.84586202, 0.8781922 , 0.87303374,\n",
      "       0.87542997, 0.88778336, 0.8780625 , 0.87667741, 0.88546302,\n",
      "       0.8963593 , 0.84434256, 0.8477813 , 0.87305051, 0.85362667,\n",
      "       0.87013357, 0.88288707, 0.86929258, 0.87082498, 0.87800371,\n",
      "       0.87635031, 0.87801723, 0.87191799, 0.87808099, 0.89454226,\n",
      "       0.87484964, 0.86248412, 0.86706963, 0.88005556, 0.87855431,\n",
      "       0.88081347, 0.88987733, 0.87670179, 0.87152752, 0.86965779,\n",
      "       0.87515234, 0.87752713, 0.86797096, 0.87525813, 0.87590139,\n",
      "       0.87469419, 0.87100307, 0.85155927, 0.87599519, 0.83279856,\n",
      "       0.87396997, 0.88075322, 0.84686025, 0.86959156, 0.84000344,\n",
      "       0.8794117 , 0.87265212, 0.87002693, 0.84535922, 0.86938262,\n",
      "       0.88835697, 0.87110547, 0.87311704, 0.89384036, 0.8880761 ,\n",
      "       0.87377897, 0.89056938, 0.87437212, 0.88000607, 0.87151157,\n",
      "       0.8837491 , 0.8677224 , 0.85861359, 0.8732084 , 0.89336611,\n",
      "       0.87688601, 0.88998917, 0.84345278, 0.81912374, 0.82131022,\n",
      "       0.86658632, 0.87467101, 0.8706074 , 0.87650529, 0.87401954,\n",
      "       0.87648724, 0.87424115, 0.84198295, 0.86960488, 0.87713733,\n",
      "       0.81208652, 0.88512995, 0.89111015, 0.89310594, 0.88832005,\n",
      "       0.8705161 , 0.84685273, 0.89106664, 0.87510439, 0.88206374,\n",
      "       0.83944631, 0.84956636, 0.8803135 , 0.85348725, 0.86351758,\n",
      "       0.87414859, 0.87503396, 0.88282091, 0.85841524, 0.8781899 ,\n",
      "       0.88149967, 0.84134969, 0.87005789, 0.87802653, 0.87177767,\n",
      "       0.85621929, 0.87445611, 0.83372067, 0.83897871, 0.87053264,\n",
      "       0.87323097, 0.87965944, 0.88821232, 0.86607652, 0.8429207 ,\n",
      "       0.87925649, 0.88606948, 0.89069642, 0.87869409, 0.87053346,\n",
      "       0.87682058, 0.87501271, 0.84023398, 0.87029167, 0.87227327,\n",
      "       0.87767715, 0.87050383, 0.87721045, 0.87913393, 0.86677671,\n",
      "       0.86135754, 0.89331983, 0.87129516, 0.89110001, 0.85171933,\n",
      "       0.82801035, 0.86788192, 0.85871176, 0.87437105, 0.8647977 ,\n",
      "       0.86825883, 0.82697828, 0.8895275 , 0.86151657, 0.86019365,\n",
      "       0.88339616, 0.87491183, 0.87271586, 0.88230118, 0.87832827,\n",
      "       0.87315132, 0.8402934 , 0.87205852, 0.87003009, 0.88974051,\n",
      "       0.86977936, 0.87575061, 0.87309107, 0.86889093, 0.86367441,\n",
      "       0.88107291, 0.87224745, 0.85974794, 0.86674919, 0.83315923])] \n",
      "\n",
      "mean AUC :  0.8704150229287196\n",
      "All std:  [array([0.0148093 , 0.02122339, 0.01328959, 0.01890766, 0.08061422,\n",
      "       0.00426011, 0.01148032, 0.00806801, 0.02524868, 0.01058319,\n",
      "       0.01199982, 0.01992593, 0.05926503, 0.01039359, 0.01648599,\n",
      "       0.01450258, 0.00956262, 0.01221734, 0.02105239, 0.03054665,\n",
      "       0.02533956, 0.02005968, 0.01409472, 0.01884272, 0.059006  ,\n",
      "       0.01977736, 0.02870734, 0.01595697, 0.01703307, 0.02626824,\n",
      "       0.0102378 , 0.00599772, 0.04824819, 0.01695978, 0.02590508,\n",
      "       0.01353302, 0.01530673, 0.01077583, 0.01481417, 0.01101955,\n",
      "       0.01424494, 0.0604112 , 0.05369907, 0.02594606, 0.060478  ,\n",
      "       0.0394124 , 0.01206045, 0.00931521, 0.03122993, 0.01198567,\n",
      "       0.00794415, 0.01257327, 0.02382515, 0.01016211, 0.01457436,\n",
      "       0.0226123 , 0.0109789 , 0.01023212, 0.01348435, 0.01663437,\n",
      "       0.0151466 , 0.0130093 , 0.01879132, 0.02335242, 0.02297603,\n",
      "       0.00679237, 0.01143227, 0.02953569, 0.01718593, 0.00765337,\n",
      "       0.00763853, 0.00870342, 0.04879719, 0.02294899, 0.07113218,\n",
      "       0.01970234, 0.01473059, 0.04607283, 0.02910804, 0.09560512,\n",
      "       0.01409648, 0.02518354, 0.02371005, 0.04992583, 0.02469218,\n",
      "       0.01583011, 0.023904  , 0.02378759, 0.0162922 , 0.00998417,\n",
      "       0.00953018, 0.01161927, 0.01920362, 0.01688245, 0.0077963 ,\n",
      "       0.00566642, 0.03476455, 0.04030202, 0.00783217, 0.01347545,\n",
      "       0.01078147, 0.01422738, 0.04823002, 0.10551042, 0.05431398,\n",
      "       0.02502122, 0.0188549 , 0.00861887, 0.01998821, 0.0245342 ,\n",
      "       0.00974791, 0.01098887, 0.07003045, 0.01472735, 0.01214597,\n",
      "       0.11538508, 0.01229855, 0.01296803, 0.01614343, 0.00768766,\n",
      "       0.01563441, 0.04883682, 0.01525012, 0.00971806, 0.01235376,\n",
      "       0.05471322, 0.02087311, 0.01588126, 0.06519049, 0.02425393,\n",
      "       0.0090339 , 0.00866109, 0.00583281, 0.04103295, 0.02045169,\n",
      "       0.00536777, 0.07907668, 0.02404329, 0.01922609, 0.03578058,\n",
      "       0.02324638, 0.02436414, 0.08022632, 0.09853492, 0.02361795,\n",
      "       0.02338695, 0.01619027, 0.01560928, 0.01040931, 0.0920391 ,\n",
      "       0.01897819, 0.01207706, 0.01167506, 0.01980914, 0.02629108,\n",
      "       0.01354194, 0.02081236, 0.06813631, 0.00844063, 0.02184973,\n",
      "       0.01215957, 0.02607135, 0.01766134, 0.01484477, 0.01067078,\n",
      "       0.02922797, 0.01338718, 0.00839411, 0.01410454, 0.04780852,\n",
      "       0.09158146, 0.00959847, 0.03499152, 0.0200899 , 0.02708268,\n",
      "       0.02324398, 0.08184627, 0.01501599, 0.01665699, 0.05477502,\n",
      "       0.00552079, 0.02253421, 0.00813849, 0.01287194, 0.02106022,\n",
      "       0.02734453, 0.03825708, 0.00794022, 0.02714303, 0.01259248,\n",
      "       0.02879626, 0.01863239, 0.02050331, 0.03394882, 0.03247952,\n",
      "       0.01545237, 0.02277788, 0.01198064, 0.02844486, 0.09710143])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.23636363636363636, 'min_child_weight': 43, 'max_depth': 1, 'gamma': 0.8490606060606061, 'eta': 0.4483855948021186} \n",
      "\n",
      "Best index/iterasi :  40\n",
      "Best AUC : 0.8963593027066221 ( std: 0.01424494378868698 ) \n",
      "\n",
      "running time:  7585.68091917038  detik. Dalam menit:  126.42801531950633  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-16157d671a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_income\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_income\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper_space_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterasi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Seed: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint_hasil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterasi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-f7df020fa3a6>\u001b[0m in \u001b[0;36mrandom_search\u001b[0;34m(X, y, model, parameter, iterasi, evalscore, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m                    verbose= 1)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbest_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seeds=[1,12]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=random_search(X_income,y_income,model_x,hyper_space_2,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:11:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  22 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.83002445, 0.88502594, 0.84683108, 0.85236678, 0.87085106,\n",
      "       0.86297802, 0.82234861, 0.87192016, 0.87015809, 0.87014985,\n",
      "       0.87316469, 0.87325939, 0.87052072, 0.8758911 , 0.82086169,\n",
      "       0.86652888, 0.87842458, 0.86421109, 0.89175703, 0.83253321,\n",
      "       0.87689689, 0.87955866, 0.88932557, 0.86578624, 0.86284372,\n",
      "       0.88526472, 0.87662526, 0.86344491, 0.84868659, 0.87398879,\n",
      "       0.88867119, 0.86071539, 0.8754887 , 0.85732563, 0.87824489,\n",
      "       0.84464289, 0.87688968, 0.88420035, 0.86696704, 0.88687263,\n",
      "       0.8731211 , 0.87697068, 0.87485736, 0.87589328, 0.8424776 ,\n",
      "       0.89295652, 0.87447691, 0.87516034, 0.87410028, 0.87551933,\n",
      "       0.87710621, 0.8674089 , 0.87459185, 0.87529814, 0.82446133,\n",
      "       0.87424222, 0.87964402, 0.8715436 , 0.87686722, 0.87039621,\n",
      "       0.87431542, 0.87722725, 0.86600001, 0.89196779, 0.8681206 ,\n",
      "       0.89084617, 0.87291022, 0.83597942, 0.87348461, 0.87665393,\n",
      "       0.87836324, 0.87319757, 0.88904295, 0.84399612, 0.87420978,\n",
      "       0.8432226 , 0.87796581, 0.87029703, 0.87395534, 0.86935198,\n",
      "       0.86779881, 0.87164366, 0.88822992, 0.87456479, 0.87453428,\n",
      "       0.87346888, 0.87446131, 0.89421566, 0.87669283, 0.88483495,\n",
      "       0.87670859, 0.87526404, 0.87105453, 0.86926771, 0.87679287,\n",
      "       0.89406936, 0.87760652, 0.87177782, 0.87462735, 0.87448167,\n",
      "       0.8363384 , 0.89188105, 0.86984662, 0.88089184, 0.8226164 ,\n",
      "       0.87780859, 0.87667127, 0.86112477, 0.89214122, 0.87018128,\n",
      "       0.86146594, 0.88966007, 0.87426442, 0.88750257, 0.86335764,\n",
      "       0.87622724, 0.87318785, 0.86950555, 0.87543426, 0.86865244,\n",
      "       0.83343695, 0.87210831, 0.87592993, 0.87682738, 0.86726173,\n",
      "       0.87925537, 0.88463126, 0.87134718, 0.88704852, 0.86265851,\n",
      "       0.87690874, 0.87478003, 0.87683355, 0.85605767, 0.85920737,\n",
      "       0.83472081, 0.87343749, 0.88329008, 0.87272196, 0.85923494,\n",
      "       0.87625371, 0.85193595, 0.87269759, 0.88843855, 0.8294034 ,\n",
      "       0.88911222, 0.88232331, 0.87089225, 0.88188928, 0.85742223,\n",
      "       0.89203994, 0.88214444, 0.87704112, 0.83970634, 0.87666556,\n",
      "       0.87032574, 0.85157481, 0.8736555 , 0.87084671, 0.83109078,\n",
      "       0.8606593 , 0.86230598, 0.88014375, 0.85897023, 0.8769972 ,\n",
      "       0.87507543, 0.88852494, 0.86959459, 0.86264244, 0.88028091,\n",
      "       0.88168927, 0.87190273, 0.87391867, 0.87539668, 0.88531392,\n",
      "       0.88289372, 0.87507664, 0.8768296 , 0.87304585, 0.87622891,\n",
      "       0.87168936, 0.87052262, 0.87470993, 0.89070213, 0.87803781,\n",
      "       0.8715572 , 0.8734626 , 0.8701644 , 0.8337444 , 0.87323486,\n",
      "       0.84610231, 0.8531531 , 0.87945205, 0.87438622, 0.86498007,\n",
      "       0.87228734, 0.87717395, 0.88967826, 0.89193648, 0.86580175])] \n",
      "\n",
      "mean AUC :  0.8706736346324913\n",
      "All std:  [array([0.04417625, 0.01363521, 0.05801925, 0.00813768, 0.00984952,\n",
      "       0.04346661, 0.11385052, 0.02359309, 0.0213119 , 0.02434222,\n",
      "       0.02384614, 0.02606274, 0.02654361, 0.01612292, 0.07526314,\n",
      "       0.02390039, 0.01988625, 0.03388112, 0.01620417, 0.0047597 ,\n",
      "       0.00872441, 0.01722072, 0.01318513, 0.02884255, 0.02424776,\n",
      "       0.01254795, 0.01785921, 0.03048429, 0.04603109, 0.015343  ,\n",
      "       0.01515344, 0.02915724, 0.01029508, 0.05555639, 0.01941508,\n",
      "       0.02152661, 0.01263667, 0.01175554, 0.02592732, 0.01371375,\n",
      "       0.00813159, 0.00763683, 0.01853718, 0.01250039, 0.0615939 ,\n",
      "       0.01484848, 0.00824831, 0.01833336, 0.0220289 , 0.02003424,\n",
      "       0.01261131, 0.02605092, 0.02631561, 0.01778438, 0.01459852,\n",
      "       0.02566377, 0.00869575, 0.02624606, 0.02085443, 0.02461386,\n",
      "       0.0260963 , 0.01651478, 0.01041879, 0.0144039 , 0.02629524,\n",
      "       0.01383505, 0.0250557 , 0.05887673, 0.02197001, 0.00726825,\n",
      "       0.01888336, 0.00783747, 0.01118262, 0.00802866, 0.01951665,\n",
      "       0.07137095, 0.01987764, 0.02637754, 0.02596743, 0.00925188,\n",
      "       0.01091019, 0.02647698, 0.01582301, 0.02485566, 0.01317792,\n",
      "       0.0260666 , 0.01169564, 0.00734391, 0.00534932, 0.01117616,\n",
      "       0.01654756, 0.01929551, 0.00711975, 0.01552928, 0.02787852,\n",
      "       0.01593383, 0.01552238, 0.00806797, 0.01479271, 0.02561646,\n",
      "       0.08398269, 0.01621369, 0.00990168, 0.01537912, 0.1061295 ,\n",
      "       0.01820796, 0.01734576, 0.01129007, 0.01055504, 0.0312157 ,\n",
      "       0.01150543, 0.01487031, 0.02594205, 0.01444136, 0.00695274,\n",
      "       0.02245242, 0.00792242, 0.00712152, 0.00972648, 0.00970548,\n",
      "       0.09149732, 0.0275796 , 0.00913645, 0.0211003 , 0.04022275,\n",
      "       0.02186994, 0.00600102, 0.02208866, 0.00800204, 0.01096208,\n",
      "       0.01227315, 0.01773192, 0.01737359, 0.00371789, 0.01114844,\n",
      "       0.08252774, 0.01645563, 0.0073322 , 0.02088776, 0.054253  ,\n",
      "       0.02075506, 0.04625507, 0.02570993, 0.01442162, 0.00735587,\n",
      "       0.01585776, 0.00585555, 0.0231962 , 0.01400346, 0.01192713,\n",
      "       0.01332832, 0.0129347 , 0.02052989, 0.07801039, 0.01435566,\n",
      "       0.00876071, 0.01395897, 0.02309414, 0.02572872, 0.0781246 ,\n",
      "       0.03362357, 0.04539952, 0.01207861, 0.03461774, 0.02000369,\n",
      "       0.01378714, 0.01539827, 0.0271506 , 0.0109664 , 0.01505113,\n",
      "       0.00559527, 0.00808993, 0.01927985, 0.02000968, 0.00982118,\n",
      "       0.00590014, 0.01751075, 0.01080598, 0.00789705, 0.02537068,\n",
      "       0.00829387, 0.03113018, 0.02714655, 0.01373703, 0.01910187,\n",
      "       0.02651987, 0.02538309, 0.03200265, 0.06250758, 0.00869242,\n",
      "       0.0316059 , 0.04284321, 0.01972962, 0.02598982, 0.00309157,\n",
      "       0.02806016, 0.01811484, 0.01257615, 0.01178925, 0.02605072])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.3727272727272727, 'min_child_weight': 56, 'max_depth': 2, 'gamma': 1.6365454545454543, 'eta': 0.2199593068030075} \n",
      "\n",
      "Best index/iterasi :  87\n",
      "Best AUC : 0.8942156612744983 ( std: 0.007343907830010932 ) \n",
      "\n",
      "running time:  7405.62762093544  detik. Dalam menit:  123.42712701559067  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:06:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  32 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.80489007, 0.863862  , 0.87508539, 0.88696675, 0.87310834,\n",
      "       0.87580643, 0.87266559, 0.8603711 , 0.84353904, 0.8726123 ,\n",
      "       0.84967982, 0.85832484, 0.87484489, 0.86043819, 0.87562445,\n",
      "       0.8780279 , 0.87953122, 0.86470604, 0.84348051, 0.83780108,\n",
      "       0.86162297, 0.84591944, 0.82378426, 0.88921758, 0.88843834,\n",
      "       0.82029017, 0.88462837, 0.87652907, 0.88389353, 0.88974281,\n",
      "       0.88749184, 0.88261594, 0.85860341, 0.88994282, 0.8643964 ,\n",
      "       0.88386814, 0.84180968, 0.87956439, 0.86196665, 0.8924555 ,\n",
      "       0.87176564, 0.87682419, 0.86039715, 0.86274354, 0.87322853,\n",
      "       0.89362064, 0.89000237, 0.87020363, 0.85585435, 0.87632416,\n",
      "       0.87361174, 0.87422468, 0.87126431, 0.85745036, 0.86737041,\n",
      "       0.87561822, 0.86378272, 0.87741195, 0.86400308, 0.8826702 ,\n",
      "       0.87537814, 0.87276233, 0.88222265, 0.87745846, 0.8759135 ,\n",
      "       0.86371299, 0.87605876, 0.88347256, 0.89096283, 0.84915304,\n",
      "       0.86155218, 0.89171546, 0.86915595, 0.86448738, 0.87765685,\n",
      "       0.8882975 , 0.86797435, 0.88268152, 0.82874813, 0.86518748,\n",
      "       0.85446785, 0.87235355, 0.88489836, 0.86536698, 0.854483  ,\n",
      "       0.87291893, 0.85729609, 0.87634365, 0.87069527, 0.89173567,\n",
      "       0.87764847, 0.8705359 , 0.87944749, 0.87789723, 0.87716532,\n",
      "       0.89393726, 0.86545541, 0.87178303, 0.85360138, 0.83801572,\n",
      "       0.87329694, 0.88166582, 0.87561439, 0.88402251, 0.86223394,\n",
      "       0.85715355, 0.87050046, 0.87738226, 0.87595453, 0.88768469,\n",
      "       0.86087626, 0.87321786, 0.85630756, 0.85924113, 0.87117636,\n",
      "       0.87506352, 0.87504091, 0.8584513 , 0.88419582, 0.88541153,\n",
      "       0.86340628, 0.87760048, 0.89188779, 0.86774664, 0.8570278 ,\n",
      "       0.85920043, 0.89175086, 0.89091753, 0.8694711 , 0.89027244,\n",
      "       0.86913428, 0.86901606, 0.87741795, 0.88117971, 0.86913447,\n",
      "       0.87707173, 0.88523746, 0.88327365, 0.86252906, 0.87816232,\n",
      "       0.89212728, 0.88953717, 0.87245477, 0.85989955, 0.87670417,\n",
      "       0.86060538, 0.88274961, 0.88403004, 0.85268201, 0.86489056,\n",
      "       0.86897252, 0.87224043, 0.86723229, 0.86103305, 0.86843999,\n",
      "       0.86970006, 0.87046878, 0.82015508, 0.87399142, 0.88840083,\n",
      "       0.87293594, 0.8856868 , 0.87384469, 0.8793175 , 0.88496693,\n",
      "       0.87163409, 0.86517388, 0.87331916, 0.87052712, 0.87753588,\n",
      "       0.85853564, 0.87568318, 0.87422097, 0.87163673, 0.87897096,\n",
      "       0.86718286, 0.86291976, 0.86972763, 0.85955083, 0.8597661 ,\n",
      "       0.87348306, 0.82121215, 0.83936332, 0.82816169, 0.87433861,\n",
      "       0.87528559, 0.87346872, 0.83637297, 0.87474439, 0.86034505,\n",
      "       0.89431028, 0.87209951, 0.87110637, 0.86329381, 0.86099283,\n",
      "       0.88068711, 0.87492574, 0.82816199, 0.87413649, 0.87800534])] \n",
      "\n",
      "mean AUC :  0.8699349688943258\n",
      "All std:  [array([0.07316265, 0.03040035, 0.00998324, 0.01376883, 0.02617008,\n",
      "       0.01969722, 0.00802421, 0.01179983, 0.07660211, 0.01895879,\n",
      "       0.05097852, 0.03936061, 0.0124947 , 0.01148934, 0.01805571,\n",
      "       0.00804012, 0.00593759, 0.02825416, 0.06190905, 0.06083579,\n",
      "       0.01152991, 0.02573816, 0.10513957, 0.01463552, 0.0142952 ,\n",
      "       0.08918241, 0.01000208, 0.00777621, 0.00545326, 0.01117869,\n",
      "       0.00914436, 0.01014109, 0.01072872, 0.01286827, 0.00646476,\n",
      "       0.01278916, 0.07846525, 0.01585185, 0.01146528, 0.01382616,\n",
      "       0.00787771, 0.01856442, 0.01666586, 0.04531504, 0.0254132 ,\n",
      "       0.01475243, 0.01168141, 0.02712236, 0.01114218, 0.01062378,\n",
      "       0.00785358, 0.00807403, 0.0095755 , 0.04853689, 0.02738214,\n",
      "       0.01660928, 0.02373039, 0.02064345, 0.04045653, 0.00633821,\n",
      "       0.02090872, 0.00908749, 0.01668781, 0.01554706, 0.01669369,\n",
      "       0.03817483, 0.01559702, 0.01401415, 0.014195  , 0.07044505,\n",
      "       0.01159079, 0.01514456, 0.02348762, 0.02966525, 0.01887962,\n",
      "       0.01186955, 0.00985148, 0.00944751, 0.02078615, 0.0455563 ,\n",
      "       0.0383335 , 0.02582327, 0.01456888, 0.04228086, 0.04640266,\n",
      "       0.00784644, 0.01108794, 0.02005433, 0.0255421 , 0.01321967,\n",
      "       0.00594964, 0.00958079, 0.01523149, 0.0149004 , 0.01564313,\n",
      "       0.01303398, 0.02457315, 0.0261893 , 0.05471385, 0.05680352,\n",
      "       0.02495639, 0.01476373, 0.0203845 , 0.01184931, 0.05371688,\n",
      "       0.05376378, 0.02532128, 0.01845833, 0.02349714, 0.00774203,\n",
      "       0.01177534, 0.02847323, 0.01162125, 0.02848035, 0.02611174,\n",
      "       0.02014372, 0.01649198, 0.01174273, 0.01008021, 0.01238662,\n",
      "       0.03750686, 0.02079205, 0.01413468, 0.02163055, 0.03053407,\n",
      "       0.00603289, 0.01242739, 0.01119674, 0.02742827, 0.01402285,\n",
      "       0.02368484, 0.02739083, 0.01319293, 0.01055019, 0.03019979,\n",
      "       0.0051258 , 0.00988492, 0.00660707, 0.01332792, 0.02069465,\n",
      "       0.01350412, 0.01484098, 0.0079987 , 0.03078944, 0.02756742,\n",
      "       0.03583219, 0.01361144, 0.01026429, 0.05420266, 0.04285505,\n",
      "       0.02410776, 0.02605111, 0.01067316, 0.01816888, 0.00745632,\n",
      "       0.0249392 , 0.00808205, 0.09305809, 0.00900658, 0.01475126,\n",
      "       0.02621246, 0.00885832, 0.02263255, 0.01555085, 0.01355172,\n",
      "       0.02643533, 0.00992066, 0.01811385, 0.02362984, 0.02197079,\n",
      "       0.01107726, 0.0096937 , 0.01543759, 0.01108098, 0.00699877,\n",
      "       0.00962974, 0.0305786 , 0.02543749, 0.01578318, 0.02576198,\n",
      "       0.02544616, 0.01108463, 0.07649029, 0.02845237, 0.02213643,\n",
      "       0.02023447, 0.01989108, 0.09610086, 0.02598308, 0.03204956,\n",
      "       0.01457095, 0.00811648, 0.00771928, 0.01088945, 0.01141766,\n",
      "       0.01473066, 0.02005106, 0.06260434, 0.00905847, 0.02562201])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.33636363636363636, 'min_child_weight': 59, 'max_depth': 87, 'gamma': 1.7778888888888886, 'eta': 0.0607832312829723} \n",
      "\n",
      "Best index/iterasi :  190\n",
      "Best AUC : 0.8943102763099775 ( std: 0.01457095284083108 ) \n",
      "\n",
      "running time:  6958.222449064255  detik. Dalam menit:  115.97037415107091  menit\n"
     ]
    }
   ],
   "source": [
    "seeds=[22,32]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=random_search(X_income,y_income,model_x,hyper_space_2,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:04:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  42 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.87598193, 0.83417888, 0.85366643, 0.81954323, 0.8795094 ,\n",
      "       0.84170868, 0.87365071, 0.85838402, 0.86408889, 0.86811438,\n",
      "       0.86904413, 0.83936794, 0.84451692, 0.87167568, 0.89118015,\n",
      "       0.8779256 , 0.88965219, 0.89343034, 0.86638864, 0.86841409,\n",
      "       0.87566721, 0.88932787, 0.86221188, 0.87513167, 0.86119451,\n",
      "       0.89478198, 0.87745588, 0.89250551, 0.88517072, 0.89317583,\n",
      "       0.87459959, 0.89649252, 0.88288597, 0.86213193, 0.86333233,\n",
      "       0.87058966, 0.86961131, 0.87905569, 0.85157715, 0.87344489,\n",
      "       0.87097951, 0.83982131, 0.87291731, 0.87941344, 0.84173991,\n",
      "       0.87592182, 0.86976758, 0.84215379, 0.877281  , 0.89171525,\n",
      "       0.87545823, 0.87509408, 0.86047492, 0.80939298, 0.86682016,\n",
      "       0.89236222, 0.86856073, 0.86813099, 0.86998935, 0.87204344,\n",
      "       0.85881413, 0.86711313, 0.87177896, 0.87371635, 0.881049  ,\n",
      "       0.84435834, 0.87280448, 0.85945685, 0.85480506, 0.87207964,\n",
      "       0.87296974, 0.87057837, 0.87675761, 0.85774269, 0.89368093,\n",
      "       0.85227953, 0.88288397, 0.87585024, 0.87291133, 0.83862672,\n",
      "       0.88228257, 0.87017454, 0.87651566, 0.84152409, 0.86804731,\n",
      "       0.87167787, 0.87316318, 0.88661997, 0.88269581, 0.87747474,\n",
      "       0.85516169, 0.83295615, 0.87295695, 0.87345564, 0.87284964,\n",
      "       0.87769056, 0.87050852, 0.87841171, 0.84487131, 0.88108767,\n",
      "       0.86668665, 0.87888129, 0.88371288, 0.89276685, 0.8688148 ,\n",
      "       0.87106856, 0.88423149, 0.88018196, 0.86098109, 0.88680806,\n",
      "       0.87626806, 0.87669095, 0.86141013, 0.8741074 , 0.87569293,\n",
      "       0.87417052, 0.8607705 , 0.87182918, 0.87603945, 0.89081275,\n",
      "       0.87485654, 0.84728054, 0.89284627, 0.87022652, 0.8728905 ,\n",
      "       0.83528228, 0.89172605, 0.87744852, 0.82550144, 0.8662273 ,\n",
      "       0.86847226, 0.8558055 , 0.87733681, 0.83112485, 0.8729623 ,\n",
      "       0.87260841, 0.86808268, 0.86435567, 0.87754652, 0.87999494,\n",
      "       0.87659929, 0.86171842, 0.86075105, 0.87182722, 0.87869926,\n",
      "       0.8729051 , 0.87089361, 0.86237267, 0.87483496, 0.87076348,\n",
      "       0.81175474, 0.87198669, 0.86610387, 0.86500758, 0.87722113,\n",
      "       0.8510257 , 0.80972729, 0.87662921, 0.88387343, 0.87370262,\n",
      "       0.83089778, 0.88446429, 0.89072551, 0.85442074, 0.87246221,\n",
      "       0.88940667, 0.87019403, 0.87710746, 0.87143483, 0.82422699,\n",
      "       0.87585327, 0.88459507, 0.89403807, 0.86716143, 0.84541409,\n",
      "       0.86457016, 0.87016238, 0.8581903 , 0.87186853, 0.86035844,\n",
      "       0.84910847, 0.83374101, 0.87411363, 0.84641802, 0.88549434,\n",
      "       0.86273702, 0.85938021, 0.89067596, 0.87130432, 0.87903654,\n",
      "       0.87458425, 0.85629056, 0.87533555, 0.85138709, 0.86937132,\n",
      "       0.85600737, 0.87449174, 0.87089667, 0.86503665, 0.86907855])] \n",
      "\n",
      "mean AUC :  0.8683306361600915\n",
      "All std:  [array([0.00516121, 0.08605986, 0.04674834, 0.09298614, 0.01385209,\n",
      "       0.06459102, 0.01754569, 0.01244451, 0.04197215, 0.02465468,\n",
      "       0.00649112, 0.08313712, 0.05307796, 0.02332613, 0.01223465,\n",
      "       0.01878937, 0.01163748, 0.01487441, 0.0392357 , 0.00989216,\n",
      "       0.0213384 , 0.01133417, 0.03200994, 0.0135637 , 0.0117026 ,\n",
      "       0.01397693, 0.01923556, 0.01551726, 0.01066906, 0.01377672,\n",
      "       0.01618115, 0.01555539, 0.01353969, 0.01145327, 0.0185164 ,\n",
      "       0.02705685, 0.00877379, 0.01483484, 0.04015335, 0.00810831,\n",
      "       0.03217693, 0.0881919 , 0.02527933, 0.00347889, 0.01696474,\n",
      "       0.02328035, 0.02895878, 0.06320553, 0.01873959, 0.01282092,\n",
      "       0.00875126, 0.01639389, 0.05078884, 0.08481308, 0.02662287,\n",
      "       0.01155147, 0.023888  , 0.02637071, 0.0219026 , 0.0084371 ,\n",
      "       0.04370247, 0.02613327, 0.00851003, 0.01894489, 0.01492952,\n",
      "       0.00819761, 0.00819124, 0.03511322, 0.01184466, 0.01944847,\n",
      "       0.02926934, 0.02535714, 0.01361924, 0.01660689, 0.0160989 ,\n",
      "       0.0572877 , 0.01317471, 0.02308646, 0.02064058, 0.05321717,\n",
      "       0.01317989, 0.00998069, 0.01117779, 0.06053886, 0.02546286,\n",
      "       0.0285802 , 0.00777878, 0.01549083, 0.01263013, 0.00601149,\n",
      "       0.01193864, 0.04572178, 0.00885817, 0.0253114 , 0.02491244,\n",
      "       0.01987877, 0.02708102, 0.01646307, 0.07722687, 0.01578243,\n",
      "       0.02793183, 0.02030946, 0.0060254 , 0.01146121, 0.02292784,\n",
      "       0.02609066, 0.01056382, 0.00604176, 0.0475651 , 0.0163865 ,\n",
      "       0.00898522, 0.01380875, 0.01162758, 0.01485121, 0.00843493,\n",
      "       0.01974299, 0.04676125, 0.02527261, 0.01791237, 0.01421988,\n",
      "       0.01197757, 0.07025857, 0.01281419, 0.00850658, 0.00768241,\n",
      "       0.07059322, 0.01537884, 0.01000984, 0.07495998, 0.02900678,\n",
      "       0.0091259 , 0.04879109, 0.00968161, 0.04862071, 0.00809567,\n",
      "       0.02569235, 0.03620912, 0.04406375, 0.01308383, 0.01506519,\n",
      "       0.00973815, 0.04623822, 0.01166857, 0.02225045, 0.02072114,\n",
      "       0.00927197, 0.00769006, 0.01155277, 0.00940124, 0.00795106,\n",
      "       0.04448194, 0.02757416, 0.02843635, 0.02377734, 0.00957542,\n",
      "       0.05342282, 0.10908526, 0.0166265 , 0.01159512, 0.02520124,\n",
      "       0.08187405, 0.00590323, 0.00381246, 0.06943053, 0.02220297,\n",
      "       0.01471747, 0.02034183, 0.01003605, 0.02662283, 0.09327079,\n",
      "       0.00952448, 0.01144084, 0.01605521, 0.01928439, 0.05077668,\n",
      "       0.03556852, 0.03239509, 0.03588225, 0.02620633, 0.01154347,\n",
      "       0.050148  , 0.0227683 , 0.02585827, 0.03667654, 0.01144478,\n",
      "       0.02696541, 0.03019832, 0.01091545, 0.02572854, 0.01269324,\n",
      "       0.02595532, 0.02541762, 0.00858303, 0.0671549 , 0.02086138,\n",
      "       0.01048574, 0.00884302, 0.02856306, 0.01020928, 0.00852539])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.40909090909090906, 'min_child_weight': 77, 'max_depth': 14, 'gamma': 1.49520202020202, 'eta': 0.06696160054853219} \n",
      "\n",
      "Best index/iterasi :  31\n",
      "Best AUC : 0.8964925249494264 ( std: 0.015555392149129859 ) \n",
      "\n",
      "running time:  8858.467427968979  detik. Dalam menit:  147.64112379948298  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:23:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  52 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.88359248, 0.8854202 , 0.87442205, 0.87126716, 0.85946122,\n",
      "       0.86955624, 0.8703512 , 0.88219738, 0.87077982, 0.8648481 ,\n",
      "       0.8830188 , 0.88057185, 0.88023521, 0.81422413, 0.8764818 ,\n",
      "       0.87344833, 0.86875931, 0.86671666, 0.86875871, 0.88136675,\n",
      "       0.87129322, 0.8894105 , 0.87659687, 0.87030488, 0.89162067,\n",
      "       0.88316886, 0.84710254, 0.86963143, 0.84931744, 0.87488345,\n",
      "       0.8678514 , 0.87137802, 0.88851365, 0.88830153, 0.88838988,\n",
      "       0.86354204, 0.8918986 , 0.87730224, 0.8719291 , 0.89217636,\n",
      "       0.85711623, 0.88165297, 0.87464795, 0.87123362, 0.86899228,\n",
      "       0.87819745, 0.8503775 , 0.87593182, 0.87985193, 0.86196843,\n",
      "       0.87671143, 0.88073302, 0.86890694, 0.84650321, 0.87496765,\n",
      "       0.8762757 , 0.88128696, 0.87993915, 0.87426394, 0.88657363,\n",
      "       0.87335467, 0.88162223, 0.84716006, 0.86431856, 0.89176864,\n",
      "       0.88982664, 0.88823717, 0.87788228, 0.87470116, 0.88939231,\n",
      "       0.88250965, 0.8675001 , 0.89063476, 0.85328784, 0.85251249,\n",
      "       0.89108275, 0.86803397, 0.8870381 , 0.87046949, 0.76833871,\n",
      "       0.86921799, 0.85245199, 0.8725425 , 0.85893486, 0.87755535,\n",
      "       0.87375758, 0.89196496, 0.80911041, 0.87576807, 0.8679025 ,\n",
      "       0.87674176, 0.87388666, 0.8543912 , 0.85415669, 0.87567733,\n",
      "       0.88944282, 0.88017078, 0.83464356, 0.83157598, 0.85471704,\n",
      "       0.87413661, 0.87800407, 0.88305899, 0.86856957, 0.87466723,\n",
      "       0.87546942, 0.87390035, 0.85328159, 0.87001315, 0.87244031,\n",
      "       0.81131785, 0.88575258, 0.8815818 , 0.85517688, 0.89335015,\n",
      "       0.88335501, 0.87320961, 0.863113  , 0.85963283, 0.86606148,\n",
      "       0.87093182, 0.87051581, 0.87378784, 0.87293074, 0.88091319,\n",
      "       0.88812156, 0.86479402, 0.87323177, 0.85277418, 0.85025236,\n",
      "       0.88684787, 0.87124858, 0.87797366, 0.86833535, 0.87180097,\n",
      "       0.88410568, 0.88006489, 0.88599624, 0.87883364, 0.89564332,\n",
      "       0.87984762, 0.85146786, 0.8896212 , 0.88359383, 0.87743289,\n",
      "       0.88827378, 0.82848284, 0.86509907, 0.87589369, 0.86971702,\n",
      "       0.8512486 , 0.86376862, 0.86970471, 0.87673525, 0.86543654,\n",
      "       0.8962228 , 0.8672134 , 0.82504144, 0.8640034 , 0.8863358 ,\n",
      "       0.81818178, 0.87049303, 0.87328455, 0.88771971, 0.8775234 ,\n",
      "       0.84568642, 0.86245993, 0.87995606, 0.86296492, 0.87352739,\n",
      "       0.86849202, 0.82119422, 0.84211574, 0.87226943, 0.8703814 ,\n",
      "       0.8205598 , 0.85942013, 0.87046843, 0.87880726, 0.85324406,\n",
      "       0.86343316, 0.86342424, 0.87540267, 0.86088981, 0.87235809,\n",
      "       0.85994855, 0.88199264, 0.85643109, 0.86650647, 0.87585047,\n",
      "       0.87177512, 0.88638402, 0.87665376, 0.87150859, 0.88164737,\n",
      "       0.85587236, 0.89148019, 0.89020849, 0.87574221, 0.85725741])] \n",
      "\n",
      "mean AUC :  0.8699717813307353\n",
      "All std:  [array([0.01342747, 0.01414747, 0.02444423, 0.00970006, 0.03631326,\n",
      "       0.00895098, 0.02563315, 0.0119149 , 0.02174581, 0.01571335,\n",
      "       0.01473992, 0.00705529, 0.00615826, 0.05345622, 0.02718829,\n",
      "       0.00823878, 0.02918827, 0.02212608, 0.0089525 , 0.01102692,\n",
      "       0.02666531, 0.01148013, 0.00604301, 0.02532626, 0.01054639,\n",
      "       0.01376112, 0.06801056, 0.00570163, 0.06189192, 0.00848557,\n",
      "       0.03805458, 0.0073661 , 0.01524176, 0.01050868, 0.01669768,\n",
      "       0.01512632, 0.01479438, 0.01948871, 0.02387659, 0.0157957 ,\n",
      "       0.06100724, 0.01548719, 0.01859459, 0.02585703, 0.00847375,\n",
      "       0.00696119, 0.04566762, 0.00883978, 0.00445257, 0.04703303,\n",
      "       0.02034028, 0.02143111, 0.00737252, 0.07200286, 0.02029265,\n",
      "       0.01161744, 0.00658402, 0.01621521, 0.0213365 , 0.01118168,\n",
      "       0.01442981, 0.00299621, 0.01903992, 0.03608073, 0.01040257,\n",
      "       0.01098376, 0.01241697, 0.00693517, 0.01966647, 0.01585007,\n",
      "       0.01422524, 0.0098261 , 0.013746  , 0.05163648, 0.01404194,\n",
      "       0.01714517, 0.02329052, 0.00944211, 0.02545065, 0.03940311,\n",
      "       0.02362533, 0.04531331, 0.02340612, 0.03994986, 0.01008854,\n",
      "       0.00960348, 0.01005584, 0.12750568, 0.02400176, 0.03730458,\n",
      "       0.00990427, 0.01362673, 0.04734996, 0.03410601, 0.02023092,\n",
      "       0.01265382, 0.01775735, 0.10388268, 0.03967613, 0.034121  ,\n",
      "       0.00908714, 0.01564851, 0.01256278, 0.03275347, 0.01558994,\n",
      "       0.02253295, 0.02316872, 0.06714839, 0.00961222, 0.02417732,\n",
      "       0.10707105, 0.01345615, 0.01405585, 0.06503922, 0.01461017,\n",
      "       0.01488776, 0.00794025, 0.01067298, 0.02972596, 0.00794918,\n",
      "       0.02624589, 0.02612091, 0.0080208 , 0.02600715, 0.0151963 ,\n",
      "       0.00909802, 0.01080814, 0.02936802, 0.05745961, 0.0680929 ,\n",
      "       0.01312794, 0.02637019, 0.02040934, 0.03472053, 0.02395394,\n",
      "       0.0118674 , 0.01084968, 0.0043339 , 0.01084906, 0.01369243,\n",
      "       0.01672052, 0.04863651, 0.01403537, 0.01183265, 0.02103755,\n",
      "       0.00931647, 0.04445802, 0.03563461, 0.02350174, 0.03164881,\n",
      "       0.04656699, 0.02751989, 0.00899197, 0.00916228, 0.01001078,\n",
      "       0.01339736, 0.01643559, 0.07746295, 0.01122239, 0.0104003 ,\n",
      "       0.09176697, 0.01053919, 0.01009271, 0.01071625, 0.00875626,\n",
      "       0.07684342, 0.01092111, 0.00629028, 0.04839321, 0.02607122,\n",
      "       0.02802309, 0.08319986, 0.06487023, 0.02351396, 0.02562564,\n",
      "       0.05221268, 0.03065577, 0.02926411, 0.01923476, 0.04146548,\n",
      "       0.03090946, 0.029077  , 0.01015759, 0.02860715, 0.02331037,\n",
      "       0.03819351, 0.00443439, 0.06123571, 0.02888307, 0.02211196,\n",
      "       0.0080605 , 0.0111897 , 0.01565487, 0.02598651, 0.01186403,\n",
      "       0.04747961, 0.01530076, 0.01225489, 0.0164276 , 0.01165811])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.49090909090909085, 'min_child_weight': 95, 'max_depth': 29, 'gamma': 1.071171717171717, 'eta': 0.28018665564591955} \n",
      "\n",
      "Best index/iterasi :  155\n",
      "Best AUC : 0.8962228048908489 ( std: 0.013397364114316718 ) \n",
      "\n",
      "running time:  8326.181213617325  detik. Dalam menit:  138.7696868936221  menit\n"
     ]
    }
   ],
   "source": [
    "seeds=[42,52]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=random_search(X_income,y_income,model_x,hyper_space_2,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  62 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.88327842, 0.89016871, 0.87548683, 0.87332967, 0.8730039 ,\n",
      "       0.86314342, 0.81708831, 0.85704262, 0.8744468 , 0.87892919,\n",
      "       0.87694249, 0.87469605, 0.87418516, 0.87572187, 0.87755816,\n",
      "       0.87764532, 0.86366332, 0.86981714, 0.86555651, 0.863029  ,\n",
      "       0.87245862, 0.86706793, 0.85863226, 0.87073987, 0.87387998,\n",
      "       0.88816904, 0.87460194, 0.84837921, 0.87609122, 0.88049705,\n",
      "       0.88415576, 0.89047489, 0.87153253, 0.87070708, 0.86974186,\n",
      "       0.8705956 , 0.86570738, 0.87578861, 0.82140007, 0.8709913 ,\n",
      "       0.88572534, 0.88600964, 0.87102236, 0.87193681, 0.87630968,\n",
      "       0.87254113, 0.83970737, 0.87375687, 0.84774528, 0.87780238,\n",
      "       0.86201626, 0.85252265, 0.85106746, 0.84875276, 0.86564536,\n",
      "       0.87306197, 0.8636752 , 0.86638507, 0.87695514, 0.88130608,\n",
      "       0.88665513, 0.87149414, 0.8604242 , 0.86813555, 0.87722501,\n",
      "       0.85929043, 0.89271525, 0.87490512, 0.87015676, 0.85335173,\n",
      "       0.87981981, 0.87325278, 0.87218635, 0.88709528, 0.76833871,\n",
      "       0.86738541, 0.85069189, 0.87789651, 0.88684193, 0.87759195,\n",
      "       0.85182303, 0.87899004, 0.87824972, 0.87187273, 0.88851139,\n",
      "       0.89292434, 0.86254748, 0.81285311, 0.86606635, 0.87865351,\n",
      "       0.85841011, 0.87037665, 0.87078392, 0.87817611, 0.8660388 ,\n",
      "       0.88796202, 0.87623675, 0.89322075, 0.84888333, 0.87459715,\n",
      "       0.85636581, 0.87289179, 0.86698687, 0.8609185 , 0.87280745,\n",
      "       0.86784602, 0.8278243 , 0.8842392 , 0.84193119, 0.88043216,\n",
      "       0.87485486, 0.87538463, 0.89273716, 0.87371436, 0.8596527 ,\n",
      "       0.86192563, 0.86285015, 0.88804858, 0.87621464, 0.86744259,\n",
      "       0.86745961, 0.87290204, 0.8490189 , 0.85140057, 0.86956925,\n",
      "       0.82275953, 0.87027313, 0.88058805, 0.8787817 , 0.87514326,\n",
      "       0.87040299, 0.85340375, 0.88343927, 0.87656995, 0.84689848,\n",
      "       0.88363447, 0.87056428, 0.87924332, 0.87257054, 0.87692853,\n",
      "       0.86721749, 0.85073866, 0.86052744, 0.81851039, 0.89289929,\n",
      "       0.88292474, 0.8809434 , 0.88191272, 0.8773762 , 0.89072597,\n",
      "       0.8453515 , 0.88688176, 0.85786323, 0.87658113, 0.86980189,\n",
      "       0.8395931 , 0.86948248, 0.8690698 , 0.87260822, 0.86433719,\n",
      "       0.87196563, 0.87980432, 0.86540266, 0.87489909, 0.88638862,\n",
      "       0.86265122, 0.87197553, 0.86449985, 0.87958203, 0.86639423,\n",
      "       0.88661317, 0.87730529, 0.88341972, 0.88369573, 0.87176211,\n",
      "       0.87185269, 0.8893129 , 0.87302363, 0.85582134, 0.87442473,\n",
      "       0.88908809, 0.86357928, 0.87752346, 0.87317663, 0.87595583,\n",
      "       0.8897489 , 0.86972354, 0.87362891, 0.87080938, 0.8645487 ,\n",
      "       0.88955885, 0.86091582, 0.81264047, 0.86522896, 0.85554896,\n",
      "       0.7950341 , 0.87572466, 0.88006596, 0.88450804, 0.89150494])] \n",
      "\n",
      "mean AUC :  0.8691709794532797\n",
      "All std:  [array([0.00936024, 0.00837431, 0.00379941, 0.02244678, 0.02355944,\n",
      "       0.03080391, 0.08160457, 0.0333686 , 0.01977053, 0.00582472,\n",
      "       0.01979228, 0.02015247, 0.00845828, 0.02092277, 0.00964947,\n",
      "       0.01147029, 0.0253168 , 0.00875723, 0.01008373, 0.03074793,\n",
      "       0.02396334, 0.02357285, 0.03816049, 0.0182688 , 0.01410981,\n",
      "       0.0119576 , 0.00892852, 0.04248553, 0.01115188, 0.01485529,\n",
      "       0.00916715, 0.01137671, 0.02625147, 0.0142538 , 0.00757269,\n",
      "       0.008529  , 0.0432195 , 0.02095016, 0.08993907, 0.02620947,\n",
      "       0.01148077, 0.0102562 , 0.02688526, 0.02625591, 0.01346938,\n",
      "       0.02533374, 0.02570014, 0.00965236, 0.05002077, 0.01974648,\n",
      "       0.01132832, 0.03295468, 0.0651397 , 0.04988135, 0.03484143,\n",
      "       0.02606482, 0.03967528, 0.01081289, 0.01506249, 0.00928072,\n",
      "       0.01190964, 0.02547701, 0.04433843, 0.03512441, 0.00832088,\n",
      "       0.03321211, 0.01402556, 0.02010012, 0.00887753, 0.03034907,\n",
      "       0.01706674, 0.00848361, 0.02893557, 0.00926602, 0.03940311,\n",
      "       0.02739166, 0.0332428 , 0.02149878, 0.01509288, 0.00829376,\n",
      "       0.04823704, 0.01439554, 0.01604041, 0.01978382, 0.01243928,\n",
      "       0.01469862, 0.03769501, 0.02646964, 0.02755227, 0.01121739,\n",
      "       0.04658155, 0.02179883, 0.02683716, 0.02039717, 0.02006623,\n",
      "       0.01474833, 0.01922737, 0.01725122, 0.05214538, 0.01512793,\n",
      "       0.04097622, 0.0078181 , 0.02450373, 0.01184448, 0.00880414,\n",
      "       0.02419328, 0.09116322, 0.01001796, 0.08367205, 0.01464663,\n",
      "       0.00850432, 0.01871087, 0.01046889, 0.01302287, 0.01190124,\n",
      "       0.01125206, 0.01137003, 0.01764342, 0.01986834, 0.03237045,\n",
      "       0.02527836, 0.02359557, 0.05586676, 0.03719129, 0.00568089,\n",
      "       0.04634511, 0.02468079, 0.00520801, 0.01438791, 0.00863931,\n",
      "       0.00898189, 0.04787631, 0.0126028 , 0.01219533, 0.03049059,\n",
      "       0.01209899, 0.015825  , 0.0077087 , 0.02519754, 0.01005658,\n",
      "       0.02089813, 0.01179851, 0.03046401, 0.10178362, 0.01650479,\n",
      "       0.013841  , 0.01334769, 0.00642616, 0.0094813 , 0.01699165,\n",
      "       0.08348582, 0.00944417, 0.01128877, 0.02167845, 0.02645814,\n",
      "       0.0140935 , 0.02474441, 0.03205008, 0.02632779, 0.03037904,\n",
      "       0.0253445 , 0.00591263, 0.02876452, 0.02653787, 0.00496897,\n",
      "       0.01146297, 0.02741429, 0.04322468, 0.015938  , 0.0285507 ,\n",
      "       0.01507977, 0.02195459, 0.00764241, 0.01326401, 0.02797284,\n",
      "       0.0253382 , 0.0122988 , 0.02286518, 0.01099239, 0.00947238,\n",
      "       0.01139942, 0.0109096 , 0.02009621, 0.00840891, 0.00910185,\n",
      "       0.01582617, 0.02501147, 0.02581255, 0.0089203 , 0.01172918,\n",
      "       0.01101916, 0.04350799, 0.1118598 , 0.00643401, 0.04094005,\n",
      "       0.06349933, 0.00463331, 0.01504022, 0.01238223, 0.01513825])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.38181818181818183, 'min_child_weight': 80, 'max_depth': 18, 'gamma': 1.9596161616161614, 'eta': 0.08239785684528515} \n",
      "\n",
      "Best index/iterasi :  97\n",
      "Best AUC : 0.8932207474039224 ( std: 0.01725122161709839 ) \n",
      "\n",
      "running time:  7761.685734987259  detik. Dalam menit:  129.36142891645432  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  72 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.8848522 , 0.85755453, 0.87588336, 0.8773104 , 0.87558672,\n",
      "       0.89188611, 0.84499969, 0.8483773 , 0.88046322, 0.8749451 ,\n",
      "       0.87953355, 0.86033593, 0.87566166, 0.88161351, 0.88064486,\n",
      "       0.86732356, 0.87529552, 0.87645167, 0.87679957, 0.87936295,\n",
      "       0.8731927 , 0.89024869, 0.8622333 , 0.84783534, 0.88213296,\n",
      "       0.87976929, 0.86452332, 0.88845733, 0.87210921, 0.87625552,\n",
      "       0.86791259, 0.86899062, 0.87849587, 0.86070284, 0.89320966,\n",
      "       0.87198238, 0.8732275 , 0.87226647, 0.87412038, 0.84204863,\n",
      "       0.88739141, 0.88864771, 0.87695317, 0.88691938, 0.85766669,\n",
      "       0.8761383 , 0.88779441, 0.8758259 , 0.87730224, 0.84631969,\n",
      "       0.87081262, 0.84143873, 0.8358177 , 0.87223895, 0.87520469,\n",
      "       0.87958746, 0.88555574, 0.86219262, 0.87550557, 0.86148704,\n",
      "       0.87350766, 0.89489351, 0.87911315, 0.88440355, 0.85176329,\n",
      "       0.87195573, 0.87749718, 0.86468518, 0.87163017, 0.88058635,\n",
      "       0.87947663, 0.87441565, 0.86893046, 0.87830772, 0.85069276,\n",
      "       0.87644604, 0.87656821, 0.87227253, 0.86954848, 0.87792384,\n",
      "       0.88448204, 0.86989632, 0.85050748, 0.87343179, 0.88049667,\n",
      "       0.87037788, 0.88359506, 0.88342215, 0.87489476, 0.89302666,\n",
      "       0.87174338, 0.87685794, 0.89232625, 0.88938671, 0.87894567,\n",
      "       0.8691752 , 0.87496044, 0.86394419, 0.87167098, 0.87695467,\n",
      "       0.86255166, 0.88908817, 0.88053864, 0.87433367, 0.87294868,\n",
      "       0.85366829, 0.8615639 , 0.86359751, 0.87596456, 0.87437941,\n",
      "       0.88898895, 0.86877332, 0.85500438, 0.89416856, 0.8561706 ,\n",
      "       0.870318  , 0.87350678, 0.8721658 , 0.81731809, 0.87783274,\n",
      "       0.87783353, 0.87538659, 0.87084374, 0.87728312, 0.86867005,\n",
      "       0.89284237, 0.8709627 , 0.86831961, 0.88797529, 0.88161568,\n",
      "       0.8766073 , 0.83143268, 0.88935583, 0.86308577, 0.87416715,\n",
      "       0.87430751, 0.85768483, 0.89677408, 0.88493395, 0.82532011,\n",
      "       0.88173895, 0.85152122, 0.86495544, 0.86907761, 0.8895872 ,\n",
      "       0.87642893, 0.85850489, 0.88828935, 0.87702611, 0.84591968,\n",
      "       0.89058391, 0.86661624, 0.88153868, 0.89397533, 0.88019714,\n",
      "       0.89152824, 0.87379661, 0.89297555, 0.83833167, 0.88019347,\n",
      "       0.87586485, 0.85466652, 0.88016487, 0.88794757, 0.8850168 ,\n",
      "       0.87121297, 0.86307717, 0.87472556, 0.83805215, 0.87836886,\n",
      "       0.87856616, 0.88801683, 0.88797576, 0.87039551, 0.84796176,\n",
      "       0.88977764, 0.87126768, 0.87792124, 0.87551174, 0.87752081,\n",
      "       0.84396484, 0.84984468, 0.86772074, 0.8379684 , 0.87198698,\n",
      "       0.87486336, 0.86328156, 0.84918878, 0.87738219, 0.80098955,\n",
      "       0.85842216, 0.87420279, 0.86440619, 0.87923446, 0.87578102,\n",
      "       0.86777033, 0.85551863, 0.85643345, 0.86472072, 0.85832813])] \n",
      "\n",
      "mean AUC :  0.8715860079551807\n",
      "All std:  [array([0.01235389, 0.01093899, 0.01237923, 0.01748549, 0.00503955,\n",
      "       0.01508677, 0.07329164, 0.05277691, 0.02195853, 0.01979861,\n",
      "       0.01031865, 0.03337962, 0.02224962, 0.01461666, 0.01013038,\n",
      "       0.0098285 , 0.00783591, 0.0109533 , 0.01336566, 0.01594244,\n",
      "       0.00791855, 0.01286347, 0.01074069, 0.07910105, 0.01268497,\n",
      "       0.00623209, 0.03813692, 0.0154446 , 0.02502978, 0.01762009,\n",
      "       0.0364739 , 0.0355456 , 0.01659139, 0.03133676, 0.01187934,\n",
      "       0.0246518 , 0.00848002, 0.02613445, 0.01076514, 0.05550151,\n",
      "       0.01276902, 0.01163866, 0.00900513, 0.0117473 , 0.04095989,\n",
      "       0.01577844, 0.01207629, 0.00806448, 0.01963459, 0.07844503,\n",
      "       0.02556843, 0.09061429, 0.06433771, 0.02531632, 0.02558623,\n",
      "       0.01542028, 0.01134871, 0.01116891, 0.01342891, 0.03849381,\n",
      "       0.00816809, 0.0165649 , 0.01575955, 0.01194133, 0.07275635,\n",
      "       0.02439055, 0.01863556, 0.01079853, 0.00665899, 0.01640595,\n",
      "       0.02154312, 0.02183585, 0.03318601, 0.01775169, 0.01177006,\n",
      "       0.00933717, 0.01390363, 0.00838284, 0.01216134, 0.01059353,\n",
      "       0.00508091, 0.02540305, 0.03583972, 0.00797836, 0.0083851 ,\n",
      "       0.00540297, 0.00998609, 0.01035055, 0.01968496, 0.01637676,\n",
      "       0.0214097 , 0.01732715, 0.01436463, 0.01194549, 0.01326039,\n",
      "       0.02374693, 0.01949784, 0.03307044, 0.00815367, 0.00933438,\n",
      "       0.01098998, 0.0150063 , 0.01457427, 0.00865933, 0.02346344,\n",
      "       0.05371163, 0.03355012, 0.01628164, 0.01037551, 0.01910306,\n",
      "       0.01261359, 0.02314042, 0.05191217, 0.01315759, 0.01050093,\n",
      "       0.0202776 , 0.00774936, 0.02591721, 0.10518244, 0.02025902,\n",
      "       0.01844497, 0.00867736, 0.02549519, 0.02111885, 0.009887  ,\n",
      "       0.01558612, 0.02577197, 0.02641302, 0.01264241, 0.00599315,\n",
      "       0.00914524, 0.10549081, 0.01571857, 0.02500746, 0.02603786,\n",
      "       0.02620434, 0.04613647, 0.0148287 , 0.01429403, 0.08724959,\n",
      "       0.01432248, 0.04950406, 0.02348955, 0.01809124, 0.01187588,\n",
      "       0.02056108, 0.03767155, 0.01457576, 0.01942609, 0.04967196,\n",
      "       0.00942893, 0.00980048, 0.01081117, 0.0158533 , 0.00595935,\n",
      "       0.01473253, 0.02068945, 0.01389065, 0.05326444, 0.02177826,\n",
      "       0.02024356, 0.04565502, 0.01385643, 0.01298824, 0.01165055,\n",
      "       0.00752721, 0.01061676, 0.0255708 , 0.07092388, 0.01665721,\n",
      "       0.00544258, 0.01402338, 0.01143617, 0.02572   , 0.04017417,\n",
      "       0.0140607 , 0.02306725, 0.02165822, 0.01749765, 0.0130418 ,\n",
      "       0.03852412, 0.04001143, 0.03244819, 0.08062448, 0.00811892,\n",
      "       0.01254653, 0.01336813, 0.07555675, 0.01797167, 0.02588683,\n",
      "       0.02561084, 0.02300189, 0.02923121, 0.01750686, 0.01383242,\n",
      "       0.03892518, 0.0110426 , 0.03396523, 0.04504513, 0.04381994])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.3181818181818182, 'min_child_weight': 61, 'max_depth': 86, 'gamma': 0.7077171717171717, 'eta': 0.07850456200204509} \n",
      "\n",
      "Best index/iterasi :  137\n",
      "Best AUC : 0.8967740825292576 ( std: 0.01482869713338525 ) \n",
      "\n",
      "running time:  7570.104618549347  detik. Dalam menit:  126.16841030915579  menit\n"
     ]
    }
   ],
   "source": [
    "seeds=[62,72]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=random_search(X_income,y_income,model_x,hyper_space_2,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:24:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  82 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.87018855, 0.8394892 , 0.88326647, 0.85594457, 0.86860321,\n",
      "       0.81530675, 0.88656136, 0.89376485, 0.87104501, 0.89112842,\n",
      "       0.89024169, 0.86457567, 0.8752118 , 0.86877965, 0.88370933,\n",
      "       0.86767519, 0.85679208, 0.86933837, 0.89341747, 0.87737044,\n",
      "       0.87622357, 0.87800614, 0.88771759, 0.85428789, 0.87879197,\n",
      "       0.86436124, 0.87646253, 0.87623811, 0.86949173, 0.87214361,\n",
      "       0.8758139 , 0.88136046, 0.85825776, 0.87555064, 0.88075972,\n",
      "       0.87916089, 0.87956911, 0.86449912, 0.87136955, 0.87001274,\n",
      "       0.87695785, 0.86794873, 0.8615839 , 0.86821075, 0.87728492,\n",
      "       0.88855368, 0.87490496, 0.8727144 , 0.87078669, 0.88657193,\n",
      "       0.87460065, 0.86328319, 0.87536729, 0.88645824, 0.86288629,\n",
      "       0.8888586 , 0.86981273, 0.8786814 , 0.86612548, 0.85729932,\n",
      "       0.89212821, 0.85731425, 0.87213958, 0.8823682 , 0.87291171,\n",
      "       0.85805917, 0.82953322, 0.83846402, 0.87272821, 0.87606569,\n",
      "       0.88969594, 0.89254873, 0.87330756, 0.8349421 , 0.8509311 ,\n",
      "       0.87299197, 0.8796871 , 0.89159427, 0.87372102, 0.87740161,\n",
      "       0.86756913, 0.88207314, 0.87250515, 0.88005694, 0.87599892,\n",
      "       0.87850673, 0.87746807, 0.87133148, 0.87687826, 0.88800468,\n",
      "       0.89013159, 0.81147101, 0.87968486, 0.87711506, 0.88838223,\n",
      "       0.87425073, 0.89202156, 0.88086414, 0.87650459, 0.86795644,\n",
      "       0.87990024, 0.88849437, 0.87212408, 0.87471744, 0.84279205,\n",
      "       0.87186249, 0.88153009, 0.85749133, 0.87403592, 0.86647325,\n",
      "       0.87900646, 0.87951079, 0.85815015, 0.87263505, 0.87079339,\n",
      "       0.88677355, 0.82204892, 0.85851909, 0.86965728, 0.8849873 ,\n",
      "       0.87670052, 0.89410338, 0.86835326, 0.87223239, 0.87357672,\n",
      "       0.88684717, 0.84689566, 0.87782174, 0.81512755, 0.87755425,\n",
      "       0.85624807, 0.87089719, 0.86273752, 0.87668366, 0.87085462,\n",
      "       0.85654351, 0.87389184, 0.88540333, 0.81796381, 0.87108221,\n",
      "       0.87488159, 0.87945705, 0.87687531, 0.87330016, 0.76833871,\n",
      "       0.87680585, 0.86890269, 0.82899919, 0.83441585, 0.85259098,\n",
      "       0.88796419, 0.88959008, 0.86539757, 0.87371246, 0.88953057,\n",
      "       0.89044782, 0.8727577 , 0.86719826, 0.88926518, 0.87592645,\n",
      "       0.87011081, 0.88075792, 0.88213514, 0.89053228, 0.87067383,\n",
      "       0.86124004, 0.87538662, 0.86682448, 0.87665761, 0.87045716,\n",
      "       0.86576449, 0.86722536, 0.87057301, 0.87284735, 0.86249741,\n",
      "       0.87767581, 0.89523493, 0.87615344, 0.87559352, 0.8642733 ,\n",
      "       0.86199153, 0.83762154, 0.89453053, 0.85768054, 0.84984703,\n",
      "       0.83955938, 0.87508773, 0.86761582, 0.89361371, 0.87158239,\n",
      "       0.87590966, 0.87475473, 0.83145562, 0.8687306 , 0.82880511,\n",
      "       0.89041019, 0.89599069, 0.87856357, 0.88170647, 0.87025445])] \n",
      "\n",
      "mean AUC :  0.8706819645722976\n",
      "All std:  [array([0.02720099, 0.01864384, 0.00761147, 0.02349807, 0.02374413,\n",
      "       0.10441808, 0.01478839, 0.01539093, 0.02528183, 0.01242923,\n",
      "       0.01344172, 0.0102345 , 0.01897102, 0.02734196, 0.00625693,\n",
      "       0.00997402, 0.01148728, 0.02984987, 0.01453196, 0.01895031,\n",
      "       0.01518668, 0.02054885, 0.01420461, 0.04635722, 0.01612755,\n",
      "       0.03562972, 0.01334831, 0.01995004, 0.02321014, 0.02582078,\n",
      "       0.00852464, 0.01174883, 0.05801951, 0.02711515, 0.00496477,\n",
      "       0.01725283, 0.0160287 , 0.01828597, 0.00826616, 0.00912776,\n",
      "       0.00990423, 0.00672898, 0.01184816, 0.00712504, 0.01377778,\n",
      "       0.01040262, 0.01484583, 0.01764766, 0.02280087, 0.00985299,\n",
      "       0.01056493, 0.04816459, 0.00949906, 0.00958296, 0.01101778,\n",
      "       0.00811117, 0.02329853, 0.01602694, 0.02781843, 0.01139642,\n",
      "       0.01561565, 0.01077647, 0.02408773, 0.01453649, 0.02146751,\n",
      "       0.05220982, 0.00753107, 0.08725259, 0.00941023, 0.01381836,\n",
      "       0.008703  , 0.01178236, 0.00949691, 0.0788365 , 0.04912134,\n",
      "       0.02600166, 0.00570406, 0.01485271, 0.02741621, 0.01848008,\n",
      "       0.02510307, 0.01576843, 0.0253676 , 0.02210023, 0.01100216,\n",
      "       0.00494281, 0.01204878, 0.0096186 , 0.0125535 , 0.01442402,\n",
      "       0.01293338, 0.12125085, 0.02036631, 0.02069937, 0.01380369,\n",
      "       0.02512328, 0.01511885, 0.01436718, 0.00924737, 0.02546873,\n",
      "       0.01128089, 0.01328998, 0.02645436, 0.00851961, 0.02543595,\n",
      "       0.00840895, 0.01456956, 0.04061303, 0.00901122, 0.01046571,\n",
      "       0.01527785, 0.00662091, 0.03034412, 0.0077081 , 0.00725675,\n",
      "       0.01214927, 0.09805594, 0.05587495, 0.02341411, 0.00572219,\n",
      "       0.01591911, 0.0137403 , 0.02096196, 0.02568513, 0.02720586,\n",
      "       0.01016989, 0.01044871, 0.00835879, 0.09537024, 0.01910962,\n",
      "       0.01159638, 0.02484533, 0.0251212 , 0.01390016, 0.02723779,\n",
      "       0.03344982, 0.02753516, 0.00863402, 0.1113016 , 0.02505853,\n",
      "       0.00933267, 0.01666878, 0.00946665, 0.00791515, 0.03940311,\n",
      "       0.01864908, 0.0321307 , 0.0068448 , 0.01538092, 0.02285612,\n",
      "       0.01309496, 0.01690733, 0.01017317, 0.0260079 , 0.00961612,\n",
      "       0.01232768, 0.03378275, 0.03207613, 0.01024597, 0.02085372,\n",
      "       0.02360434, 0.01461346, 0.01326004, 0.01366243, 0.02501376,\n",
      "       0.02790794, 0.01437354, 0.00992995, 0.01998115, 0.02557955,\n",
      "       0.01833431, 0.02505154, 0.02112564, 0.02553491, 0.02678486,\n",
      "       0.01859043, 0.01541141, 0.01719989, 0.02383666, 0.04035954,\n",
      "       0.00523075, 0.02264082, 0.01685904, 0.0301822 , 0.06346677,\n",
      "       0.05745596, 0.00845221, 0.03579755, 0.01367132, 0.01642398,\n",
      "       0.024841  , 0.01999333, 0.06027897, 0.00974765, 0.00662051,\n",
      "       0.01093401, 0.01384948, 0.00834262, 0.00619563, 0.00886765])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.4545454545454546, 'min_child_weight': 87, 'max_depth': 26, 'gamma': 1.8586565656565655, 'eta': 0.2052637752709252} \n",
      "\n",
      "Best index/iterasi :  196\n",
      "Best AUC : 0.8959906949782847 ( std: 0.013849476633379298 ) \n",
      "\n",
      "running time:  7012.552988529205  detik. Dalam menit:  116.87588314215343  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:26:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Seed:  92 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.87007269, 0.87439326, 0.88342991, 0.84231309, 0.89294951,\n",
      "       0.85713548, 0.87677719, 0.89052365, 0.88693645, 0.87642012,\n",
      "       0.87439284, 0.8951201 , 0.86560567, 0.89158849, 0.88167013,\n",
      "       0.80346926, 0.86025514, 0.88721725, 0.84478056, 0.87802242,\n",
      "       0.88406893, 0.87093632, 0.88618702, 0.86850363, 0.87336509,\n",
      "       0.87061732, 0.82164905, 0.88514895, 0.87131357, 0.85154675,\n",
      "       0.86670169, 0.87122478, 0.87138311, 0.86968848, 0.840714  ,\n",
      "       0.852254  , 0.86971386, 0.876982  , 0.82428903, 0.87334368,\n",
      "       0.88761653, 0.88430563, 0.85234045, 0.85692424, 0.82081649,\n",
      "       0.86955296, 0.87580212, 0.85115453, 0.87824352, 0.88027462,\n",
      "       0.88417578, 0.87950185, 0.87896018, 0.87522058, 0.89069949,\n",
      "       0.87431594, 0.87395552, 0.85146855, 0.85961538, 0.86093304,\n",
      "       0.86902218, 0.88978734, 0.87145032, 0.87126773, 0.87155639,\n",
      "       0.82609486, 0.87363776, 0.86425315, 0.87741533, 0.8758548 ,\n",
      "       0.87984821, 0.878053  , 0.87837637, 0.86602704, 0.87436434,\n",
      "       0.86775944, 0.8749546 , 0.87515178, 0.89185084, 0.87391587,\n",
      "       0.8656936 , 0.82786238, 0.87336464, 0.88714337, 0.87778476,\n",
      "       0.8933856 , 0.89061026, 0.87742839, 0.89317011, 0.82412459,\n",
      "       0.88498011, 0.83793826, 0.87018684, 0.87003692, 0.86331426,\n",
      "       0.87960193, 0.87536236, 0.83933326, 0.88223873, 0.89289278,\n",
      "       0.88656075, 0.88267924, 0.86798666, 0.87529206, 0.87280661,\n",
      "       0.88453931, 0.88471342, 0.86953704, 0.87079486, 0.86744513,\n",
      "       0.88615676, 0.87170142, 0.88603923, 0.88098114, 0.87883115,\n",
      "       0.85840332, 0.87893678, 0.8695851 , 0.87303785, 0.86773936,\n",
      "       0.87102693, 0.87720171, 0.81195495, 0.87387463, 0.86441152,\n",
      "       0.86011384, 0.87143614, 0.87310405, 0.87558621, 0.88295263,\n",
      "       0.88100027, 0.86417918, 0.87763692, 0.87437394, 0.87636596,\n",
      "       0.85929065, 0.82730812, 0.86873877, 0.81887669, 0.86810311,\n",
      "       0.87016606, 0.89068167, 0.88225735, 0.8722034 , 0.87573816,\n",
      "       0.86444306, 0.89435908, 0.8749731 , 0.86824141, 0.88042539,\n",
      "       0.87730271, 0.87886696, 0.87408947, 0.87056375, 0.86345079,\n",
      "       0.89307947, 0.87246497, 0.87735698, 0.86778077, 0.86926392,\n",
      "       0.87878982, 0.85938421, 0.87914961, 0.83955413, 0.867811  ,\n",
      "       0.86302891, 0.87118036, 0.85569556, 0.88391755, 0.87702549,\n",
      "       0.85682138, 0.87720942, 0.88791528, 0.89453553, 0.81994311,\n",
      "       0.87389811, 0.8727298 , 0.86199808, 0.87727867, 0.85718828,\n",
      "       0.87766148, 0.82402911, 0.87265312, 0.87196006, 0.87508516,\n",
      "       0.87105661, 0.88576628, 0.87506394, 0.87623209, 0.84613452,\n",
      "       0.8570385 , 0.86305937, 0.87810485, 0.85371528, 0.89264713,\n",
      "       0.87741141, 0.87930406, 0.87843496, 0.86962173, 0.89587558])] \n",
      "\n",
      "mean AUC :  0.870302989081294\n",
      "All std:  [array([0.02470791, 0.02344444, 0.01260471, 0.05050586, 0.01321955,\n",
      "       0.03809004, 0.0164137 , 0.01271204, 0.01523527, 0.02175024,\n",
      "       0.02103782, 0.01376602, 0.01087159, 0.01180834, 0.00677204,\n",
      "       0.04619636, 0.04136549, 0.01211474, 0.00519485, 0.01770752,\n",
      "       0.01137621, 0.02705134, 0.01018607, 0.0089076 , 0.00956657,\n",
      "       0.0095083 , 0.11378767, 0.00675341, 0.02507368, 0.04835943,\n",
      "       0.03114403, 0.02530065, 0.02357449, 0.02563749, 0.07991977,\n",
      "       0.06488472, 0.00457897, 0.00922347, 0.10250224, 0.00762861,\n",
      "       0.01141993, 0.01157873, 0.01222016, 0.03502042, 0.08857839,\n",
      "       0.0250472 , 0.01127673, 0.02845896, 0.00539116, 0.00640061,\n",
      "       0.00552841, 0.00498556, 0.01500756, 0.01113134, 0.01297413,\n",
      "       0.02210675, 0.02138798, 0.04870546, 0.03044329, 0.01190481,\n",
      "       0.01017069, 0.01363043, 0.03073881, 0.00897903, 0.02561471,\n",
      "       0.07232637, 0.02410878, 0.01033211, 0.01610948, 0.01867629,\n",
      "       0.00646519, 0.01063231, 0.01528761, 0.02343996, 0.01842622,\n",
      "       0.01759927, 0.01846397, 0.01882708, 0.01625225, 0.0064024 ,\n",
      "       0.03621622, 0.0207246 , 0.00959712, 0.01209882, 0.01726788,\n",
      "       0.01244987, 0.01506687, 0.01608458, 0.01478115, 0.00280202,\n",
      "       0.00706122, 0.02629881, 0.02362906, 0.02564157, 0.01064544,\n",
      "       0.00615571, 0.02062793, 0.08255482, 0.01436453, 0.01653178,\n",
      "       0.01094645, 0.00954758, 0.00895636, 0.02493715, 0.02519908,\n",
      "       0.00355561, 0.01143577, 0.00729456, 0.00842966, 0.03658754,\n",
      "       0.01345219, 0.00816831, 0.00739585, 0.00698744, 0.00626492,\n",
      "       0.03259865, 0.01781616, 0.01054427, 0.03050143, 0.03353677,\n",
      "       0.01229522, 0.02136894, 0.05643983, 0.00997124, 0.01023468,\n",
      "       0.03412682, 0.02969634, 0.00799067, 0.02232419, 0.01350084,\n",
      "       0.00706533, 0.04605103, 0.01764412, 0.02605171, 0.01330077,\n",
      "       0.0321071 , 0.05241086, 0.01008001, 0.08808523, 0.00607852,\n",
      "       0.00871358, 0.01721508, 0.00560647, 0.02624919, 0.02328432,\n",
      "       0.02522232, 0.01486954, 0.00872246, 0.02855607, 0.01116809,\n",
      "       0.01309804, 0.01324563, 0.02533406, 0.02538007, 0.04746874,\n",
      "       0.01530352, 0.02500684, 0.01185059, 0.02147823, 0.02396551,\n",
      "       0.01250899, 0.04258341, 0.02160956, 0.08859474, 0.02532801,\n",
      "       0.04688289, 0.00837008, 0.04969829, 0.01274732, 0.01976729,\n",
      "       0.03933783, 0.02035707, 0.01394568, 0.01350762, 0.1070439 ,\n",
      "       0.01119147, 0.02766292, 0.01156253, 0.02182219, 0.01091339,\n",
      "       0.01353634, 0.08713427, 0.00781727, 0.024925  , 0.02536395,\n",
      "       0.02536804, 0.01061633, 0.01993836, 0.02165748, 0.07283602,\n",
      "       0.04481279, 0.02118901, 0.01592871, 0.05416981, 0.0161492 ,\n",
      "       0.02016781, 0.00496618, 0.00749364, 0.02415479, 0.01556705])] \n",
      "\n",
      "Best Hyperparameter:  {'subsample': 0.17272727272727273, 'min_child_weight': 35, 'max_depth': 13, 'gamma': 1.5557777777777777, 'eta': 0.1101645949633657} \n",
      "\n",
      "Best index/iterasi :  199\n",
      "Best AUC : 0.8958755825029645 ( std: 0.015567049719128565 ) \n",
      "\n",
      "running time:  7325.425446271896  detik. Dalam menit:  122.0904241045316  menit\n"
     ]
    }
   ],
   "source": [
    "seeds=[82,92]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=random_search(X_income,y_income,model_x,hyper_space_2,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1(Bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T00:04:35.975194Z",
     "start_time": "2020-12-23T15:01:10.409578Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.5762058388168595, 0.697428641264036, 0.5999210157854928, 0.6495906855959842, 0.6447209454652031, 0.5442446855222829, 0.6951579574011202, 0.7102752271584232, 0.7376850212817643, 0.7151714252751994, 0.8165943144602882, 0.7217857431050326, 0.8163140706258278, 0.7357919519868986, 0.8148213313160344, 0.8089347827631688, 0.819529559779728, 0.8175814714984005, 0.8079925912855895, 0.8210091100885643, 0.8106865616822203, 0.8215476171283821, 0.5878378944236893, 0.8167733517998621, 0.8171294524807594, 0.7956607228735776, 0.8193766159192214, 0.8166090033957575, 0.7626356712992314, 0.8204026662160356, 0.5213964246163681, 0.7455500867511222, 0.790259637746804, 0.8113829145764877, 0.8198991368602165, 0.8162639415165012, 0.8156061234983325, 0.8136344785321643, 0.8052394331848902, 0.8170515920125653, 0.60287848192628, 0.811783843140546, 0.8133594249460443, 0.8144281439165791, 0.5960906233593406, 0.8083120463370244, 0.824989657461476, 0.795664132213639, 0.8098653703487262, 0.5642895632492692, 0.8211194808831143, 0.6188896333251306, 0.6679804834876852, 0.8038968054092412, 0.8167733517998621, 0.8214052332416124, 0.8185292407076303, 0.60287848192628, 0.7923800809346134, 0.8253461962341162, 0.817433087824383, 0.8222810852251669, 0.8222732544621809, 0.7885156460476016, 0.824552731371981, 0.8194523190573493, 0.816403277223476, 0.8186667940841683, 0.8104967850651476, 0.8177826625016484, 0.7254259727392265, 0.8144054683032538, 0.8174052670664265, 0.8198991368602165, 0.8168381458355102, 0.8242811272918761, 0.8079350685266652, 0.8210150084816871, 0.8177191996329418, 0.81762354425813, 0.7913895987624546, 0.7971752484517093, 0.8088452557525696, 0.7806074402871475, 0.8213874423607875, 0.8185552662304003, 0.8139479588741275, 0.815702729653847, 0.8198991368602165, 0.7760708475250434, 0.8155090457001523, 0.8121363265646526, 0.8222142854590995, 0.8245527038006468, 0.8194625839564081, 0.8253791499259756, 0.8176074601140252, 0.8145259546154693, 0.8115903226465834, 0.6190749410605974, 0.7732843844849943, 0.8112060700202413, 0.8161876875865116, 0.8105737919316494, 0.7170684039552835, 0.7905714696888835, 0.7654234421123831, 0.6870762974165833, 0.7910026103688064, 0.7284559660911287, 0.823813516492887, 0.8136893545262459, 0.8128778344793145, 0.8192122805852057, 0.824544702322191, 0.8030530306757065, 0.8057901750184487, 0.8219239862578044, 0.8157186728866795, 0.7646855902782648, 0.7839926214715619, 0.8151113004488623, 0.8115256991084125, 0.8244248072025464, 0.8175731004911699, 0.8169134899377838, 0.6668738393376492, 0.8167224404465948, 0.807549391163371, 0.8242874125834557, 0.8197935056519683, 0.823395371091523, 0.821419811907961, 0.8041198196653723, 0.6549510573134371, 0.8188196189019102, 0.8229929739617118, 0.7734597247700561, 0.8149419001067153, 0.8195135047451109, 0.6815527531995902, 0.8139151045441688, 0.8256458967903424, 0.823000645703299, 0.8239840257770012, 0.5458584669591765, 0.8206224395521673, 0.8127036572233378, 0.822323940012923, 0.824638675137291, 0.8111213233876087, 0.8223955936518681, 0.8224143734725844, 0.8237659463635617, 0.8072202304763206, 0.8228316216790624, 0.822980619048026, 0.823033606747131, 0.8238334597884802, 0.8265356100984104, 0.8240608920865324, 0.811948090507755, 0.8265120257452365, 0.8222771385790919, 0.8231201659923165, 0.8244073934127261, 0.8099482949529239, 0.8219115784415904, 0.8211713705796406, 0.8227671259460423, 0.8208590631143897, 0.8261985978633763, 0.8244248201507584, 0.8195546221864128, 0.8202129687877427, 0.8261669495115515, 0.8258903633388313, 0.8262271396477346, 0.8258905290342052, 0.8258450226681481, 0.8088657191033078, 0.8140252337096714, 0.8220650855364741, 0.8229123443037862, 0.824903708222105, 0.826433565230863, 0.8174231245845964, 0.8182859434821883, 0.824540737763435, 0.820487229080951, 0.7709607862275302, 0.8137847614428534, 0.8256201938093904, 0.8141062492116866, 0.8243959622922, 0.8271156755077339, 0.8269330491789598, 0.8128613134372866, 0.822928381632656, 0.8279033638129405]] \n",
      "\n",
      "mean AUC :  0.7902173223975779\n",
      "All std:  [[0.09452902663508038, 0.12275836136019672, 0.1320331564995393, 0.12642993797088142, 0.14088790304658377, 0.11451730796443778, 0.12518248014529965, 0.12619063164126854, 0.12371922506321494, 0.12109532917582702, 0.06988849195055868, 0.12375062291284325, 0.07407467068322714, 0.1310846498170913, 0.0737272569321898, 0.0755412709307418, 0.07192531993101015, 0.0724285983447619, 0.07343937663330075, 0.07153653884922484, 0.08008735614187525, 0.07225152409617037, 0.10527564559510483, 0.07277984710596537, 0.07283011628754349, 0.06966345338628037, 0.07251145995233935, 0.07470122264979247, 0.07966011384083922, 0.068312697131603, 0.08194695869882032, 0.11529234473273531, 0.07602626090794737, 0.07251721451301267, 0.07185155589751861, 0.07395057466318058, 0.07164704861666912, 0.07762481793326681, 0.07672735282156232, 0.07486513208652286, 0.07929183013716791, 0.06974919164629628, 0.07149029621284055, 0.07100161360325032, 0.10422034052498494, 0.06652811881796644, 0.06974146359641883, 0.06966986663404305, 0.07182708402092151, 0.1345778033220209, 0.07276829279141486, 0.09669385881601202, 0.15323580313273152, 0.07766908853121651, 0.07277984710596537, 0.0718083048781885, 0.0715962143877613, 0.07929183013716791, 0.0657305711420217, 0.07202510223777725, 0.0753449457371978, 0.07200821221955506, 0.06658747153699338, 0.05404060007317505, 0.07034665348026405, 0.07132899352264499, 0.07177615473035655, 0.06710320427231076, 0.07847215397145456, 0.07001971511008366, 0.12554353619641823, 0.07367369317729901, 0.07183150250769513, 0.07185155589751861, 0.07559585546180955, 0.07143520347608072, 0.06738237233031841, 0.07131780091370392, 0.06916812855167764, 0.07188801072615035, 0.07390130555154278, 0.0649372747943896, 0.06730927360125318, 0.08786563673095873, 0.0673525810912682, 0.06609364059973802, 0.0731582315979818, 0.07081723926287557, 0.07185155589751861, 0.08980501165018633, 0.07715255471721442, 0.0736281933215342, 0.07123162354566125, 0.07023005584024769, 0.06996711535304012, 0.07220238599952117, 0.0713651022760383, 0.07405798133328753, 0.0707563096494195, 0.09691813992657407, 0.08315734212706599, 0.07073431242200116, 0.0730589762166169, 0.07146585028096253, 0.10205280165517332, 0.08154283585704061, 0.09649572713568823, 0.1372688972495956, 0.05350216177252156, 0.09633913561891486, 0.06962925022558832, 0.07605179641915098, 0.06992165445221006, 0.06898382710286866, 0.07180476436681435, 0.07357025677111037, 0.07925757247198859, 0.06567660187596541, 0.06991770948120675, 0.03818816086373479, 0.04947745939792537, 0.0727203784037813, 0.07122733372396244, 0.07032439338045836, 0.07263715616657132, 0.069824366450064, 0.10409947948689835, 0.07063201401081066, 0.067426090241423, 0.06965323902794458, 0.07126304994413847, 0.07233521902558981, 0.07308605060213906, 0.07869387989794197, 0.13049007802280216, 0.07187864003740241, 0.06763852910618473, 0.08579685851412332, 0.07224196567103125, 0.06729696212096278, 0.160971249833903, 0.07082025590409861, 0.07089051795837685, 0.07046218194042632, 0.07186318157842206, 0.11677772567725234, 0.06986335016659298, 0.07388039750740515, 0.07192596233990461, 0.07147725868959526, 0.0752939783226872, 0.07224947341809704, 0.07008795239351727, 0.07228819779713738, 0.07588660726659288, 0.07251701228428932, 0.07255543724401396, 0.07231279206636154, 0.06988218990386547, 0.07145430827720967, 0.07221899490724455, 0.07683505805570949, 0.069376823674407, 0.07064651850206356, 0.07095746521054777, 0.07066149377128035, 0.07632325400124321, 0.06479809510776302, 0.06516000199842768, 0.07057228963596406, 0.07021320355725089, 0.07146348685352027, 0.07191985506978182, 0.07062409526897424, 0.07057517140397633, 0.0703139081712717, 0.06912080787581211, 0.0714395127820038, 0.06912107803149965, 0.06904542381219604, 0.07054924227728744, 0.0764822964880431, 0.07172376234387681, 0.06977101805690583, 0.06912493928401703, 0.061138597065352907, 0.07272495762335085, 0.07250257551971982, 0.06213518478676258, 0.06879295777579976, 0.09240634008438917, 0.06841986021758295, 0.05838919206591693, 0.06973315825947964, 0.062211950241257134, 0.05988897464372444, 0.061023370246725585, 0.07473729727326817, 0.06302521214282746, 0.05791917153596413]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.08059842301218641), ('gamma', 2.0), ('max_depth', 50), ('min_child_weight', 63), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  199\n",
      "Best AUC : 0.8279033638129405 ( std: 0.05791917153596413 ) \n",
      "\n",
      "running time:  3283.78160405159  detik. Dalam menit:  54.72969340085983  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  12 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.7210639171578557, 0.7248884090165653, 0.6191813298180681, 0.6832100213324429, 0.655205579759513, 0.6075362935637627, 0.6502076926208021, 0.8113538681686507, 0.8122137330976564, 0.7061795488113891, 0.7217857431050326, 0.8213548182999649, 0.8078413834872992, 0.8169779920066917, 0.7515276910023788, 0.802573426240922, 0.7946698219197954, 0.8119740370574886, 0.8101179297119826, 0.8051516802365318, 0.6689007743703953, 0.8208117547061238, 0.8149711349493993, 0.7930957259464386, 0.60287848192628, 0.7971752484517093, 0.7922411978283107, 0.808973588400908, 0.7897681071393065, 0.808303839837395, 0.7956607228735776, 0.6229333689189552, 0.7955521550496242, 0.8117204626410028, 0.8163223303823461, 0.8218508542323173, 0.8121167474629433, 0.8198991368602165, 0.8185797244337261, 0.8206332664660896, 0.8072493808803224, 0.82548195675462, 0.8059901080528155, 0.6971052162608365, 0.8095452883407561, 0.824054211016564, 0.8206701279811146, 0.8034154887559858, 0.8157185580885024, 0.7721571129091155, 0.8175884255253384, 0.825700213516226, 0.8219211552717501, 0.8169614765111077, 0.8109776113055949, 0.7871629222609912, 0.821921213653865, 0.8186779942713918, 0.8202531727911637, 0.8186132086310982, 0.6611591233694337, 0.8230611163699569, 0.7237554815738986, 0.7360887436388937, 0.8153198350315973, 0.8202411213777251, 0.8166473615428012, 0.8210455346724908, 0.8061158925299783, 0.785087522567672, 0.8122760641705912, 0.7998384550058125, 0.7922901724990767, 0.8165582800345217, 0.8190789507632718, 0.806001096994371, 0.8204236297737292, 0.8159266977173135, 0.8039407209848358, 0.7635774169034262, 0.8172387690360391, 0.8152063998328791, 0.8193766159192214, 0.7923800809346134, 0.7146415957206651, 0.822776883889652, 0.8152285270433307, 0.8117844500622954, 0.8198991368602165, 0.7962390474081421, 0.7948085481207932, 0.8080015868893236, 0.7930666148301343, 0.814200607378095, 0.731127608048343, 0.8180418942704845, 0.6538557261520551, 0.8162979236710859, 0.8198586214368179, 0.8117599994457999, 0.6170071727072929, 0.8212274146861639, 0.820249896236248, 0.7875436103543242, 0.8178709837991093, 0.8210704362075059, 0.8075882898005673, 0.8198991368602165, 0.8173079002990072, 0.5559927727607703, 0.7971752484517093, 0.7921645870926952, 0.6185206044322061, 0.5559927727607703, 0.8074148658487001, 0.6928434231966923, 0.8198991368602165, 0.813060810363353, 0.8083291879271567, 0.8129058335099755, 0.8233408478976956, 0.8211181331493707, 0.8171969269966499, 0.8171294524807594, 0.8197033762421383, 0.8182756207742962, 0.8155900095319049, 0.7923800809346134, 0.7830841255104098, 0.8116482133646499, 0.8152417369198208, 0.8167733517998621, 0.6686039418131978, 0.6679804834876852, 0.8145834800899147, 0.8165013496853162, 0.8054655547795888, 0.7226923295503908, 0.8173653648607887, 0.8097440346301665, 0.7772647998688058, 0.8209257847441064, 0.8129799497448761, 0.8172542007445781, 0.8113478690787426, 0.7735249925452725, 0.8171294524807594, 0.8118372471635351, 0.82155139522003, 0.8242461287838245, 0.7846515548974942, 0.8195147137533864, 0.8193766159192214, 0.8192470609693667, 0.7956607228735776, 0.8193766159192214, 0.8224250214831763, 0.8241816598995769, 0.7506527310420864, 0.8236259186045263, 0.8149556604680458, 0.8045979964559893, 0.6815527531995902, 0.802081475611466, 0.8024742822448251, 0.7951392752360668, 0.7830252855030266, 0.7296076119030187, 0.7780124698138129, 0.820583649826125, 0.8155900095319049, 0.7145961896446562, 0.820279856531388, 0.8149675884804648, 0.8178000491946461, 0.8191642114052213, 0.8011242142822574, 0.8239797794080096, 0.8171374219085589, 0.8255960515306199, 0.8140805299244688, 0.784903499636795, 0.8047994076332368, 0.8191905496830054, 0.8258611778957445, 0.8088404655766901, 0.717195781906944, 0.8193031133341756, 0.6744259008944636, 0.8158165833925269, 0.8145259546154693, 0.8174864939154551, 0.8171365804470895, 0.7872549404848419, 0.8198991368602165, 0.8100173013343505, 0.8166000704825511, 0.8159073805294185, 0.8186404686680305, 0.8198958237987019]] \n",
      "\n",
      "mean AUC :  0.7880104808206317\n",
      "All std:  [[0.12866925378945204, 0.13379386427319362, 0.09386882918170242, 0.12854502761231476, 0.11681530548501769, 0.12518061237818112, 0.11588289831245932, 0.07016042564687229, 0.0699874028638955, 0.1287655945345463, 0.12375062291284325, 0.0715438554093105, 0.0710484706594651, 0.07283163537602448, 0.11757276708821483, 0.06847690575833296, 0.07301965623987923, 0.07191793426199596, 0.0740352046027637, 0.07591719343292806, 0.15188970866897747, 0.07007105152947178, 0.07144107221603122, 0.08030585135442828, 0.07929183013716791, 0.0649372747943896, 0.06161845666105461, 0.07282903100115781, 0.07281341414337993, 0.07588990757848872, 0.06966345338628037, 0.09742352111372882, 0.06378535727286673, 0.07411893446346375, 0.07245637550076775, 0.0715219836174283, 0.07008387577179898, 0.07185155589751861, 0.07179140408953032, 0.07294644290792128, 0.07496873571790966, 0.06867280099226966, 0.07798696516383019, 0.14552395518172703, 0.07413045556911588, 0.07214837483373747, 0.07317029899337808, 0.07797385838224564, 0.08005851939973671, 0.07866710779146098, 0.07028748032256472, 0.07145722404805487, 0.07247689083427647, 0.07026134529807246, 0.07231919699316966, 0.07828739774150315, 0.07206173136139479, 0.07351373088860022, 0.07265986873726368, 0.07119830559194411, 0.16368104571910994, 0.07044011417670838, 0.12784780913612956, 0.11521606335907227, 0.07516382148968986, 0.06915545825169896, 0.07228357255232974, 0.07164386236810501, 0.07745429569929706, 0.061927924806885394, 0.07321274437994592, 0.08152478251883719, 0.06956596737295606, 0.07343208381154012, 0.0688757887628414, 0.06777361855257148, 0.07096504366114649, 0.06907301389795822, 0.08176279268660713, 0.08324614720619168, 0.07094648645270679, 0.08092472068559094, 0.07251145995233935, 0.0657305711420217, 0.09904994994435887, 0.06949020512899023, 0.0726146117331307, 0.07119057421573328, 0.07185155589751861, 0.0872788092791112, 0.07561267878748251, 0.0725649891116356, 0.0883763696964374, 0.07989191544058134, 0.09849646131354065, 0.07299460527294949, 0.11680036975694885, 0.07236806602041199, 0.07215338736523058, 0.06151713227979307, 0.09438506004594852, 0.06613184505445374, 0.065940856452401, 0.05804339547222644, 0.07063929463154228, 0.07111841420914969, 0.07516054467668114, 0.07185155589751861, 0.06963091321111486, 0.12566082099029077, 0.0649372747943896, 0.08038775620823393, 0.09638504068331455, 0.12566082099029077, 0.06688623880443129, 0.13814952926361052, 0.07185155589751861, 0.07358201856199026, 0.07402794017217156, 0.07425109316275696, 0.07044935360595554, 0.06480242487847167, 0.07256934024139883, 0.07283011628754349, 0.07156773450953542, 0.07146807761125802, 0.07450187762954832, 0.0657305711420217, 0.058835845670690445, 0.08052205489808575, 0.07379426757355723, 0.07277984710596537, 0.15099114324726898, 0.15323580313273152, 0.07457458243574629, 0.07371402841191707, 0.06856537696324255, 0.13023239655608881, 0.07185669288816632, 0.07007901046819823, 0.07723753859504694, 0.07065341653371061, 0.08003810490200024, 0.07292763601177613, 0.07030704994972116, 0.07699853324060954, 0.07283011628754349, 0.07443769000237795, 0.06941403721803521, 0.06439482888224428, 0.04986702507264684, 0.0706916853604187, 0.07251145995233935, 0.0719441273893753, 0.06966345338628037, 0.07251145995233935, 0.06492688075166275, 0.06404600081453085, 0.08665238692610393, 0.0669565442587724, 0.07864054804433153, 0.07713600300108861, 0.160971249833903, 0.08020148816417318, 0.08028395548055231, 0.0812751896029302, 0.08574725214807695, 0.10632416827103594, 0.0835350443026719, 0.07152845309228303, 0.07450187762954832, 0.09916952734265325, 0.07084045583094511, 0.07751483931244564, 0.07169595151396843, 0.0686970609833407, 0.08174330814287592, 0.06332466071863203, 0.07053136922105357, 0.06184117828688129, 0.06880566393144454, 0.07802039813208826, 0.07236080453386688, 0.06814237699252101, 0.07005596594288599, 0.06712618269722839, 0.10221903780064101, 0.07177101377877977, 0.15724862957956282, 0.07405058012411876, 0.07405798133328753, 0.07239605748002177, 0.06936732617890176, 0.08201644593992992, 0.07185155589751861, 0.07320839778601373, 0.07171771958370286, 0.0671600693312308, 0.06691167757701445, 0.070095164940256]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.003396098736081857), ('gamma', 0.001), ('max_depth', 52), ('min_child_weight', 84), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  184\n",
      "Best AUC : 0.8258611778957445 ( std: 0.07005596594288599 ) \n",
      "\n",
      "running time:  3419.5358164310455  detik. Dalam menit:  56.99226360718409  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  22 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.7512180343810191, 0.6903754665866721, 0.6535129310587742, 0.49281288740092805, 0.7411470804124137, 0.787220426393716, 0.5836504064621469, 0.6942327588858503, 0.7132708091172258, 0.5779919665789722, 0.7364226754931611, 0.6218029543904725, 0.8127442274730414, 0.7125232535794379, 0.8066506375920705, 0.7976144926146052, 0.8135335297242349, 0.7973769143228383, 0.8103879671964535, 0.6013511093943682, 0.711599907902288, 0.8132295053141606, 0.8164625746348911, 0.7857982687159996, 0.8116803407779355, 0.8080818238721509, 0.7923800809346134, 0.8183023618241593, 0.6039075938714511, 0.8056586071207235, 0.7772655026436147, 0.8001088672374873, 0.8253311852510536, 0.8109571627284657, 0.7902853591767377, 0.5949817187766036, 0.8193766159192214, 0.6826321911654994, 0.8211140999621587, 0.8123028132738184, 0.7259184668333204, 0.8168228100439887, 0.8181485480965317, 0.8143939877319504, 0.8142991968638985, 0.8178086896759686, 0.7634849964910677, 0.8119215493432695, 0.8022291090292558, 0.807692958899357, 0.7971752484517093, 0.7254259727392265, 0.8128553817563581, 0.8177188671267418, 0.8173930401381827, 0.8143366103310751, 0.8196902707871758, 0.8117476118579774, 0.8113847150403167, 0.8109554953687048, 0.8226123020365766, 0.60287848192628, 0.5148512275607904, 0.8017725483899265, 0.8164907377700084, 0.8138511094072224, 0.8202317415601885, 0.8124882555421444, 0.7944253938768928, 0.8165088416922489, 0.8193766159192214, 0.8164144104494973, 0.8251700508427787, 0.5559927727607703, 0.8213695849068102, 0.818576994437934, 0.8158812908650438, 0.806309173936523, 0.7217857431050326, 0.8119941807130011, 0.8169077290096971, 0.8165674996147092, 0.7923800809346134, 0.8150374358343947, 0.8231718501416961, 0.6679804834876852, 0.8238888786816424, 0.7870738455852354, 0.7146415957206651, 0.8154919519173588, 0.7817585739754137, 0.8192560687875176, 0.8222585807321408, 0.8157348701468056, 0.8130795926972952, 0.8073387102789449, 0.8126265017963265, 0.8177163082702298, 0.8152778356336343, 0.7755641513640905, 0.8180683600897076, 0.8154046677924494, 0.8136705523199352, 0.8064063153735469, 0.819984349466695, 0.7855231724209731, 0.8148391968574444, 0.8246694287232973, 0.8174376448532434, 0.8130573512053481, 0.8067644290021136, 0.8112767506426257, 0.8172570628550534, 0.7621178745558955, 0.7625157481887516, 0.8198991368602165, 0.6193453891931117, 0.8133257290561219, 0.8215474365049907, 0.7655143817797325, 0.8225303859898845, 0.8205647183006268, 0.711145584321938, 0.7738727522682165, 0.815659036099635, 0.8169652096554293, 0.8121094281772027, 0.8165721055285359, 0.8185125217013225, 0.813311088450129, 0.8136706391530999, 0.810943299260041, 0.8199221499064288, 0.815194804301855, 0.7130896291326954, 0.8175069052162128, 0.811271215176846, 0.8173406929458703, 0.8130906086448466, 0.8198039031851243, 0.8121717155868131, 0.6932824075151626, 0.7632237311718306, 0.8185075069049718, 0.7835709933390279, 0.60287848192628, 0.8058728595212797, 0.8050036428703072, 0.8110577431124228, 0.8144835463704317, 0.8173825680510138, 0.8169981685434893, 0.814014606297191, 0.8141994729672637, 0.8071541818540761, 0.8244992013676988, 0.7916091725789869, 0.8116475108657211, 0.7023131002787275, 0.760557879359397, 0.8097463749556371, 0.60287848192628, 0.5117907159988211, 0.6832935710260707, 0.8116726997673996, 0.8249187955975777, 0.8219466881518244, 0.8140083790190353, 0.8260091513144086, 0.8084218185130557, 0.7830841255104098, 0.7884440414176624, 0.7829934668216968, 0.8175792740531713, 0.808756727992206, 0.5564798591927466, 0.7654158228521212, 0.8193117407695121, 0.8265189855354419, 0.8236586683286841, 0.804326513985849, 0.7050063086562449, 0.6910939096131319, 0.8214939404339173, 0.8172886095632227, 0.5477781827295479, 0.7059725281840062, 0.8115985416391304, 0.8238749259365473, 0.7871749407907064, 0.717195781906944, 0.8190326692694068, 0.8190922344197813, 0.6898806035575632, 0.7266845203732369, 0.8191170517358113, 0.8252470852053073, 0.825062687371506, 0.818387304811305, 0.8252085368659104]] \n",
      "\n",
      "mean AUC :  0.7773550552525432\n",
      "All std:  [[0.1141432055538272, 0.11982518712209088, 0.1304323712532874, 0.09193203420679676, 0.12845054681849447, 0.08265046211119162, 0.08286708278170549, 0.14492978813239452, 0.126921906669856, 0.12686722272204423, 0.13153455747870502, 0.09603509429954356, 0.07032997093446261, 0.11307636423605756, 0.07446344271243546, 0.07681463154706228, 0.07237778813857898, 0.06806101244549977, 0.07118662914035957, 0.0958284424618069, 0.13905299129675774, 0.07204448818141572, 0.07142237182590208, 0.07927196331870515, 0.073563768277902, 0.07377293426640749, 0.0657305711420217, 0.07071837756626534, 0.10860424183370194, 0.07068526761652484, 0.09604570601827146, 0.07257125655375295, 0.07197681413302305, 0.07127565582253279, 0.06718364360118866, 0.08835576989649531, 0.07251145995233935, 0.14019425514463138, 0.07190357181813944, 0.07974852079572085, 0.10844710247081887, 0.07565659115901953, 0.07314717919629908, 0.07592850047498266, 0.07983279117727668, 0.07268112775812627, 0.0815685683000935, 0.07462668292634708, 0.07285064864560481, 0.0735366973398667, 0.0649372747943896, 0.12554353619641823, 0.0728252830825076, 0.07118165162738854, 0.07130722916999363, 0.07332460893452605, 0.07223957056344797, 0.0639919781936679, 0.07309013899895939, 0.06948918332377688, 0.07156350264121833, 0.07929183013716791, 0.07710392321405968, 0.07963511378283063, 0.07518355088956667, 0.07843052774814181, 0.07198693919973487, 0.08153037092756135, 0.10069116675201681, 0.07282956173377299, 0.07251145995233935, 0.0738067522407967, 0.06910883087491998, 0.12566082099029077, 0.07121921046953872, 0.07190040957974084, 0.0738462620334124, 0.06979780496289216, 0.12375062291284325, 0.07793352510384075, 0.07437268805468775, 0.07409626927742444, 0.0657305711420217, 0.07104833708740689, 0.07287629991646884, 0.15323580313273152, 0.06968786544716303, 0.09233458629377107, 0.09904994994435887, 0.0719745508730114, 0.07328498688821658, 0.06749602712969043, 0.07243056194466145, 0.07463598547642743, 0.07134509653521152, 0.0682669292627697, 0.07289171672693384, 0.06985794328988842, 0.0734869666296893, 0.07995119134134689, 0.07155581320998404, 0.06990394579960112, 0.07703408051180516, 0.07330622436999552, 0.07097659075567105, 0.08303504834363205, 0.07116701996684778, 0.07205861334842549, 0.06990269916872642, 0.08026959617133064, 0.07883044160647669, 0.07484184531095818, 0.07025170250527954, 0.10621728805864739, 0.07909412620510176, 0.07185155589751861, 0.09722275890878986, 0.07474303869189243, 0.07155890018550967, 0.08925794837884946, 0.0723267779296115, 0.06874641401477923, 0.11976183197523026, 0.07949268687337391, 0.07679040041692559, 0.07252973168303206, 0.07998438868039892, 0.07379357193014618, 0.07010276989717039, 0.07115688386132066, 0.0755056799386893, 0.07622741625909023, 0.0661729851215342, 0.07037740555360657, 0.11445092099536461, 0.0738553900608035, 0.07853143231380919, 0.07247691902809568, 0.07451946876431849, 0.06901990888447887, 0.07265415403769772, 0.15025860493392051, 0.09138294994752372, 0.0692270299953392, 0.06544762152947588, 0.07929183013716791, 0.07702328447811643, 0.07943393489104972, 0.06661443139758699, 0.07371276801437518, 0.0702481238555921, 0.07230617288299845, 0.0777689854127306, 0.07729029383471486, 0.07016284622352202, 0.07133335855371184, 0.0807648574884977, 0.08029499157350639, 0.14027253728451378, 0.10376910722187976, 0.07554158891781104, 0.07929183013716791, 0.10777530848627474, 0.14783758488783175, 0.0694258270755419, 0.07204170805807111, 0.0722288682038478, 0.07358739188108174, 0.07005160637666606, 0.07658318019761919, 0.058835845670690445, 0.07850467824443161, 0.08859769553452178, 0.0704914124704103, 0.07679169425236634, 0.08073442728817165, 0.09382190028357183, 0.07161752524334478, 0.06961781974195833, 0.06970973042217836, 0.07028993616029564, 0.10804767044768786, 0.13281841970440592, 0.07071416693421759, 0.07308630927153839, 0.14535362312199965, 0.1431239127832294, 0.07599868244561174, 0.07119885603904592, 0.08463885632342, 0.10221903780064101, 0.0701771298185675, 0.07173722667170188, 0.1528848171226747, 0.12261648863654523, 0.07119526959463386, 0.06271797912040886, 0.06304759099127281, 0.06832185446122602, 0.06245679970022395]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.0032218022967337974), ('gamma', 0.001), ('max_depth', 67), ('min_child_weight', 85), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  178\n",
      "Best AUC : 0.8265189855354419 ( std: 0.06961781974195833 ) \n",
      "\n",
      "running time:  3630.605807542801  detik. Dalam menit:  60.51009679238002  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  32 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.7259085685647526, 0.6688075217882011, 0.6875024781966064, 0.6645467898311228, 0.8073312072752682, 0.670607287818999, 0.7283587768517721, 0.8000643152809753, 0.6081866762169749, 0.5889548555562387, 0.8215404804179223, 0.8157067210845674, 0.7247417781784061, 0.8206746426930801, 0.741177952372922, 0.8145449588955386, 0.8211252762466384, 0.6675155893361487, 0.8037139781100954, 0.8086051221497267, 0.8073059500282838, 0.8109669389898393, 0.8122629921252144, 0.7964953755877995, 0.8171333708655085, 0.8126691440154644, 0.7661211513588777, 0.8106398685772691, 0.7811568787022204, 0.8120392328453806, 0.8198991368602165, 0.778550294445405, 0.822330441794041, 0.6611591233694337, 0.8130237423445007, 0.8214469756868592, 0.817830245626205, 0.8154788869292926, 0.7956607228735776, 0.7254542185885011, 0.7923800809346134, 0.80097880428943, 0.8155125391314705, 0.60287848192628, 0.8184312514047721, 0.802843426922789, 0.8084327567830455, 0.7620935525348639, 0.7853994178120041, 0.8204865046656896, 0.8180936356907267, 0.811545626179178, 0.8229627618686669, 0.8177777747494831, 0.7905865053366072, 0.8187693721008761, 0.8253791499259756, 0.5148512275607904, 0.8182511076995099, 0.8086985213586826, 0.8064964128695244, 0.8240198496461412, 0.8008147150380113, 0.8221183475707428, 0.7552161184504746, 0.7377165381109784, 0.8084134515916814, 0.8216170125044959, 0.8253461962341162, 0.783902633481638, 0.8173966986387121, 0.7367532793891931, 0.8102019103836666, 0.811220843585947, 0.8120128408222389, 0.7998553061774843, 0.8155113724248171, 0.8263695351569247, 0.8266611068409883, 0.8199614115905256, 0.6190882588597723, 0.8257408508790046, 0.7156728414870284, 0.8243808928695268, 0.8074789891539979, 0.8198184698257664, 0.8248997408975205, 0.827896506338804, 0.8273136529732718, 0.792702627343779, 0.8030474348499816, 0.8057524008160026, 0.4963451385282809, 0.8260446532001868, 0.8156018308845286, 0.8273370797841543, 0.6209092055977117, 0.7814583330166868, 0.8029065393416903, 0.704612124554826, 0.7747960160406181, 0.8193766159192214, 0.8038437731711786, 0.8038506027583635, 0.8174627578467922, 0.8139042977952089, 0.8268504307915717, 0.8210192431707458, 0.8131293535566934, 0.8249056762841479, 0.818124206506495, 0.8173209800337857, 0.810248858718957, 0.6686039418131978, 0.8153539625840667, 0.8249942048762737, 0.8156040335924254, 0.8249474223061605, 0.8263407367323574, 0.5636276483912398, 0.8179145588240281, 0.8249517233586643, 0.824087778545122, 0.815135549973934, 0.8220358916093771, 0.8162924772305974, 0.815606693198584, 0.8185570507043729, 0.8270334767338685, 0.8118941999709037, 0.8271171122457079, 0.8214273133222644, 0.8214807750402308, 0.8255440117032734, 0.8261225887469312, 0.8231608343170863, 0.8292261027699155, 0.8271726215271124, 0.8257919126009649, 0.8241178202476089, 0.8128776549200977, 0.8186424987574041, 0.8248101182656842, 0.8291704546791803, 0.8280652813518596, 0.8260544756541375, 0.8262542782888325, 0.8242455334471808, 0.8257641914204529, 0.8240592234495668, 0.8275920861476437, 0.8254749764204745, 0.8284658506484047, 0.8259280219898243, 0.8272541370504032, 0.826830639160818, 0.8271845595213319, 0.828755076094246, 0.8259353443199435, 0.8283154255101792, 0.8274766542969724, 0.8284077716334353, 0.8271844697026758, 0.8276568550044057, 0.8269481407745402, 0.8193664639360939, 0.8270189581262657, 0.8262468055177827, 0.8243272742207682, 0.8264580722901846, 0.8271618724846052, 0.8261176892862276, 0.8290035261441681, 0.8279938393304545, 0.8288060426059735, 0.8252503907194904, 0.8279483285445811, 0.8276645291744713, 0.8279778363405593, 0.8274761175741818, 0.828529174220841, 0.8273455419747373, 0.8283059739759524, 0.8239156386216776, 0.8282505154261061, 0.8283208249055863, 0.8191185253213545, 0.8288368223564462, 0.8277550384884227, 0.8279749221913985, 0.8264096726237542, 0.8276269467698235, 0.8271951856822534, 0.8286412794739976, 0.827380590743692, 0.8290403902370893, 0.8256914779898485, 0.8265067778549595, 0.8278865704018249, 0.8240024382049361]] \n",
      "\n",
      "mean AUC :  0.7985504317344819\n",
      "All std:  [[0.11965199309047538, 0.12731197392722607, 0.12553582680294098, 0.1174367752963176, 0.06693933576363133, 0.12941382601718235, 0.12245091230752883, 0.07675438845797097, 0.06738180396650245, 0.12249608463206664, 0.07128628593401155, 0.07330942923573006, 0.12536652149191024, 0.07234290437406092, 0.12395402875680957, 0.07116035771032303, 0.07270175805287431, 0.1501102015331656, 0.07308925735449738, 0.0740910092356974, 0.08060831798640443, 0.07312750812210471, 0.06936049238153559, 0.07219940620045442, 0.07283550563057076, 0.08014740056869744, 0.12093457708432966, 0.07973030474901549, 0.07401457977168942, 0.07065348732416565, 0.07185155589751861, 0.10602821259109563, 0.07261222157699325, 0.16368104571910994, 0.07051768961572526, 0.07075033601204263, 0.0723837136201822, 0.07481397939112881, 0.06966345338628037, 0.12555064203033273, 0.0657305711420217, 0.08083331566968864, 0.07298556893775512, 0.07929183013716791, 0.07086410761668445, 0.06649716809705619, 0.07181582100352336, 0.10167262795857528, 0.08623715949721716, 0.07315409641418076, 0.06564239630244505, 0.06585555239763065, 0.06508644970712417, 0.07259175398387084, 0.06804274449266784, 0.06941655753645697, 0.07220238599952117, 0.07710392321405968, 0.06745195065607865, 0.07626991122037162, 0.0793266694790212, 0.06101945659890613, 0.07051782522508558, 0.06937796335713793, 0.09251886440127122, 0.10002611696947875, 0.06952228596293164, 0.0715719042756803, 0.07202510223777725, 0.08182678659159878, 0.07285230884814015, 0.11252258635633106, 0.07874467401775681, 0.08001448612376098, 0.0717759848319173, 0.08340406069019467, 0.07642633017346609, 0.060823505063952836, 0.06158727463161116, 0.07320972874281473, 0.09688778477423797, 0.07087841711072813, 0.10030284539647467, 0.07194626988921593, 0.0745561313370699, 0.07272784811358494, 0.07259768115908673, 0.05983032249471401, 0.06016017536084712, 0.07348395921309799, 0.0790018741520849, 0.07885679498147198, 0.0788931208933876, 0.059571632989142954, 0.07044519172400807, 0.06202550284010543, 0.09878239135774332, 0.07800368002278286, 0.07135266856156099, 0.15618743166348678, 0.08978271435341859, 0.07251145995233935, 0.07487093028332145, 0.07750904415736116, 0.07230915891778474, 0.06385928348616371, 0.060665307450676845, 0.06605089348209824, 0.07238446824033064, 0.061461369695726374, 0.06944783727256486, 0.0707149211050158, 0.07348183148446269, 0.15099114324726898, 0.07224884972736083, 0.061270786498584605, 0.07211440566240351, 0.06139383834115084, 0.06063153429188266, 0.1248725512839524, 0.0699600103104188, 0.06182728192474996, 0.0722096017083292, 0.07317407236415838, 0.06529406715962802, 0.07269025578763474, 0.07011924918813724, 0.07054768661817915, 0.05833231963282792, 0.06956678696723174, 0.06104858690281706, 0.07231111440045863, 0.06980951366086192, 0.058370511765392374, 0.062010264782558326, 0.0628131887502769, 0.05899563512873987, 0.058617139357149226, 0.05995016346272368, 0.06081192789731034, 0.07719953791463048, 0.06453311575424858, 0.06077986648821614, 0.06007085497282035, 0.06159220860847742, 0.06014592457449741, 0.05800138065607964, 0.06110439677781263, 0.05848975535824639, 0.07222001852990334, 0.05983935229221473, 0.05959327047302244, 0.060414255547616605, 0.06207283591488911, 0.06091581910103452, 0.05991221902275517, 0.05936377181489188, 0.061116909831394645, 0.062030382395078694, 0.05933505073890463, 0.05930525481628056, 0.061481746937599766, 0.05932981790331296, 0.06039995609276679, 0.06093569532525572, 0.07112578281789451, 0.059335440953589766, 0.06130236743158337, 0.06213534351199883, 0.060188826889457134, 0.058615458790551404, 0.059513045774893754, 0.05948047142148115, 0.05910366656636787, 0.060110331490005026, 0.06166015974513668, 0.0617457192897538, 0.061364889030161525, 0.059412595809274216, 0.062198518483724895, 0.06069280980448222, 0.0582773183190849, 0.06191248310162241, 0.06057685554993361, 0.05905824233339068, 0.06160359658806047, 0.07200923415599554, 0.06026866886233918, 0.06039844869642312, 0.058738679517504014, 0.06084584280307238, 0.05965846415417321, 0.05881074706284861, 0.05873135625227188, 0.05836753948347867, 0.06067496831606685, 0.061312386804389225, 0.05715503642640228, 0.06133501593252449, 0.06398003309031174]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.10566640330311981), ('gamma', 2.0), ('max_depth', 33), ('min_child_weight', 64), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  136\n",
      "Best AUC : 0.8292261027699155 ( std: 0.05899563512873987 ) \n",
      "\n",
      "running time:  3055.0756661891937  detik. Dalam menit:  50.9179277698199  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  42 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.6728863333909728, 0.5917980930356215, 0.7553334313517351, 0.6527296532815826, 0.5987948951407229, 0.5508661983089084, 0.6999729811213202, 0.749920993985091, 0.5982246820475154, 0.6774460169308562, 0.821292379899359, 0.8198991368602165, 0.8252334231206784, 0.7329476585672086, 0.7220490410554313, 0.7849760289816327, 0.7971986264578361, 0.7769741134725131, 0.682482344148106, 0.8092400593724525, 0.6699492125329869, 0.8173510977018115, 0.8049536904274102, 0.8166569155909236, 0.7138574590142938, 0.8167091151754534, 0.8179615786705288, 0.812388020655945, 0.8192635379759627, 0.8043603809184097, 0.8228971213573207, 0.8198991368602165, 0.8209568281132859, 0.8193766159192214, 0.4779938162894927, 0.8239620648464697, 0.8203312149446783, 0.717195781906944, 0.8163676741403492, 0.7956607228735776, 0.8196285969399592, 0.6686039418131978, 0.816179761322736, 0.7898011282975507, 0.8187909637342043, 0.821189670809355, 0.8165578829997785, 0.7743732561361324, 0.8218337180444811, 0.8036812289602018, 0.817477126506975, 0.808404142932003, 0.8207654741489099, 0.8169652096554293, 0.8069239936056666, 0.8213390139290706, 0.8162378688634803, 0.8210657728799122, 0.8120556920260212, 0.8087995885208646, 0.6872338247034969, 0.8256550744347513, 0.8072393094427924, 0.80452700066581, 0.8175950045635955, 0.8269427472744688, 0.8183244981979213, 0.8217417150508368, 0.8107160390425835, 0.8159370542452377, 0.824984364678406, 0.5856762346215362, 0.8177339088284927, 0.8175869020125063, 0.8145189386407952, 0.8097487200942886, 0.727376059190645, 0.7859833094361681, 0.6954057281412138, 0.8114524623072221, 0.8180731735294342, 0.8177339088284927, 0.8188947408685624, 0.7656096096666638, 0.8135458096359208, 0.8144632173478096, 0.8154003652995405, 0.7895694163647543, 0.7254172763985237, 0.820899243639688, 0.8163682803862651, 0.8183611526691668, 0.7604269910349412, 0.8150169988449688, 0.8259632283780902, 0.7835709933390279, 0.8252570828927552, 0.8143881829051219, 0.8117261001300471, 0.7650603667441274, 0.8243542728772734, 0.8161848916107762, 0.8171330103867278, 0.7480966923626712, 0.8216712376307985, 0.7956607228735776, 0.8141684032987089, 0.8205279213769255, 0.7959724248890903, 0.8206072234142875, 0.8216125113136569, 0.60287848192628, 0.8174549240986135, 0.818335359181773, 0.7635990972709741, 0.60287848192628, 0.8225159153793328, 0.8140795987325022, 0.8258518426371219, 0.8250860838372596, 0.7574697713803382, 0.8166859420882989, 0.8169921805856691, 0.8257663901680841, 0.8133473323465652, 0.8242724487200135, 0.8071826524857845, 0.8233246109974544, 0.8262248034353086, 0.7956607228735776, 0.794468377948631, 0.8173808344791583, 0.8257780542233946, 0.8226304936429728, 0.8205164462930478, 0.8255726842561484, 0.8258156423393013, 0.8212115858591568, 0.8249478118111752, 0.8187420203668826, 0.8221507807936846, 0.8256752118096863, 0.8186456823958179, 0.8213177872528667, 0.8244535332153985, 0.8210993996869099, 0.819656738951545, 0.8253692282832076, 0.8296180541427381, 0.8254802156423492, 0.8213984240201206, 0.8273935337498923, 0.826084906025864, 0.8226615773530569, 0.8292682934894511, 0.8226390274509089, 0.8278822254167764, 0.8256829898286556, 0.8268602762999475, 0.8250969792507753, 0.8283733158217856, 0.8257639951819152, 0.8195815985726551, 0.8282191989811759, 0.828899515316819, 0.8291631964279933, 0.8260509805209884, 0.8257376921903343, 0.8096132553096435, 0.8072405686850653, 0.8120351321681089, 0.814851448716373, 0.8257120534702357, 0.825287717530215, 0.8267631886072311, 0.8143425034156541, 0.8272131742992852, 0.8205908707830113, 0.825553341373684, 0.8256609593036726, 0.8293919764429969, 0.8247023355535462, 0.8288203114311586, 0.8279654312267628, 0.8179944683155231, 0.8287003116912303, 0.8287227888081948, 0.8245430408496176, 0.8256997523256636, 0.8256314689826734, 0.8261821328833501, 0.8275293489097292, 0.8265096635597118, 0.8268199055338538, 0.8173706990859217, 0.8271264681720801, 0.8230855031099842, 0.825755682624794, 0.8246649847688282, 0.8258481266409415]] \n",
      "\n",
      "mean AUC :  0.7967598500951266\n",
      "All std:  [[0.13905486673803774, 0.10346259583927483, 0.11212680263828191, 0.12613767286559385, 0.12296720340703346, 0.09038299078125099, 0.12516431866898922, 0.11243765800352705, 0.0895842802290618, 0.13260697823208084, 0.07144165296716644, 0.07185155589751861, 0.0695428732691897, 0.12793025329415397, 0.13197390607002626, 0.06124281936748993, 0.07793580439640833, 0.08982419283935858, 0.07008953560476006, 0.06767485249527493, 0.15109158035826073, 0.07398886036708224, 0.06534342615175628, 0.0726035354303897, 0.1387863880839894, 0.07278934835322358, 0.07197414288939082, 0.07340237802654127, 0.07208628500886159, 0.07648721803935324, 0.07235861869769261, 0.07185155589751861, 0.07211405549950653, 0.07251145995233935, 0.08241794913515171, 0.07245398462119682, 0.07136748877575219, 0.10221903780064101, 0.06917266085028424, 0.06966345338628037, 0.07021025675557663, 0.15099114324726898, 0.07330118272384573, 0.07553020611220491, 0.07141215864741962, 0.0712463836202063, 0.07148722831441187, 0.05597615443400654, 0.07018979640225886, 0.07768576322703973, 0.07202663130568873, 0.06929496991169024, 0.07136748069285768, 0.07252973168303206, 0.06799722452912003, 0.07258101930276274, 0.07287657651869012, 0.06726097097963249, 0.07223369899622947, 0.07536282493900905, 0.13929091976124114, 0.06968167621387507, 0.07338807041925371, 0.07878014921975295, 0.07346593417295251, 0.06936731802214527, 0.07156698538358679, 0.07241792202223869, 0.07284573113590864, 0.07416347274495633, 0.07078794649407795, 0.11130868023995176, 0.07121142823076601, 0.07356950395165286, 0.07422190316669744, 0.07449862269594959, 0.12798099163674076, 0.07972631044709659, 0.13581829877276988, 0.07218849765227396, 0.07065994916909722, 0.07121142823076601, 0.06826264905313482, 0.09342862608511596, 0.07079461089108528, 0.07880651937163262, 0.07202040468968261, 0.07839394400970937, 0.1255437186469168, 0.06806714853599592, 0.07406988151431927, 0.07311533442685815, 0.10787388134683126, 0.07277256504931001, 0.05834219615203199, 0.06544762152947588, 0.06076977758274914, 0.07145357273023785, 0.06593877006466309, 0.0876264052488116, 0.06366558770362997, 0.07598380832880854, 0.06820943217049324, 0.1105243363092452, 0.06907409626596518, 0.06966345338628037, 0.07387092472051107, 0.06426931378173174, 0.06904040162355746, 0.07229530143001954, 0.0716138908118382, 0.07929183013716791, 0.07032380695533642, 0.06447585744889874, 0.09458353859618418, 0.07929183013716791, 0.07178791791930011, 0.07472567368268104, 0.07068378305686276, 0.07169154212667105, 0.08784805785753903, 0.07077562006910444, 0.07212251864533081, 0.06086823141259368, 0.06895149107454782, 0.07042988739577392, 0.0780058621452716, 0.05952631405804672, 0.0713854896572257, 0.06966345338628037, 0.07239033926103179, 0.06970111934455421, 0.07013837128197214, 0.06189856768222366, 0.07072852474402094, 0.07012261521953658, 0.06895517992427365, 0.07077668841266052, 0.0719604332159209, 0.0718250906762143, 0.062398526836126025, 0.05992967367147601, 0.0699300926445635, 0.06982028793259318, 0.06405102886476065, 0.07282822264345139, 0.07056526194601044, 0.07171036161469752, 0.05985521543731752, 0.059929745878993114, 0.07182717773639082, 0.059984655303327916, 0.0598213484916251, 0.06152490953759585, 0.05871519395310706, 0.07207636289927769, 0.06050335946855326, 0.058391181293861456, 0.060031355804950726, 0.060045799857921134, 0.06037910897096978, 0.05865869565466981, 0.07143325025163187, 0.057544982832826434, 0.06047840938200051, 0.060808495499241784, 0.05881468955518662, 0.0692360448004003, 0.07476781368157702, 0.07850011325640292, 0.08062730529828586, 0.0725858682142746, 0.059503715631116554, 0.06973045186516809, 0.06264515233536672, 0.07820338727814576, 0.0696516829030491, 0.0724785771783701, 0.06848692270895702, 0.06075525523652856, 0.05934441342258018, 0.06099875697591492, 0.06050402390663208, 0.06004285313227458, 0.07266118075163511, 0.06091331023656592, 0.06201885564079532, 0.07100066482429766, 0.0701427604489327, 0.061780872269703746, 0.059149943757777386, 0.05875603473256552, 0.05869807741157448, 0.059790020388490996, 0.06963190782495257, 0.06184503095376607, 0.06948518700603863, 0.06264095241102882, 0.05918431170968064, 0.06068419174716842]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.10449415206564538), ('gamma', 0.001), ('max_depth', 33), ('min_child_weight', 64), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  148\n",
      "Best AUC : 0.8296180541427381 ( std: 0.05985521543731752 ) \n",
      "\n",
      "running time:  3193.6800076961517  detik. Dalam menit:  53.228000128269194  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  52 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.6639900936365498, 0.813792990197006, 0.5286890583269858, 0.6126212997303856, 0.7598957390664348, 0.6695938814088672, 0.7129585846810387, 0.688489490725811, 0.6211294060745476, 0.6064880578455869, 0.7709663370677032, 0.821503848669217, 0.7536703742034299, 0.8108401966172101, 0.6870036758230461, 0.801189686917456, 0.8005545808245367, 0.717195781906944, 0.8198656769099228, 0.824574712996386, 0.7988170324479246, 0.8184762531666402, 0.7997374205934465, 0.8242028545082882, 0.8234305630081853, 0.7954275854822238, 0.8232667346552109, 0.8175269133303324, 0.8203425346434691, 0.8209225893507731, 0.7403488036467757, 0.8102540753238255, 0.7254542185885011, 0.7971752484517093, 0.6611591233694337, 0.80474134454191, 0.8153827832196634, 0.724307232055249, 0.812442083349109, 0.8070793779747082, 0.8172606263110566, 0.7923800809346134, 0.6675182958362468, 0.8140420141349072, 0.7922035982033776, 0.8194620180878264, 0.7652223436281681, 0.7880804687186227, 0.7778968942550204, 0.8220721778881012, 0.8233459166578944, 0.6161148179973174, 0.7458294152624383, 0.8123847876276813, 0.8080507615441621, 0.8150943941771491, 0.8070681196598445, 0.6942393519436942, 0.8117120556508979, 0.7267745410808325, 0.8173352743003425, 0.8122548808134608, 0.8195062401808867, 0.8207140148031675, 0.8185731838194811, 0.8103667450924648, 0.8132445618624908, 0.8177703449785546, 0.7532793326411216, 0.8086948831540055, 0.8017640222308637, 0.8198676657379631, 0.810759450919801, 0.8117066016693063, 0.8212771580429439, 0.6189426605300637, 0.8238288319356666, 0.8175408409573562, 0.8122867834447366, 0.810146958078783, 0.7551266276046673, 0.8186031181614731, 0.8024986680889057, 0.8083730082023717, 0.8203937385569019, 0.6709715819107821, 0.80082233812992, 0.8118907448996261, 0.8239840257770012, 0.8170217670118388, 0.8159193111450347, 0.818329924680806, 0.8224990629099062, 0.8198991368602165, 0.8189701913174787, 0.8254185007811122, 0.8247439774064256, 0.7903667249064456, 0.8159244546397314, 0.8219244358502712, 0.8175823347407174, 0.8261309925352649, 0.810692871859014, 0.8072605645227199, 0.8082874477366975, 0.8020886228413473, 0.8241969409096523, 0.7664076593691938, 0.8244540996461374, 0.8132587551570077, 0.8205989912197904, 0.8073215705938657, 0.7838479898334918, 0.8082017387650496, 0.7839769701748953, 0.8052845836374406, 0.8250289369557038, 0.8206916643071498, 0.8033424076865715, 0.8136513390870324, 0.8223014638557105, 0.60287848192628, 0.8148122806438102, 0.8226938339720457, 0.8227032268122135, 0.7989704744472889, 0.8081875379190581, 0.8178532249626134, 0.817939855579798, 0.8150997360399165, 0.8198991368602165, 0.8157938967423556, 0.8138911812474426, 0.8106941930392431, 0.8224996915617417, 0.7775110360338412, 0.8212624635004097, 0.7669538050318498, 0.8147974847362445, 0.8178985855162993, 0.7785770263856969, 0.6832935710260707, 0.7767450700285512, 0.8170247692425575, 0.7923800809346134, 0.8265428020581901, 0.8107355776784806, 0.7511963767694451, 0.7133935524758147, 0.8123322323388814, 0.5618492899265131, 0.8198522373253676, 0.7596674405565731, 0.8214039127800894, 0.8191682202528585, 0.8173111861560036, 0.8091754439445533, 0.8119902724029856, 0.8165582800345217, 0.8161574429932408, 0.8070657623183605, 0.8242495556020197, 0.8112393280715093, 0.820904653806374, 0.8198991368602165, 0.7956607228735776, 0.8240853962038502, 0.8189681309919866, 0.8112242740444414, 0.7649898451860694, 0.8193766159192214, 0.8197912091125056, 0.8183693941011922, 0.8190922344197813, 0.8152778356336343, 0.8151432311918694, 0.8151641984762061, 0.8209817431270813, 0.8186096127143284, 0.8170878100097607, 0.824608016311243, 0.7966093545803051, 0.7773503812222734, 0.8197009597562164, 0.8059362404857956, 0.7208560122555314, 0.821259669890025, 0.7926766813428398, 0.8211269713144475, 0.8151493156616151, 0.816681959593714, 0.8266578800664403, 0.8262240153747707, 0.8232182759110085, 0.7621220395815598, 0.8149568426654183, 0.8076810519920472, 0.8166048338109689, 0.8262428091669584, 0.8195912800879851]] \n",
      "\n",
      "mean AUC :  0.7910527041901197\n",
      "All std:  [[0.11679218638317432, 0.06523029941628823, 0.11541470501443973, 0.07184206780173687, 0.0942639713098194, 0.13066190970407465, 0.1396483033939101, 0.12735444895575868, 0.11620703146286021, 0.08451811751400393, 0.1203622477802212, 0.07134977117229724, 0.11889489168179558, 0.07480420653178536, 0.13708158195164552, 0.07602396129625547, 0.08230958743181717, 0.10221903780064101, 0.07180487136805833, 0.07259063250520921, 0.08040707566328414, 0.07087502931835778, 0.08200506875713753, 0.07091583972958952, 0.07246363190174733, 0.0789555070163925, 0.07290176248095614, 0.07093635497576056, 0.0692682670516364, 0.07164807785814045, 0.15777899620342295, 0.07110313747111816, 0.12555064203033273, 0.0649372747943896, 0.16368104571910994, 0.0771962036413879, 0.07428209780100087, 0.12850638224210015, 0.07047829025596503, 0.06728666740239596, 0.07335996151147334, 0.0657305711420217, 0.1526328709191636, 0.06786572927881711, 0.07255001995733011, 0.07295127098787516, 0.097101228024763, 0.08644220146266518, 0.06554534295475954, 0.06423859156082921, 0.06470992127427397, 0.09462065459855898, 0.09409232495011269, 0.07127829303908358, 0.07694146646413998, 0.08095983537612958, 0.06848420043434335, 0.09953854886652025, 0.07084007739787926, 0.12733960065767194, 0.0768776534769411, 0.07325795797610764, 0.06681708349940577, 0.06546069253997656, 0.07015212095487956, 0.06431946662352543, 0.07199009488315654, 0.07020136604675212, 0.1049031233681859, 0.07536894687414067, 0.0762467543681019, 0.06294572910272603, 0.08350372928534296, 0.07382700922789603, 0.07141724558434322, 0.09677443332383256, 0.06252935056012111, 0.07523194274622334, 0.0720973822410919, 0.08074643069787951, 0.10891716210556944, 0.06482295637226662, 0.06901846907245564, 0.08491059219403314, 0.06905225022877423, 0.12604082683416273, 0.0738517486465057, 0.07063861344720207, 0.07186318157842206, 0.07292048554522294, 0.07386461359786169, 0.07357651283490589, 0.06275686913530426, 0.07185155589751861, 0.06414605012989275, 0.06132378890589641, 0.07127605260118244, 0.07508061571329884, 0.07478937914880784, 0.07205931506206815, 0.07199527431613258, 0.05920403505548938, 0.06427349713494783, 0.0666109411593311, 0.07713309062410657, 0.080733005163674, 0.07012708479609416, 0.12545496525622338, 0.061279902205962924, 0.07003347605888623, 0.07084377510684538, 0.07920497224743545, 0.10822926190249081, 0.06749358167831893, 0.09458469786432906, 0.0851756184274996, 0.06887766561888013, 0.06199071969687372, 0.06701054796893136, 0.06464741100275563, 0.07089599729971142, 0.07929183013716791, 0.07195383840175822, 0.06501657227430432, 0.06260569159360371, 0.08209340651036748, 0.06287855023928272, 0.06977263160190991, 0.07051370329169335, 0.07360906099551591, 0.07185155589751861, 0.06629958772917716, 0.0753070590504967, 0.0706978555938854, 0.06313133854216262, 0.09001701758126412, 0.07268084052300075, 0.1182469603271293, 0.07542182799367773, 0.07481681181662635, 0.11976875525572289, 0.14783758488783175, 0.09034032398389163, 0.07125315660305434, 0.0657305711420217, 0.05955172194972905, 0.06627573786717017, 0.13532765718937573, 0.10689813520620553, 0.07186070538438753, 0.11645439716350987, 0.06691720634229342, 0.11425420599063064, 0.07197648411879765, 0.06962218525155005, 0.07172947925460262, 0.07168046925558905, 0.07135912597503241, 0.07343208381154012, 0.06769271839991353, 0.07776080227837591, 0.06151537412492576, 0.06472199835368445, 0.07016190451870477, 0.07185155589751861, 0.06966345338628037, 0.07044564076359529, 0.06715551651401151, 0.07483572444071204, 0.10657488614664457, 0.07251145995233935, 0.0626368793217083, 0.07079986784046005, 0.07173722667170188, 0.0734869666296893, 0.07850800110837806, 0.06991328984857287, 0.07005073256647659, 0.068401480514898, 0.07282010486761017, 0.06293965217933507, 0.0867911878261491, 0.09595574998278136, 0.068536645019812, 0.06952614958030237, 0.14844010851007974, 0.0726424692686137, 0.07945691462304652, 0.0727641765090133, 0.07313900997820073, 0.07004457710521157, 0.07114068782141779, 0.06996981071320364, 0.07214237649967754, 0.08098805256382416, 0.07235107251652134, 0.07857512472552658, 0.07290737459650858, 0.07016619616348221, 0.0707072895157106]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.0030223813418263296), ('gamma', 2.0), ('max_depth', 54), ('min_child_weight', 87), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  191\n",
      "Best AUC : 0.8266578800664403 ( std: 0.07114068782141779 ) \n",
      "\n",
      "running time:  3116.8465218544006  detik. Dalam menit:  51.94744203090668  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  62 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.7811469637278838, 0.6751302507759408, 0.818374843735007, 0.7799085648436208, 0.6375097279097013, 0.686482939169422, 0.6155742817490043, 0.695108242222344, 0.5898029628075167, 0.6797866090930024, 0.7880469171444717, 0.8151132264036713, 0.8229711617637219, 0.8159362825927391, 0.7217857431050326, 0.8174052670664265, 0.8172433669398709, 0.8250939814241884, 0.8180317339743777, 0.7237554815738986, 0.8154551882616927, 0.8130650008122134, 0.60287848192628, 0.8010199006746234, 0.8227185070050105, 0.8173406929458703, 0.8208557772126817, 0.8144080486270234, 0.8218385660525472, 0.7947080848279162, 0.6545713010091974, 0.8173472874298666, 0.8163957707658533, 0.8255495193860252, 0.7687370891532426, 0.8182780718312435, 0.8153459106539463, 0.8180310459870455, 0.8153460291191738, 0.7245506920168883, 0.8159658972760707, 0.7905865053366072, 0.8253791499259756, 0.6792043152525205, 0.8131021765716494, 0.6888570385655872, 0.6990198838603481, 0.8173631542065553, 0.823486334865483, 0.8117544808997076, 0.8124949803197872, 0.7830929701180147, 0.8206482192241912, 0.7975445702260732, 0.8204567279213176, 0.8093907092316079, 0.8005934346766492, 0.8065767371053739, 0.60287848192628, 0.8123397683004686, 0.8099545520666523, 0.8181330935294475, 0.7022924166376775, 0.8249060307114615, 0.509184491281605, 0.7634407841901386, 0.7653847024162057, 0.7956607228735776, 0.7966444527772871, 0.7984761250727685, 0.8176774051285219, 0.8253319431637987, 0.7116681011792643, 0.8207454085678401, 0.7864366956263824, 0.7914648834591049, 0.8253791499259756, 0.8224893136435838, 0.8053568288878318, 0.8033104521514761, 0.8184310021937038, 0.8195798198904909, 0.8235664721537531, 0.8093108118297416, 0.8164154521022317, 0.8187939377655596, 0.8142466976139908, 0.7802545131484314, 0.7455642900206143, 0.8180068467920462, 0.8073495252735893, 0.8168576282851547, 0.7932640014477661, 0.8137209812083445, 0.7727707974119906, 0.8176029979157317, 0.809078840087168, 0.60287848192628, 0.8195285945879783, 0.8217166835255141, 0.8231546732530346, 0.8082561843014433, 0.8247087384034321, 0.8224342249149267, 0.8022453070055672, 0.8214238122320787, 0.8205674367064723, 0.8067182607237581, 0.6832935710260707, 0.8166647979228506, 0.814730071802331, 0.8162654032650124, 0.7834701859666282, 0.7146415957206651, 0.8208585273857796, 0.8160402957090824, 0.8120047389443469, 0.7669568541985194, 0.7987485038140218, 0.815234425953704, 0.7991949583049648, 0.8203976048627464, 0.8289578913377945, 0.5095119195629089, 0.6815527531995902, 0.6834412644722081, 0.7571632250155009, 0.5567171372279929, 0.7254542185885011, 0.8260433194968203, 0.8264880031510463, 0.8172411453426942, 0.8107481032150872, 0.7097096492458126, 0.8127020440223357, 0.8199667526385256, 0.7848813168512955, 0.8035274456086636, 0.8242434986842718, 0.8285357299183858, 0.7285022966190486, 0.82626543279228, 0.6857199757656542, 0.6932351074712627, 0.8238015195131851, 0.8234604468258815, 0.826485041238218, 0.8126238920424882, 0.8240133274219352, 0.7776374191214563, 0.7243757578863932, 0.781276268883172, 0.8251239386511396, 0.820421276534248, 0.8250256061004472, 0.8152235959388813, 0.8282807331200732, 0.8258697730948392, 0.8183294966761132, 0.8274402110909866, 0.824859378710537, 0.8272032594402207, 0.8283361240944892, 0.7670811906091796, 0.6611591233694337, 0.8227252142287437, 0.826525467423973, 0.8271008439964678, 0.8290688511215069, 0.8266504479795304, 0.7621255534420504, 0.8278060916472618, 0.8246576220853601, 0.8280839536971264, 0.8206534238902727, 0.8205972864359923, 0.8251420213439874, 0.8200882746227601, 0.8259299988755772, 0.8276195588588586, 0.8261411598713188, 0.8253461962341162, 0.8277646662453164, 0.8278015926068533, 0.8288467132432235, 0.8289994423090717, 0.8243114548556143, 0.8251948404873264, 0.8271040331153424, 0.8274809566051776, 0.8257074778855995, 0.8249572373491066, 0.8263167513075202, 0.8269266727286124, 0.8252115819435534, 0.8268625789880523, 0.8284533409458414, 0.8286371482988173, 0.8293482926265947, 0.8275324553614856]] \n",
      "\n",
      "mean AUC :  0.7888831298183377\n",
      "All std:  [[0.09683827371489213, 0.13703204219728632, 0.07109656317788844, 0.07697135439935952, 0.09176081809613507, 0.1303436408382024, 0.11438671688667765, 0.14799529701357567, 0.10563828419480738, 0.11270173977801591, 0.08339417157334614, 0.0756594298418673, 0.0719723088257602, 0.07485702093437785, 0.12375062291284325, 0.07183150250769513, 0.06852082237646524, 0.07189677976531665, 0.07215404559929399, 0.12784780913612956, 0.07298278961123972, 0.07208344222906928, 0.07929183013716791, 0.08584783502927879, 0.07152691916314556, 0.07247691902809568, 0.0713708312487459, 0.07350041938406542, 0.06642455130755637, 0.08955564976450335, 0.09678887565779454, 0.07346612123122166, 0.0738324586173824, 0.06928652623024374, 0.06855035823904744, 0.07199156963314346, 0.07116012035612872, 0.07009812961332908, 0.06961196373323442, 0.12890486703045276, 0.0727597859541191, 0.06804274449266784, 0.07220238599952117, 0.16041137284482646, 0.07364076034671697, 0.15240888965340416, 0.11525173311318625, 0.06171784963107093, 0.07188618836491277, 0.07255866396280729, 0.07714324650458639, 0.08586230401787828, 0.0692164255050926, 0.06535177279711228, 0.06790169385703985, 0.07422794496438485, 0.07605322907656677, 0.07082047948892112, 0.07929183013716791, 0.08009633112452569, 0.07411953354797776, 0.07486185382871832, 0.13686895485854253, 0.07194906007483454, 0.1291476352868047, 0.08039311930232974, 0.0912520734089168, 0.06966345338628037, 0.08486013069514205, 0.06045907001690156, 0.06972605197864988, 0.07119829322917698, 0.10992699625464375, 0.06682356753670106, 0.07750143788956369, 0.0678695809402916, 0.07220238599952117, 0.07020935276861065, 0.07779634479798116, 0.07655443380338406, 0.07269883615377926, 0.06142081725667691, 0.07036099580576577, 0.06471301666819218, 0.06522467751323469, 0.07251449256198973, 0.0712290288192672, 0.08519277178087958, 0.10269101785280764, 0.07172838829644003, 0.07271246030847969, 0.07065464185990457, 0.07229148178087584, 0.07185703028525717, 0.09144082890890666, 0.07170811635056955, 0.07491679309699009, 0.07929183013716791, 0.06937679568910934, 0.07153575143863974, 0.0717257217348668, 0.07570066210805573, 0.06224439330658264, 0.0653471506355166, 0.06961098601217762, 0.06722356323085198, 0.07130539639712548, 0.07296725431742296, 0.14783758488783175, 0.07553984957756787, 0.07813721838722765, 0.07350928550324852, 0.08345917872308808, 0.09904994994435887, 0.07188605369791927, 0.07715929958257477, 0.06709000153116801, 0.12013260985390635, 0.07726108101500148, 0.0716587223508004, 0.06575773385820478, 0.07260385335048333, 0.0590647940762479, 0.07376544620910928, 0.160971249833903, 0.15864170995321017, 0.09632796749145012, 0.10512353635520147, 0.12555064203033273, 0.06189327990725718, 0.06952683386082954, 0.07579868721674844, 0.07290106550189245, 0.12861605476576563, 0.07184045833051123, 0.0637805176665827, 0.08887700201508959, 0.07608329534336353, 0.06380970430835228, 0.05994387709664785, 0.1265425689808944, 0.061641848031724504, 0.15450353285201637, 0.14920249407774624, 0.06470275966077631, 0.069263578195158, 0.06156600984836914, 0.07553822124158428, 0.063645622499185, 0.11824520011882919, 0.12114172398928015, 0.08697272408944388, 0.06493314491550699, 0.06361416511361341, 0.06886627366267199, 0.07323606954482294, 0.061858182359968955, 0.07144500831261821, 0.06626777815888121, 0.07004361957246015, 0.061772138026908646, 0.06074712549086558, 0.060538575584449195, 0.11809432834272926, 0.16368104571910994, 0.07215156065763885, 0.05949203432291752, 0.05995029102659759, 0.05964864533759572, 0.05786329937808932, 0.1294822058347737, 0.05800671302871107, 0.061106531204099784, 0.06001834251294781, 0.06875196655613017, 0.06554240603919079, 0.07183161150691306, 0.06725815150958984, 0.059404430503877066, 0.060896686156683984, 0.0695429173635934, 0.07202510223777725, 0.059991844066843665, 0.05768218604597768, 0.05948081639707555, 0.05954785003448061, 0.060701763268029486, 0.06189276063398152, 0.06031304698141446, 0.06095338135728598, 0.061111180924904154, 0.058417504945609613, 0.05845023733518283, 0.06162558124445536, 0.05880620677083016, 0.06946506194063258, 0.0602705225132695, 0.060670479962178725, 0.060612570185150795, 0.06087306166642312]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.09286046519801971), ('gamma', 2.0), ('max_depth', 45), ('min_child_weight', 64), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  198\n",
      "Best AUC : 0.8293482926265947 ( std: 0.060612570185150795 ) \n",
      "\n",
      "running time:  3299.8125178813934  detik. Dalam menit:  54.99687529802323  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  72 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.6679617098120523, 0.679900093421485, 0.5998057654061726, 0.6429947381509874, 0.5551049881353896, 0.7559862458643076, 0.6610239081773375, 0.8072324177579694, 0.7870279440113501, 0.75528334155943, 0.8193766159192214, 0.792882579232437, 0.8169388869808413, 0.623440971543982, 0.8129279321850723, 0.8223568743181624, 0.816001774825481, 0.8096046750403344, 0.8131702707731762, 0.8037234622840514, 0.725377308439837, 0.8160337501445798, 0.7056813391974859, 0.8217415212443506, 0.8121925083759267, 0.7923800809346134, 0.7146415957206651, 0.8136387570233606, 0.7994982069267929, 0.785445859481049, 0.8126098303993751, 0.60287848192628, 0.8209254948109971, 0.8208627622097636, 0.6680442940541942, 0.8234459699691504, 0.7858245865230805, 0.7865651419935537, 0.819579774632908, 0.512432724219145, 0.8195847359792555, 0.8105631391923109, 0.8124360906319182, 0.779858141861616, 0.816942558184323, 0.8115484695302388, 0.7513770332297168, 0.817291810415051, 0.8136866221173016, 0.8180984535640711, 0.7237787186592638, 0.5960906233593406, 0.8165352214647272, 0.7971752484517093, 0.8155057484691911, 0.7262436946770408, 0.8180374830343978, 0.8070732001985035, 0.8038370244141972, 0.8169311414118172, 0.8177339088284927, 0.7600886755840697, 0.820556908169798, 0.8127834232193866, 0.8158419688681589, 0.8054330887202252, 0.5559927727607703, 0.729673138945273, 0.7854690743103436, 0.8093152353764629, 0.8214715900207253, 0.8208432879976401, 0.8210620414813522, 0.812970479278514, 0.8169869657237651, 0.8201561903168035, 0.82141111115321, 0.8189850826034816, 0.801864771455548, 0.8081988667303321, 0.7976936319479635, 0.8226113124169878, 0.8162535438810034, 0.8170211085539574, 0.8213494110061376, 0.8217257635419002, 0.8152031057020177, 0.8193766159192214, 0.8091508587044133, 0.7646425752481955, 0.8198991368602165, 0.8224570912556245, 0.8225908676877279, 0.8216506689700909, 0.8191185253213545, 0.8195262556961798, 0.8200131183877863, 0.8219859899808716, 0.7740310817153842, 0.8121288022963492, 0.8172638948988402, 0.8210360400112745, 0.8202085062869887, 0.8204258146967689, 0.8178206397458343, 0.8252965293417567, 0.8230132907968607, 0.8244878403790944, 0.8238376231729466, 0.8248272953439851, 0.8240558360326661, 0.8271435486698142, 0.8249679616837201, 0.8249648479773853, 0.8268176845364422, 0.8269887814018603, 0.8266021156565048, 0.827372923533525, 0.827218223962314, 0.827154744672499, 0.8255867235545199, 0.8237896718278631, 0.8224251631529987, 0.8258787088901084, 0.8260364269066711, 0.8260307521332155, 0.8259763904873395, 0.8253421957693624, 0.8240791465632236, 0.8263484899936823, 0.8255344602675142, 0.8265171596076315, 0.8265269264597058, 0.8258394961095685, 0.8262790268986647, 0.826517088617536, 0.8265047531779954, 0.8263089837522476, 0.8264857458393733, 0.8267268685149604, 0.8208049831255712, 0.8162279765221343, 0.8262787291695186, 0.8260991205398895, 0.8271007155637988, 0.8262051578756686, 0.8166385603289246, 0.8265172069602709, 0.8267505390791334, 0.8128463204609961, 0.8151967269898576, 0.8266845187773428, 0.8261891162000944, 0.7964953755877995, 0.8266809756801046, 0.8266261860614355, 0.8255561382441298, 0.811874883653262, 0.8177296996297018, 0.8159549605390265, 0.7237440593434568, 0.8154676596027279, 0.8206443729546667, 0.8205907490182619, 0.8176009691432609, 0.8145755200262507, 0.8233694044782496, 0.82347623102782, 0.8172003429439858, 0.8190625746472906, 0.8271229767471313, 0.8271250602632556, 0.8271211895181154, 0.6997602113712673, 0.7941830097738966, 0.7890405655957216, 0.8071578371197539, 0.8144231871771709, 0.8212305803869233, 0.8228884961156198, 0.822108423918583, 0.8191836745646885, 0.8267483898945794, 0.8267559230648066, 0.8267596297112633, 0.8202596895017468, 0.820444188043779, 0.8267584456621039, 0.8267659869189697, 0.8267668041021123, 0.8256572737958929, 0.8272107324965384, 0.8271380701992682, 0.8131470018879049, 0.8271378332013315, 0.8171969269966499, 0.8052031729547426, 0.8250959727268357, 0.8078547829382616, 0.8152297133049771]] \n",
      "\n",
      "mean AUC :  0.7998015611728193\n",
      "All std:  [[0.11972645341143268, 0.1340716055534353, 0.11746143647106698, 0.11209870190573633, 0.07017408494256597, 0.09221212585649044, 0.12832755869243198, 0.07588263685760473, 0.08026376982424235, 0.09927097714897133, 0.07251145995233935, 0.08863119864602603, 0.07563176346615334, 0.09715211259316905, 0.07097393612704357, 0.07175430118284055, 0.07177515927721159, 0.0694091101827682, 0.07522392404840378, 0.0761949562218581, 0.1462668309255167, 0.07400388229067469, 0.13850730969003414, 0.07223920986179291, 0.06434574982708328, 0.0657305711420217, 0.09904994994435887, 0.07896583741595145, 0.06988251521245305, 0.07886661723054388, 0.07148163530977591, 0.07929183013716791, 0.07133348942365722, 0.07304444812034223, 0.14639914333759707, 0.07161286705385289, 0.08366477378635365, 0.08241145259969004, 0.07004327417492409, 0.07771390255978126, 0.071435351975063, 0.07792572723455919, 0.07271058802182144, 0.05781501170585575, 0.07014028414747515, 0.06875132690440054, 0.10022201618699382, 0.07344683454729801, 0.07368106624156348, 0.0729650956911754, 0.12850138262254474, 0.10422034052498494, 0.07575180857367061, 0.0649372747943896, 0.07418662002326455, 0.12029379549508473, 0.07119972063359496, 0.07432300787474568, 0.07741076469865177, 0.07245637215261394, 0.07121142823076601, 0.10956381851605691, 0.07099068907689851, 0.06854160593897954, 0.07552684360130293, 0.07478481517330231, 0.12566082099029077, 0.12308730089538239, 0.06515624773960264, 0.0786304618255336, 0.07246859350228509, 0.07159547597920174, 0.07164347735986566, 0.07560854537886635, 0.07403908185272665, 0.06980079109164282, 0.06630479659938367, 0.07012344517545446, 0.0770759985659937, 0.07943959019867716, 0.08269578766910728, 0.07240186062729084, 0.07361152209934681, 0.06500856670499174, 0.07155532104297167, 0.07145276109512848, 0.07135928711334319, 0.07251145995233935, 0.07796610367447421, 0.08043640355300005, 0.07185155589751861, 0.07248051507724064, 0.07028029594891391, 0.06549626677791656, 0.07200923415599554, 0.07214299054931823, 0.07177800596642737, 0.0719874626971617, 0.08897236520356143, 0.07045812515332102, 0.07623835705713133, 0.07291714428460662, 0.07375731003153048, 0.07116707140500655, 0.07198104314779824, 0.06867118969898975, 0.0697681260112771, 0.06954835127135679, 0.06960257180080513, 0.07004270943836913, 0.06942046392190312, 0.07079622873687388, 0.07179455532571989, 0.07179661567799281, 0.07101092958165013, 0.07099155262914669, 0.07083969518516775, 0.0708015199892228, 0.07027806445006868, 0.06976051101641137, 0.07101660714049796, 0.07131917146746078, 0.07064888937647638, 0.0715255454754007, 0.07138053247889824, 0.07138468664263396, 0.0715105812165262, 0.06954020560455385, 0.07189341076772543, 0.07060163787259953, 0.06941083262943958, 0.0706004159576262, 0.070598702438963, 0.069850618274461, 0.07025509018383044, 0.07060046420447166, 0.07059939209570036, 0.07039580880253583, 0.07069452941137612, 0.0710774388594162, 0.06280007618129753, 0.07355128215120153, 0.07079814214464726, 0.07049942678859876, 0.06982081423664453, 0.06949354729475363, 0.07192757849903088, 0.0706004094637712, 0.06953561512437267, 0.07713776757100577, 0.06837219041271649, 0.06950630347521751, 0.06949192173543227, 0.07219940620045442, 0.06950783562854553, 0.06987648923328721, 0.07007917967824233, 0.07355834843239192, 0.06987666518137392, 0.06811752833731963, 0.1278718242131525, 0.0777449002522274, 0.06961917276658044, 0.06505316419006307, 0.07003069303623902, 0.07117421533659778, 0.06399648496632054, 0.07084576927687952, 0.06855495803005217, 0.07210909389533744, 0.07037337288638844, 0.07037362768740575, 0.07037418531684528, 0.13720546458584923, 0.06530476111934103, 0.08104247620212833, 0.070433547111782, 0.06785807805161498, 0.06550964731437037, 0.0604206561027424, 0.062346407696013045, 0.06417013697098707, 0.06995841787502922, 0.06995462118428727, 0.06995242740863329, 0.06312216397521736, 0.0642333738011351, 0.0699534848146396, 0.0699512807155885, 0.06995086656441271, 0.07023610829126345, 0.0703733890254836, 0.07037311654147173, 0.07351240045550864, 0.07037329545505547, 0.07256934024139883, 0.07720787587009499, 0.0720749953000398, 0.07783743337996779, 0.07145214388156028]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.002969769826331494), ('gamma', 0.001), ('max_depth', 39), ('min_child_weight', 87), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  117\n",
      "Best AUC : 0.827372923533525 ( std: 0.0708015199892228 ) \n",
      "\n",
      "running time:  3077.9450345039368  detik. Dalam menit:  51.29908390839895  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  82 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.7711522702815398, 0.6274370381868041, 0.7231789717438747, 0.6713299191856862, 0.7361528705692518, 0.7267209384946935, 0.8010632622467614, 0.7766372565741709, 0.5557575241900631, 0.6870321201206264, 0.7217857431050326, 0.779858141861616, 0.700716202728766, 0.8020042609892597, 0.7230465729100443, 0.8181774938782717, 0.8054884769663107, 0.8106112485750142, 0.8073585465694793, 0.8044779069341209, 0.8146376259126304, 0.8079195202117966, 0.8055072791849346, 0.5531680098996011, 0.813106745899682, 0.60287848192628, 0.6679804834876852, 0.7918207757492398, 0.8127744124315448, 0.6175349884572027, 0.8106185240820302, 0.7923800809346134, 0.8130994871779511, 0.7796902373235007, 0.8097056613936016, 0.8004166009511791, 0.8193766159192214, 0.8165582800345217, 0.6760613822808101, 0.8156033381018607, 0.8182397687619277, 0.8192803235511469, 0.815958929864815, 0.8071010124188872, 0.8237467946123046, 0.8149825918481713, 0.8129166077344273, 0.8106974098667625, 0.8156820752164509, 0.8120820535234664, 0.8244827952153332, 0.8229711617637219, 0.8143787123812537, 0.8264495582512632, 0.8223012514303281, 0.7553455786221266, 0.8084101916553592, 0.8220190913470236, 0.8255268946926786, 0.7791325301352121, 0.8156194985959411, 0.8245559618685276, 0.8155902930542701, 0.8216562414869826, 0.8191026079889872, 0.685806955291517, 0.8253461962341162, 0.822916760027954, 0.6832935710260707, 0.8159191943182429, 0.813267093419632, 0.824908967239197, 0.8250641475833955, 0.8201857186993665, 0.8255181090068504, 0.8254686248868861, 0.8208442389302081, 0.8262284331091884, 0.8269332288370667, 0.8254241008012232, 0.8248138548220553, 0.8265950364695048, 0.8254396722954616, 0.8176772246813554, 0.8192586621882898, 0.8263155756974345, 0.826449269795318, 0.826292399552377, 0.8264235823776436, 0.8267170083090405, 0.8256996337698749, 0.8266166710423541, 0.8261862272204814, 0.8264523584568588, 0.8266791836191241, 0.8265116639440542, 0.8277947981863584, 0.8257223426743088, 0.8241933693601132, 0.8234428614965623, 0.8101285595865523, 0.8167660502522777, 0.8212690732438545, 0.8214676330585764, 0.8190692833984541, 0.7940553231193118, 0.8055512492857237, 0.8133057078110222, 0.8169445184722847, 0.8263023168503757, 0.8099721278037545, 0.8217005613776173, 0.8223482414889199, 0.8224498214927756, 0.8249175945420559, 0.8214602896040076, 0.8222136376163751, 0.8253565859306718, 0.8263747565219406, 0.825228202999733, 0.82647248770191, 0.8265330646986968, 0.8241125630610665, 0.8241192394664812, 0.8257433751853362, 0.8261728179065846, 0.8260137158782395, 0.8241451831231756, 0.8268531929401247, 0.8252213462932797, 0.82683475268814, 0.8259365217835037, 0.8269916277724643, 0.8260234677596525, 0.8273077819356484, 0.8256245655952399, 0.8113880059011929, 0.826649304328122, 0.8278533725322598, 0.8267200602239874, 0.826007922957723, 0.8246585068242834, 0.8266914917185867, 0.8286818750786575, 0.8247614578708355, 0.8275427183568462, 0.8262943397201665, 0.8273609171695937, 0.8269346317427569, 0.8264999587590471, 0.8284427216195778, 0.8237596914500388, 0.8279985467588468, 0.8230120245967235, 0.8251784115417876, 0.828121278710689, 0.8276108712876828, 0.8278379903583567, 0.8275553927084472, 0.8264644244263244, 0.8273836054929841, 0.8235672162333199, 0.8275440840094763, 0.8277792478975178, 0.8290607325607607, 0.8270250424096767, 0.8273999465623233, 0.8275589671257074, 0.8275448890980314, 0.8275739404612859, 0.8275863647797308, 0.8280990071710893, 0.8275806469252998, 0.8287201621881329, 0.8279814166927956, 0.8284689598370192, 0.8281315218458954, 0.8274409192149516, 0.8286155632100259, 0.8293133878650563, 0.8280588117021275, 0.8280477719395366, 0.8276112847472221, 0.826616906799638, 0.827911779805783, 0.8280617342472558, 0.8273564007058263, 0.8278369969517788, 0.8280079432694567, 0.8278819162281066, 0.8287726305170812, 0.8253271619317516, 0.8286082878736948, 0.8288918989468698, 0.8280713842342029, 0.8268332282465123, 0.8272678963124072, 0.8267906223745304, 0.8284510736055086, 0.8229898105269651]] \n",
      "\n",
      "mean AUC :  0.8075012314308191\n",
      "All std:  [[0.08486021875585077, 0.13886432247406563, 0.1298509828207939, 0.11954343763118583, 0.08634730568314376, 0.12147374521562664, 0.06614078889664642, 0.10100452420541313, 0.07877500719849445, 0.11960125790006447, 0.12375062291284325, 0.05781501170585575, 0.10047645048639414, 0.061423383468480953, 0.12702430055154795, 0.06731257655866164, 0.06713746901443432, 0.06573981133938546, 0.07317919725444381, 0.06788996820302279, 0.0696798649275736, 0.0743253091251941, 0.0756216217818917, 0.11150184044455166, 0.08030294308710312, 0.07929183013716791, 0.15323580313273152, 0.07965538086824803, 0.08112990411600819, 0.0948090613185836, 0.07656818617053604, 0.0657305711420217, 0.07314136725834208, 0.08366696055590887, 0.07496315578846055, 0.07603078746395495, 0.07251145995233935, 0.07343208381154012, 0.1140970129412635, 0.0741712067314404, 0.07275615069803909, 0.07126056160950679, 0.07020625723985367, 0.07438040135323128, 0.07171935043328191, 0.07022622335913588, 0.07123843350632725, 0.08044067258006929, 0.07374262008249523, 0.07504037252170241, 0.0724497033718663, 0.0719723088257602, 0.07614551133968576, 0.06970347609045095, 0.0720456397455489, 0.09360747019423613, 0.07688572944742116, 0.07036528659723548, 0.06919464036894496, 0.09803762809574532, 0.07430993758999778, 0.06406789327861112, 0.07169662454739074, 0.06403532156369027, 0.0671435066595883, 0.15408135999300065, 0.07202510223777725, 0.061361669735545736, 0.14783758488783175, 0.07796863501681851, 0.08169416931174313, 0.07136767897427204, 0.0697138299860807, 0.072981914812259, 0.07185508985619116, 0.07102437678649211, 0.07132609600635849, 0.0713181651739352, 0.06937040177742713, 0.06873299902546823, 0.07203276732921073, 0.0691996854666733, 0.06931907533492455, 0.06758503508867165, 0.06878801908637215, 0.06989050788534432, 0.07077117810178878, 0.06988356367584805, 0.07123885042445856, 0.0699719080002518, 0.07014279741527463, 0.07117932520889829, 0.06948400636704105, 0.07123514177689365, 0.07079744012148557, 0.0708401409667535, 0.06262983057661392, 0.05799555955756529, 0.06252543808420061, 0.06184874892503442, 0.07718372245680229, 0.07163060631046823, 0.061787537858740874, 0.06561245939685083, 0.07304154434081721, 0.08560597650197148, 0.07449360992783549, 0.07612927429779498, 0.06920659224342701, 0.06057799736128084, 0.06473260594608429, 0.0647324550434789, 0.06608214130006937, 0.06269954955414271, 0.06320653599859927, 0.0673162730728989, 0.06307824736245274, 0.07173646256533402, 0.07155590443245316, 0.06166892194863032, 0.07146079150397136, 0.07145550877125033, 0.06358201959175622, 0.06602275980385812, 0.06137968961623159, 0.0705101399984543, 0.06402341295343526, 0.0627607386640186, 0.07102727694506843, 0.07188175097330923, 0.05950319330599026, 0.06972929216019373, 0.05759540339339107, 0.060660826287388066, 0.05839008570619492, 0.059033839530755305, 0.0778361487390817, 0.06982781168967467, 0.06085814874849742, 0.06982555887944455, 0.06166049842057645, 0.060591707772294265, 0.059647642569886285, 0.06281794048340593, 0.06466690793672045, 0.0610926309084452, 0.05925231461533252, 0.061420089928210075, 0.05986650940417591, 0.057947322308809925, 0.060653958976161486, 0.06388079483704685, 0.05996086720183525, 0.06317349680544197, 0.06343717188847989, 0.05953371699331917, 0.058327263430557955, 0.0582916131485118, 0.058020898985606445, 0.0695221365809723, 0.07072059249962741, 0.07005060074693573, 0.05801881446473097, 0.05743453009738629, 0.05890560483638961, 0.05777969575781226, 0.06032995244815764, 0.058021106547281445, 0.05801920310863817, 0.06053308438222772, 0.05862763570993674, 0.059588055186129654, 0.058628014611193845, 0.061761459577185, 0.05839969593714892, 0.05979957860590641, 0.05980193491768358, 0.060471057808408175, 0.06033173257464851, 0.060103102702709764, 0.059896970589506174, 0.06129201596281176, 0.05843988603759947, 0.06149512252648803, 0.059690493293448936, 0.05831427632673163, 0.059814964695574034, 0.0587891045503595, 0.060763350748120025, 0.05987630918237382, 0.05925252494233841, 0.06948082292600598, 0.06033239268024194, 0.05907835692796322, 0.06074857572465537, 0.061836600726286085, 0.062374348279905685, 0.059248354993509285, 0.0612938823294631, 0.06447810694033329]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.10695724745232778), ('gamma', 0.001), ('max_depth', 100), ('min_child_weight', 63), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  179\n",
      "Best AUC : 0.8293133878650563 ( std: 0.060103102702709764 ) \n",
      "\n",
      "running time:  2810.358326435089  detik. Dalam menit:  46.839305440584816  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  92 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.7436717232128063, 0.6012471403884917, 0.7554093421471126, 0.807669830921705, 0.5495153892886459, 0.7464887791566337, 0.5545376251070009, 0.7521578235043543, 0.6814723609865317, 0.8168183278757674, 0.6679804834876852, 0.7217857431050326, 0.8109810607768402, 0.6997187423079242, 0.8213059001786912, 0.7399883026513843, 0.5186047653389341, 0.6982268831151809, 0.8132425594635659, 0.8172856629064145, 0.807808195637869, 0.8209918141189272, 0.820448262047132, 0.8111451633258432, 0.6752745180178544, 0.8268928242553734, 0.8254125507588197, 0.8170311020235973, 0.823569780656266, 0.8175615756878223, 0.8082960504418607, 0.812049752662932, 0.8134497424722843, 0.8160975626597604, 0.7254542185885011, 0.8220762119226953, 0.8193766159192214, 0.8162777151511126, 0.8117969146474125, 0.8196187749638517, 0.7970844751993554, 0.785757736086407, 0.8139737578948834, 0.8126760985117432, 0.8166088583295819, 0.7049168341556218, 0.8193916647464039, 0.8091145563492017, 0.810998630675856, 0.8178657914048607, 0.8191782333083588, 0.8198991368602165, 0.8145556947676307, 0.794973326521695, 0.7600078139777103, 0.7695308095268258, 0.8198991368602165, 0.8011036691505252, 0.8062391906214244, 0.7830252855030266, 0.8160297437092212, 0.8187687029130284, 0.8036865852547252, 0.8100378023396245, 0.7952462288634417, 0.8047643068959646, 0.7083384257890335, 0.6170619249153225, 0.8134608179517508, 0.8044608961587522, 0.8184125254100617, 0.7746077455517532, 0.8164651615193314, 0.8013620791012519, 0.8089845692996954, 0.7861387390554558, 0.6224704301984869, 0.8095298343799927, 0.8173650933590805, 0.817880954142971, 0.7835205427448707, 0.6976722809556698, 0.6190196881984705, 0.8195427744231787, 0.8194689448081107, 0.8152472785681235, 0.8209421546777899, 0.8217794795818426, 0.8139022575830998, 0.8067890399940185, 0.8217460942822039, 0.7794648124902561, 0.8211941760752054, 0.8072778597490745, 0.8203056069837978, 0.8201179816054915, 0.8087038742533535, 0.8100060545977167, 0.8157472777079183, 0.809688936864293, 0.8178032944737381, 0.8240872503164691, 0.8264085185241903, 0.7923800809346134, 0.8060589745627804, 0.8133741270501731, 0.8026386225684582, 0.7947031108322176, 0.4935735190970184, 0.8187029207080136, 0.8190717317961851, 0.717195781906944, 0.8192729235742136, 0.826846403212231, 0.7646992815906949, 0.8051958428135856, 0.8262634225226924, 0.8176167006565231, 0.7127406510393978, 0.7956607228735776, 0.8198991368602165, 0.8148381403539868, 0.8098420378489134, 0.8064531910674689, 0.7604437009921611, 0.8112931675770664, 0.813826767497971, 0.6832935710260707, 0.7196241609117617, 0.7274688884659991, 0.60287848192628, 0.740928368910957, 0.8080629910765535, 0.7967129094275847, 0.7319162811850463, 0.7677994854641159, 0.8111360493947816, 0.6800560799309102, 0.8140765171703476, 0.7668870104473247, 0.8128095501625814, 0.7338923440877421, 0.5498503300925608, 0.8206389486828463, 0.7894446868272188, 0.8239698131812458, 0.8150636862736037, 0.8085984366908326, 0.8199350554819979, 0.8171294524807594, 0.8161342315534097, 0.8096838656507918, 0.7151111621855517, 0.7702117701507633, 0.7482155684823856, 0.7626764817572813, 0.805677205243083, 0.8258007671095244, 0.8032988423904112, 0.8252357682554242, 0.7404482507816122, 0.8160111663102296, 0.4920326244864269, 0.81531559553829, 0.8219875131176407, 0.7601180677897689, 0.825945210384655, 0.8230630327678651, 0.7202573443364069, 0.8198180737294415, 0.8217201038468819, 0.8210813251552176, 0.8147659039019508, 0.8227771582429603, 0.8204663636939666, 0.8170038264021555, 0.8102489593990517, 0.7855025663865914, 0.8117025824355832, 0.8245997039706822, 0.8281340985329197, 0.8263968512751146, 0.7500798814909957, 0.7591987308454377, 0.8246664617219867, 0.8257982061714483, 0.8268963113354943, 0.8241374821258056, 0.8111617672131076, 0.8146136046336552, 0.788501692583783, 0.8219350009664552, 0.8265852507900188, 0.8245691767072174, 0.8259424005562084, 0.8244360104888664, 0.8223157663873044, 0.8270936834101645, 0.8200182961763431, 0.8199991813485892]] \n",
      "\n",
      "mean AUC :  0.7836760109402617\n",
      "All std:  [[0.1208354495392187, 0.10710242953936723, 0.10309610710853169, 0.07341531062015194, 0.0852286602021482, 0.10945240882164116, 0.10311532533386777, 0.09911027014228736, 0.13297143743486448, 0.0763765814235666, 0.15323580313273152, 0.12375062291284325, 0.07258115878594504, 0.1128941231359717, 0.07157915523667768, 0.12043424147658298, 0.07495435369982507, 0.12398838535408555, 0.07343707031562657, 0.07084311916785671, 0.07100444907809873, 0.06952826393829485, 0.0690660606403141, 0.07424780728580377, 0.14060453286585997, 0.07111748787151032, 0.06987366663063888, 0.07202914451793199, 0.07034219452741243, 0.07099353909076614, 0.06935109439252538, 0.06872135322349136, 0.07193549458821012, 0.07166492307979518, 0.12555064203033273, 0.07299238183030896, 0.07251145995233935, 0.07380965919304844, 0.06991577614993298, 0.07276496703494656, 0.0712032223675484, 0.0792518362273638, 0.07561555423691663, 0.0806013646098268, 0.06972834805554733, 0.13728688902060834, 0.06943270063225912, 0.07021703247008093, 0.0813324523655536, 0.07196332764085855, 0.07060739945256428, 0.07185155589751861, 0.07935700404092959, 0.06837200576985439, 0.09793651655804884, 0.07704098264739256, 0.07185155589751861, 0.08047241795213021, 0.06712308777491986, 0.08574725214807695, 0.0712282093108587, 0.06418207526677698, 0.08268292588543903, 0.0755214409107789, 0.07972537917696197, 0.07577854104978818, 0.13464347841312754, 0.09434915975219016, 0.07857509863008244, 0.07924788890488813, 0.06902239197209359, 0.0780304321072541, 0.07082853374863135, 0.08199395998362645, 0.076835928512198, 0.08435185752380338, 0.13349389558743877, 0.07076292887008792, 0.06992634495509215, 0.0704112631662708, 0.07755159624922583, 0.13784090365955529, 0.09678033921425673, 0.06534812500672085, 0.06899635429072026, 0.07078232919044254, 0.07107046047841169, 0.06519141719609446, 0.07059003265015734, 0.06388561317102996, 0.06422078199484342, 0.07954668362319131, 0.06501080573791639, 0.06646331776809987, 0.07358671537492976, 0.07274949856528781, 0.074334487827656, 0.08052179160950919, 0.07095704894294443, 0.06472962095167965, 0.07043697378454476, 0.06969783050119867, 0.07144703208680948, 0.0657305711420217, 0.07599214227567445, 0.06409366878896916, 0.06511741091435756, 0.0829542018649618, 0.08683617005382942, 0.06596522099869111, 0.06771272244990281, 0.10221903780064101, 0.0642706919012971, 0.07029451888145084, 0.12112190407002418, 0.07613243982622167, 0.07114571605963681, 0.07136124749433678, 0.059812102366378794, 0.06966345338628037, 0.07185155589751861, 0.06692390558477959, 0.07253357083289062, 0.06997123118925866, 0.09847494228760484, 0.07784628373247028, 0.0724598217874744, 0.14783758488783175, 0.148524466685754, 0.129099440628963, 0.07929183013716791, 0.11054947609582533, 0.07795864492849379, 0.08004235050400717, 0.15001326951174637, 0.09676034180170141, 0.07144908776487308, 0.15898926205812827, 0.07627753671103983, 0.08551574597731128, 0.07864207367105035, 0.15467020788855038, 0.12118977183730588, 0.07231536706285852, 0.08486112598308597, 0.061063270995609556, 0.07185358062694824, 0.07749537432311723, 0.07166826066356731, 0.07283011628754349, 0.07304375315370913, 0.06246431685821453, 0.12393025733002393, 0.1170496619166103, 0.1404334382325838, 0.12742416222719732, 0.09214098288638817, 0.07005980713496233, 0.08289486991515355, 0.0690959119708739, 0.1080579545439347, 0.07255609750497338, 0.04159424796169352, 0.07141976259987987, 0.07215106782988744, 0.12642220659283981, 0.060639170707717995, 0.06164800164436009, 0.14913518714537263, 0.06568121207679453, 0.06101326031080605, 0.06429541879773953, 0.07188844942219624, 0.061540147612936226, 0.07049551941889629, 0.06818040150776501, 0.07321326427295537, 0.10711214937121247, 0.06044171853741553, 0.06465181789105877, 0.06066021458780653, 0.06075539603794729, 0.1368667260322134, 0.08859769691113495, 0.06364551382395871, 0.0607490553091561, 0.061478960582821825, 0.06499945953665795, 0.07742649075168273, 0.07781230225778181, 0.09296899942321979, 0.06783050371238433, 0.06124253915260537, 0.06123273697653758, 0.06120937679742184, 0.060967119042308116, 0.06744572733802563, 0.058522681702557824, 0.07173614225285964, 0.061069027049754074]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('eta', 0.11240335347073001), ('gamma', 2.0), ('max_depth', 51), ('min_child_weight', 62), ('subsample', 0.1)]) \n",
      "\n",
      "Best index/iterasi :  180\n",
      "Best AUC : 0.8281340985329197 ( std: 0.06066021458780653 ) \n",
      "\n",
      "running time:  3717.8988411426544  detik. Dalam menit:  61.964980685710906  menit\n"
     ]
    }
   ],
   "source": [
    "seeds=[1,12,22,32,42,52,62,72,82,92]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=bayes_opt(X_bank,y_bank,model_x,hyper_space_3,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2(Credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'iid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7e3b81f417cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbayes_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_credit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_credit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper_space_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterasi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Seed: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint_hasil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterasi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-4f73292ca650>\u001b[0m in \u001b[0;36mbayes_opt\u001b[0;34m(X, y, model, parameter, iterasi, evalscore, seed)\u001b[0m\n\u001b[1;32m     58\u001b[0m                    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                    \u001b[0miid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, search_spaces, optimizer_kwargs, n_iter, scoring, fit_params, n_jobs, n_points, iid, refit, cv, verbose, pre_dispatch, random_state, error_score, return_train_score)\u001b[0m\n\u001b[1;32m    311\u001b[0m              \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m              \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m              return_train_score=return_train_score)\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_search_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'iid'"
     ]
    }
   ],
   "source": [
    "seeds=[1]\n",
    "iterasi=2\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=bayes_opt(X_credit,y_credit,model_x,hyper_space_3,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds=[1,12,22,32,42,52,62,72,82,92]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=bayes_opt(X_credit,y_credit,model_x,hyper_space_3,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dataset 3(Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dataset 1(Bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T02:24:58.140142Z",
     "start_time": "2020-12-24T19:07:39.216264Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 43.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  0 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 43.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 44.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  2 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 43.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  3 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 43.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  4 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 43.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  5 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 43.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  6 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 43.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  7 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 43.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  8 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 43.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  9 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76060784, 0.76523625, 0.76104181, 0.76523625, 0.76968842,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68543434, 0.56914424, 0.70463832, 0.58225869, 0.71056257,\n",
      "       0.59138479, 0.73843989, 0.59445215, 0.75799238, 0.58897681,\n",
      "       0.67282082, 0.52882339, 0.70193789, 0.54960457, 0.70840726,\n",
      "       0.56488549, 0.73772561, 0.58145237, 0.7582664 , 0.59089077,\n",
      "       0.67283233, 0.52147984, 0.70254795, 0.54984558, 0.70830653,\n",
      "       0.56478006, 0.73772561, 0.58160436, 0.7582664 , 0.58914929,\n",
      "       0.67281431, 0.52114135, 0.70254795, 0.55116181, 0.70830653,\n",
      "       0.56498487, 0.73772561, 0.58141228, 0.7582664 , 0.58901119,\n",
      "       0.76060784, 0.76523625, 0.76102796, 0.76523625, 0.76969166,\n",
      "       0.76523625, 0.76530673, 0.76523625, 0.77354576, 0.76523625,\n",
      "       0.68600022, 0.57132019, 0.70427665, 0.58116109, 0.7114567 ,\n",
      "       0.5898654 , 0.73848409, 0.59480036, 0.75792344, 0.58974664,\n",
      "       0.67366144, 0.52806664, 0.70258663, 0.55025403, 0.70866318,\n",
      "       0.56569362, 0.73759012, 0.58171865, 0.75851261, 0.59077713,\n",
      "       0.67340643, 0.52169611, 0.70270178, 0.54977193, 0.70855611,\n",
      "       0.56419215, 0.73759012, 0.58194329, 0.75851261, 0.58816485,\n",
      "       0.67339641, 0.52130361, 0.70270178, 0.55243533, 0.70855611,\n",
      "       0.56551785, 0.73759012, 0.58181783, 0.75851261, 0.58849293,\n",
      "       0.68019608, 0.61730033, 0.6678377 , 0.5795702 , 0.63399061,\n",
      "       0.6041367 , 0.688499  , 0.6387759 , 0.71800942, 0.6503092 ,\n",
      "       0.59440926, 0.48775157, 0.60025749, 0.48283248, 0.60506957,\n",
      "       0.48094196, 0.62801309, 0.50848655, 0.65707242, 0.52386745,\n",
      "       0.56842407, 0.49923126, 0.61070172, 0.49576341, 0.61945951,\n",
      "       0.48016822, 0.63862532, 0.50433704, 0.65634244, 0.50988292,\n",
      "       0.59250238, 0.50397508, 0.58965206, 0.499553  , 0.61192547,\n",
      "       0.48298061, 0.63862532, 0.49703738, 0.65634244, 0.5150113 ,\n",
      "       0.58966953, 0.50192447, 0.58965206, 0.48868164, 0.61192547,\n",
      "       0.50338009, 0.63862532, 0.507677  , 0.65634244, 0.51824606,\n",
      "       0.66142714, 0.6172954 , 0.667856  , 0.57044454, 0.63260055,\n",
      "       0.60408612, 0.68927543, 0.63874282, 0.71401947, 0.64571985,\n",
      "       0.57200538, 0.49371458, 0.60227128, 0.49240653, 0.61399545,\n",
      "       0.48872386, 0.63819506, 0.51150229, 0.65911938, 0.52850324,\n",
      "       0.57264893, 0.48964406, 0.59517807, 0.49063645, 0.58432996,\n",
      "       0.49609019, 0.63787795, 0.49962337, 0.65354813, 0.50283974,\n",
      "       0.57898627, 0.49131167, 0.58360579, 0.49362213, 0.57833393,\n",
      "       0.49061275, 0.63787795, 0.49623027, 0.65354813, 0.51156479,\n",
      "       0.59977149, 0.48733225, 0.58360579, 0.49204578, 0.57833393,\n",
      "       0.50117443, 0.63787795, 0.49942028, 0.65354813, 0.51587391])] \n",
      "\n",
      "mean AUC :  0.6207857580760094\n",
      "All std:  [array([0.13594291, 0.13036785, 0.13437381, 0.13036785, 0.12492459,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14828132, 0.07120995, 0.1538808 , 0.06818422, 0.15210199,\n",
      "       0.07148149, 0.12390426, 0.07187182, 0.108299  , 0.06661762,\n",
      "       0.14129303, 0.06049328, 0.15221284, 0.07142638, 0.14979832,\n",
      "       0.07321201, 0.1223766 , 0.07313349, 0.10884784, 0.07619005,\n",
      "       0.14198253, 0.06124251, 0.1524556 , 0.07105939, 0.14970591,\n",
      "       0.07581516, 0.1223766 , 0.07193881, 0.10884784, 0.07628321,\n",
      "       0.14196545, 0.06123472, 0.1524556 , 0.07226724, 0.14970591,\n",
      "       0.07638288, 0.1223766 , 0.07183128, 0.10884784, 0.07609616,\n",
      "       0.13594291, 0.13036785, 0.13439716, 0.13036785, 0.12491931,\n",
      "       0.13036785, 0.11751604, 0.13036785, 0.10071573, 0.13036785,\n",
      "       0.14853408, 0.07178644, 0.15406219, 0.06760098, 0.15173059,\n",
      "       0.07110155, 0.12384672, 0.07216353, 0.10865778, 0.06708935,\n",
      "       0.14277801, 0.06061068, 0.15254637, 0.07136935, 0.14979769,\n",
      "       0.07303499, 0.12251854, 0.07247087, 0.10867726, 0.07494848,\n",
      "       0.14254879, 0.06182606, 0.15251926, 0.07181251, 0.14968586,\n",
      "       0.07479563, 0.12251854, 0.07258778, 0.10867726, 0.07475091,\n",
      "       0.14255088, 0.06270832, 0.15251926, 0.07242984, 0.14968586,\n",
      "       0.07601802, 0.12251854, 0.0724707 , 0.10867726, 0.07517767,\n",
      "       0.13354104, 0.11663757, 0.14911979, 0.09217985, 0.15186474,\n",
      "       0.06763759, 0.13984032, 0.1557377 , 0.11280733, 0.15685837,\n",
      "       0.13780157, 0.11850074, 0.09619869, 0.0854896 , 0.11205297,\n",
      "       0.09418084, 0.11774372, 0.08731402, 0.10303007, 0.11475012,\n",
      "       0.09408158, 0.10975786, 0.09646641, 0.09571619, 0.10220612,\n",
      "       0.08099824, 0.12288456, 0.10266342, 0.13010296, 0.09011991,\n",
      "       0.0991202 , 0.10419778, 0.11290914, 0.09236175, 0.09077065,\n",
      "       0.10915467, 0.12288456, 0.09874451, 0.13010296, 0.09755903,\n",
      "       0.09562174, 0.10850737, 0.11290914, 0.09811463, 0.09077065,\n",
      "       0.11431294, 0.12288456, 0.10467645, 0.13010296, 0.10125277,\n",
      "       0.13771941, 0.11663467, 0.14915227, 0.08180395, 0.15317609,\n",
      "       0.06766528, 0.13539488, 0.1557191 , 0.11421379, 0.15928534,\n",
      "       0.10256683, 0.11053518, 0.11529662, 0.09230891, 0.10549887,\n",
      "       0.10255272, 0.10564396, 0.08821162, 0.12747162, 0.09976624,\n",
      "       0.10246506, 0.10013728, 0.10623005, 0.10226633, 0.1242058 ,\n",
      "       0.0845358 , 0.11458812, 0.09743678, 0.13563382, 0.09237884,\n",
      "       0.0927777 , 0.09483197, 0.10354851, 0.09148043, 0.11392205,\n",
      "       0.10979537, 0.11458812, 0.10294721, 0.13563382, 0.09693245,\n",
      "       0.12142301, 0.09083599, 0.10354851, 0.0869207 , 0.11392205,\n",
      "       0.1031081 , 0.11458812, 0.0959614 , 0.13563382, 0.09425064])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.001, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  8\n",
      "Best AUC : 0.7735457636252889 ( std: 0.10071573262226913 ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for i in range(0,10):\n",
    "    auc,std,best_index,best_param=grid_search(X_bank,y_bank,model_x,hyper_space_1,eval_metric)\n",
    "    print(\"iterasi: \",i,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dataset 2(Credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:15:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "iterasi:  0 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76693795, 0.75742302, 0.76682351, 0.7574033 , 0.76674269,\n",
      "       0.75739124, 0.76703311, 0.75739124, 0.76696366, 0.75738932,\n",
      "       0.77861329, 0.77342111, 0.78017177, 0.77534777, 0.77994028,\n",
      "       0.77655868, 0.78015593, 0.77782613, 0.77993922, 0.77816035,\n",
      "       0.77833331, 0.76414509, 0.78067836, 0.77172854, 0.78044263,\n",
      "       0.77416272, 0.78080448, 0.77623289, 0.78054368, 0.77836333,\n",
      "       0.7784225 , 0.76176918, 0.7808739 , 0.77082424, 0.78054404,\n",
      "       0.77377902, 0.7808053 , 0.7758589 , 0.78054368, 0.77807455,\n",
      "       0.77795034, 0.76181435, 0.78090295, 0.76944992, 0.78054404,\n",
      "       0.77334843, 0.7808053 , 0.7759055 , 0.78054368, 0.77808203,\n",
      "       0.76693795, 0.75742302, 0.76682351, 0.7574033 , 0.76674269,\n",
      "       0.75739124, 0.76703311, 0.75739124, 0.76696366, 0.75738932,\n",
      "       0.77875419, 0.77349745, 0.78034932, 0.77560075, 0.78014154,\n",
      "       0.77654802, 0.7801629 , 0.777794  , 0.77986369, 0.7781299 ,\n",
      "       0.77788144, 0.76437268, 0.78115953, 0.77165548, 0.78051768,\n",
      "       0.77458095, 0.78083796, 0.77638832, 0.78040262, 0.77820307,\n",
      "       0.77813858, 0.76218311, 0.78143416, 0.77112508, 0.7804891 ,\n",
      "       0.77360856, 0.78085697, 0.77607629, 0.78040262, 0.77789526,\n",
      "       0.77815011, 0.7621898 , 0.7814703 , 0.77076272, 0.7804891 ,\n",
      "       0.77374801, 0.78085697, 0.77623722, 0.78040262, 0.77795838,\n",
      "       0.73760624, 0.70625848, 0.73118826, 0.69803496, 0.72143588,\n",
      "       0.70444771, 0.74672779, 0.71616087, 0.73623581, 0.71495119,\n",
      "       0.65572837, 0.66155891, 0.65978292, 0.66452146, 0.67660561,\n",
      "       0.66293823, 0.69743296, 0.66776602, 0.69724694, 0.67996019,\n",
      "       0.65678112, 0.67425204, 0.66647604, 0.67567222, 0.66993109,\n",
      "       0.67685276, 0.68091629, 0.67561723, 0.69401654, 0.68149117,\n",
      "       0.64375168, 0.68392086, 0.66746739, 0.67880534, 0.67515974,\n",
      "       0.68392384, 0.68091629, 0.67560317, 0.69401654, 0.6819423 ,\n",
      "       0.64375168, 0.69060742, 0.66746739, 0.68459754, 0.67515974,\n",
      "       0.68129041, 0.68091629, 0.67845951, 0.69401654, 0.69171488,\n",
      "       0.73408067, 0.70957499, 0.73155474, 0.69803496, 0.7215133 ,\n",
      "       0.70444771, 0.74672779, 0.71616087, 0.73623581, 0.71495119,\n",
      "       0.65749476, 0.65719219, 0.66723064, 0.65653791, 0.67705224,\n",
      "       0.66774594, 0.68324751, 0.66780959, 0.71015439, 0.68569496,\n",
      "       0.64778813, 0.67751446, 0.66661923, 0.67636089, 0.67277272,\n",
      "       0.67244254, 0.68559251, 0.67628605, 0.69586172, 0.67357605,\n",
      "       0.66022233, 0.68194016, 0.66800311, 0.67682711, 0.67357103,\n",
      "       0.68017432, 0.68559251, 0.6826058 , 0.69586172, 0.69103462,\n",
      "       0.65815064, 0.68242433, 0.66800311, 0.67478349, 0.67357103,\n",
      "       0.69144024, 0.68559251, 0.68988082, 0.69586172, 0.68625701])] \n",
      "\n",
      "mean AUC :  0.7295643194062087\n",
      "All std:  [array([0.01667517, 0.01301782, 0.01668685, 0.01304667, 0.01681911,\n",
      "       0.0130384 , 0.01686676, 0.0130384 , 0.01685646, 0.01303619,\n",
      "       0.0204837 , 0.01885647, 0.01947268, 0.01850775, 0.01972694,\n",
      "       0.01888035, 0.02044102, 0.01961132, 0.02071616, 0.02004127,\n",
      "       0.01944235, 0.01898667, 0.02032825, 0.01810822, 0.02022798,\n",
      "       0.01804645, 0.02057878, 0.01822331, 0.02086684, 0.01934854,\n",
      "       0.01980383, 0.0187816 , 0.02037615, 0.01854652, 0.02020585,\n",
      "       0.01876435, 0.02057127, 0.0180847 , 0.02086684, 0.01920681,\n",
      "       0.01962967, 0.01898992, 0.02040358, 0.01875277, 0.02020585,\n",
      "       0.01847486, 0.02057127, 0.01821589, 0.02086684, 0.01923121,\n",
      "       0.01667517, 0.01301782, 0.01668685, 0.01304667, 0.01681911,\n",
      "       0.0130384 , 0.01686676, 0.0130384 , 0.01685646, 0.01303619,\n",
      "       0.0202974 , 0.01889856, 0.01954693, 0.01858871, 0.01960008,\n",
      "       0.01884136, 0.02024438, 0.01959382, 0.02060128, 0.02009947,\n",
      "       0.01938505, 0.01899847, 0.02009522, 0.01831725, 0.02012832,\n",
      "       0.01805545, 0.02020227, 0.01844496, 0.02060203, 0.0193223 ,\n",
      "       0.01961972, 0.0185826 , 0.02022155, 0.01841239, 0.02026384,\n",
      "       0.01826914, 0.02018785, 0.01813194, 0.02060203, 0.01945396,\n",
      "       0.02000053, 0.01883673, 0.02024962, 0.01875016, 0.02026384,\n",
      "       0.01867256, 0.02018785, 0.01816697, 0.02060203, 0.01946716,\n",
      "       0.02922016, 0.05211786, 0.01756943, 0.07533761, 0.01413032,\n",
      "       0.05098147, 0.01766874, 0.05443904, 0.01327911, 0.06713984,\n",
      "       0.0131157 , 0.06176192, 0.00630617, 0.04653327, 0.01596662,\n",
      "       0.05578617, 0.0145419 , 0.0496041 , 0.01519377, 0.03719813,\n",
      "       0.01122218, 0.03999495, 0.01099407, 0.03463101, 0.01922476,\n",
      "       0.04394272, 0.01156513, 0.03897849, 0.01778073, 0.0420824 ,\n",
      "       0.01724205, 0.0316293 , 0.00827343, 0.03864744, 0.02239719,\n",
      "       0.03599527, 0.01156513, 0.0341542 , 0.01778073, 0.02966453,\n",
      "       0.01724205, 0.03281045, 0.00827343, 0.03469365, 0.02239719,\n",
      "       0.02367078, 0.01156513, 0.03330776, 0.01778073, 0.03206204,\n",
      "       0.02618119, 0.05463729, 0.01729901, 0.07533761, 0.01427405,\n",
      "       0.05098147, 0.01766874, 0.05443904, 0.01327911, 0.06713984,\n",
      "       0.01897604, 0.05721014, 0.00862902, 0.04299735, 0.0230308 ,\n",
      "       0.04263643, 0.00963647, 0.05324782, 0.02386577, 0.03817588,\n",
      "       0.01293745, 0.03910147, 0.01705375, 0.04268747, 0.01706368,\n",
      "       0.04535911, 0.0220788 , 0.03973187, 0.01148   , 0.03976796,\n",
      "       0.02386263, 0.0362008 , 0.01468363, 0.03611288, 0.01661507,\n",
      "       0.03040058, 0.0220788 , 0.03116445, 0.01148   , 0.02724545,\n",
      "       0.01927499, 0.02995427, 0.01468363, 0.03916424, 0.01661507,\n",
      "       0.02349422, 0.0220788 , 0.0337049 , 0.01148   , 0.02956191])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.4, 'max_depth': 26, 'min_child_weight': 5, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  92\n",
      "Best AUC : 0.7814702970849985 ( std: 0.020249623985031783 ) \n",
      "\n",
      "running time:  4094.795256137848  detik. Dalam menit:  68.24658760229747  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:25:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "iterasi:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76693795, 0.75742302, 0.76682351, 0.7574033 , 0.76674269,\n",
      "       0.75739124, 0.76703311, 0.75739124, 0.76696366, 0.75738932,\n",
      "       0.77861329, 0.77342111, 0.78017177, 0.77534777, 0.77994028,\n",
      "       0.77655868, 0.78015593, 0.77782613, 0.77993922, 0.77816035,\n",
      "       0.77833331, 0.76414509, 0.78067836, 0.77172854, 0.78044263,\n",
      "       0.77416272, 0.78080448, 0.77623289, 0.78054368, 0.77836333,\n",
      "       0.7784225 , 0.76176918, 0.7808739 , 0.77082424, 0.78054404,\n",
      "       0.77377902, 0.7808053 , 0.7758589 , 0.78054368, 0.77807455,\n",
      "       0.77795034, 0.76181435, 0.78090295, 0.76944992, 0.78054404,\n",
      "       0.77334843, 0.7808053 , 0.7759055 , 0.78054368, 0.77808203,\n",
      "       0.76693795, 0.75742302, 0.76682351, 0.7574033 , 0.76674269,\n",
      "       0.75739124, 0.76703311, 0.75739124, 0.76696366, 0.75738932,\n",
      "       0.77875419, 0.77349745, 0.78034932, 0.77560075, 0.78014154,\n",
      "       0.77654802, 0.7801629 , 0.777794  , 0.77986369, 0.7781299 ,\n",
      "       0.77788144, 0.76437268, 0.78115953, 0.77165548, 0.78051768,\n",
      "       0.77458095, 0.78083796, 0.77638832, 0.78040262, 0.77820307,\n",
      "       0.77813858, 0.76218311, 0.78143416, 0.77112508, 0.7804891 ,\n",
      "       0.77360856, 0.78085697, 0.77607629, 0.78040262, 0.77789526,\n",
      "       0.77815011, 0.7621898 , 0.7814703 , 0.77076272, 0.7804891 ,\n",
      "       0.77374801, 0.78085697, 0.77623722, 0.78040262, 0.77795838,\n",
      "       0.73760624, 0.70625848, 0.73118826, 0.69803496, 0.72143588,\n",
      "       0.70444771, 0.74672779, 0.71616087, 0.73623581, 0.71495119,\n",
      "       0.65572837, 0.66155891, 0.65978292, 0.66452146, 0.67660561,\n",
      "       0.66293823, 0.69743296, 0.66776602, 0.69724694, 0.67996019,\n",
      "       0.65678112, 0.67425204, 0.66647604, 0.67567222, 0.66993109,\n",
      "       0.67685276, 0.68091629, 0.67561723, 0.69401654, 0.68149117,\n",
      "       0.64375168, 0.68392086, 0.66746739, 0.67880534, 0.67515974,\n",
      "       0.68392384, 0.68091629, 0.67560317, 0.69401654, 0.6819423 ,\n",
      "       0.64375168, 0.69060742, 0.66746739, 0.68459754, 0.67515974,\n",
      "       0.68129041, 0.68091629, 0.67845951, 0.69401654, 0.69171488,\n",
      "       0.73408067, 0.70957499, 0.73155474, 0.69803496, 0.7215133 ,\n",
      "       0.70444771, 0.74672779, 0.71616087, 0.73623581, 0.71495119,\n",
      "       0.65749476, 0.65719219, 0.66723064, 0.65653791, 0.67705224,\n",
      "       0.66774594, 0.68324751, 0.66780959, 0.71015439, 0.68569496,\n",
      "       0.64778813, 0.67751446, 0.66661923, 0.67636089, 0.67277272,\n",
      "       0.67244254, 0.68559251, 0.67628605, 0.69586172, 0.67357605,\n",
      "       0.66022233, 0.68194016, 0.66800311, 0.67682711, 0.67357103,\n",
      "       0.68017432, 0.68559251, 0.6826058 , 0.69586172, 0.69103462,\n",
      "       0.65815064, 0.68242433, 0.66800311, 0.67478349, 0.67357103,\n",
      "       0.69144024, 0.68559251, 0.68988082, 0.69586172, 0.68625701])] \n",
      "\n",
      "mean AUC :  0.7295643194062087\n",
      "All std:  [array([0.01667517, 0.01301782, 0.01668685, 0.01304667, 0.01681911,\n",
      "       0.0130384 , 0.01686676, 0.0130384 , 0.01685646, 0.01303619,\n",
      "       0.0204837 , 0.01885647, 0.01947268, 0.01850775, 0.01972694,\n",
      "       0.01888035, 0.02044102, 0.01961132, 0.02071616, 0.02004127,\n",
      "       0.01944235, 0.01898667, 0.02032825, 0.01810822, 0.02022798,\n",
      "       0.01804645, 0.02057878, 0.01822331, 0.02086684, 0.01934854,\n",
      "       0.01980383, 0.0187816 , 0.02037615, 0.01854652, 0.02020585,\n",
      "       0.01876435, 0.02057127, 0.0180847 , 0.02086684, 0.01920681,\n",
      "       0.01962967, 0.01898992, 0.02040358, 0.01875277, 0.02020585,\n",
      "       0.01847486, 0.02057127, 0.01821589, 0.02086684, 0.01923121,\n",
      "       0.01667517, 0.01301782, 0.01668685, 0.01304667, 0.01681911,\n",
      "       0.0130384 , 0.01686676, 0.0130384 , 0.01685646, 0.01303619,\n",
      "       0.0202974 , 0.01889856, 0.01954693, 0.01858871, 0.01960008,\n",
      "       0.01884136, 0.02024438, 0.01959382, 0.02060128, 0.02009947,\n",
      "       0.01938505, 0.01899847, 0.02009522, 0.01831725, 0.02012832,\n",
      "       0.01805545, 0.02020227, 0.01844496, 0.02060203, 0.0193223 ,\n",
      "       0.01961972, 0.0185826 , 0.02022155, 0.01841239, 0.02026384,\n",
      "       0.01826914, 0.02018785, 0.01813194, 0.02060203, 0.01945396,\n",
      "       0.02000053, 0.01883673, 0.02024962, 0.01875016, 0.02026384,\n",
      "       0.01867256, 0.02018785, 0.01816697, 0.02060203, 0.01946716,\n",
      "       0.02922016, 0.05211786, 0.01756943, 0.07533761, 0.01413032,\n",
      "       0.05098147, 0.01766874, 0.05443904, 0.01327911, 0.06713984,\n",
      "       0.0131157 , 0.06176192, 0.00630617, 0.04653327, 0.01596662,\n",
      "       0.05578617, 0.0145419 , 0.0496041 , 0.01519377, 0.03719813,\n",
      "       0.01122218, 0.03999495, 0.01099407, 0.03463101, 0.01922476,\n",
      "       0.04394272, 0.01156513, 0.03897849, 0.01778073, 0.0420824 ,\n",
      "       0.01724205, 0.0316293 , 0.00827343, 0.03864744, 0.02239719,\n",
      "       0.03599527, 0.01156513, 0.0341542 , 0.01778073, 0.02966453,\n",
      "       0.01724205, 0.03281045, 0.00827343, 0.03469365, 0.02239719,\n",
      "       0.02367078, 0.01156513, 0.03330776, 0.01778073, 0.03206204,\n",
      "       0.02618119, 0.05463729, 0.01729901, 0.07533761, 0.01427405,\n",
      "       0.05098147, 0.01766874, 0.05443904, 0.01327911, 0.06713984,\n",
      "       0.01897604, 0.05721014, 0.00862902, 0.04299735, 0.0230308 ,\n",
      "       0.04263643, 0.00963647, 0.05324782, 0.02386577, 0.03817588,\n",
      "       0.01293745, 0.03910147, 0.01705375, 0.04268747, 0.01706368,\n",
      "       0.04535911, 0.0220788 , 0.03973187, 0.01148   , 0.03976796,\n",
      "       0.02386263, 0.0362008 , 0.01468363, 0.03611288, 0.01661507,\n",
      "       0.03040058, 0.0220788 , 0.03116445, 0.01148   , 0.02724545,\n",
      "       0.01927499, 0.02995427, 0.01468363, 0.03916424, 0.01661507,\n",
      "       0.02349422, 0.0220788 , 0.0337049 , 0.01148   , 0.02956191])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.4, 'max_depth': 26, 'min_child_weight': 5, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  92\n",
      "Best AUC : 0.7814702970849985 ( std: 0.020249623985031783 ) \n",
      "\n",
      "running time:  4162.834578990936  detik. Dalam menit:  69.3805763165156  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "iterasi:  2 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76693795, 0.75742302, 0.76682351, 0.7574033 , 0.76674269,\n",
      "       0.75739124, 0.76703311, 0.75739124, 0.76696366, 0.75738932,\n",
      "       0.77861329, 0.77342111, 0.78017177, 0.77534777, 0.77994028,\n",
      "       0.77655868, 0.78015593, 0.77782613, 0.77993922, 0.77816035,\n",
      "       0.77833331, 0.76414509, 0.78067836, 0.77172854, 0.78044263,\n",
      "       0.77416272, 0.78080448, 0.77623289, 0.78054368, 0.77836333,\n",
      "       0.7784225 , 0.76176918, 0.7808739 , 0.77082424, 0.78054404,\n",
      "       0.77377902, 0.7808053 , 0.7758589 , 0.78054368, 0.77807455,\n",
      "       0.77795034, 0.76181435, 0.78090295, 0.76944992, 0.78054404,\n",
      "       0.77334843, 0.7808053 , 0.7759055 , 0.78054368, 0.77808203,\n",
      "       0.76693795, 0.75742302, 0.76682351, 0.7574033 , 0.76674269,\n",
      "       0.75739124, 0.76703311, 0.75739124, 0.76696366, 0.75738932,\n",
      "       0.77875419, 0.77349745, 0.78034932, 0.77560075, 0.78014154,\n",
      "       0.77654802, 0.7801629 , 0.777794  , 0.77986369, 0.7781299 ,\n",
      "       0.77788144, 0.76437268, 0.78115953, 0.77165548, 0.78051768,\n",
      "       0.77458095, 0.78083796, 0.77638832, 0.78040262, 0.77820307,\n",
      "       0.77813858, 0.76218311, 0.78143416, 0.77112508, 0.7804891 ,\n",
      "       0.77360856, 0.78085697, 0.77607629, 0.78040262, 0.77789526,\n",
      "       0.77815011, 0.7621898 , 0.7814703 , 0.77076272, 0.7804891 ,\n",
      "       0.77374801, 0.78085697, 0.77623722, 0.78040262, 0.77795838,\n",
      "       0.73760624, 0.70625848, 0.73118826, 0.69803496, 0.72143588,\n",
      "       0.70444771, 0.74672779, 0.71616087, 0.73623581, 0.71495119,\n",
      "       0.65572837, 0.66155891, 0.65978292, 0.66452146, 0.67660561,\n",
      "       0.66293823, 0.69743296, 0.66776602, 0.69724694, 0.67996019,\n",
      "       0.65678112, 0.67425204, 0.66647604, 0.67567222, 0.66993109,\n",
      "       0.67685276, 0.68091629, 0.67561723, 0.69401654, 0.68149117,\n",
      "       0.64375168, 0.68392086, 0.66746739, 0.67880534, 0.67515974,\n",
      "       0.68392384, 0.68091629, 0.67560317, 0.69401654, 0.6819423 ,\n",
      "       0.64375168, 0.69060742, 0.66746739, 0.68459754, 0.67515974,\n",
      "       0.68129041, 0.68091629, 0.67845951, 0.69401654, 0.69171488,\n",
      "       0.73408067, 0.70957499, 0.73155474, 0.69803496, 0.7215133 ,\n",
      "       0.70444771, 0.74672779, 0.71616087, 0.73623581, 0.71495119,\n",
      "       0.65749476, 0.65719219, 0.66723064, 0.65653791, 0.67705224,\n",
      "       0.66774594, 0.68324751, 0.66780959, 0.71015439, 0.68569496,\n",
      "       0.64778813, 0.67751446, 0.66661923, 0.67636089, 0.67277272,\n",
      "       0.67244254, 0.68559251, 0.67628605, 0.69586172, 0.67357605,\n",
      "       0.66022233, 0.68194016, 0.66800311, 0.67682711, 0.67357103,\n",
      "       0.68017432, 0.68559251, 0.6826058 , 0.69586172, 0.69103462,\n",
      "       0.65815064, 0.68242433, 0.66800311, 0.67478349, 0.67357103,\n",
      "       0.69144024, 0.68559251, 0.68988082, 0.69586172, 0.68625701])] \n",
      "\n",
      "mean AUC :  0.7295643194062087\n",
      "All std:  [array([0.01667517, 0.01301782, 0.01668685, 0.01304667, 0.01681911,\n",
      "       0.0130384 , 0.01686676, 0.0130384 , 0.01685646, 0.01303619,\n",
      "       0.0204837 , 0.01885647, 0.01947268, 0.01850775, 0.01972694,\n",
      "       0.01888035, 0.02044102, 0.01961132, 0.02071616, 0.02004127,\n",
      "       0.01944235, 0.01898667, 0.02032825, 0.01810822, 0.02022798,\n",
      "       0.01804645, 0.02057878, 0.01822331, 0.02086684, 0.01934854,\n",
      "       0.01980383, 0.0187816 , 0.02037615, 0.01854652, 0.02020585,\n",
      "       0.01876435, 0.02057127, 0.0180847 , 0.02086684, 0.01920681,\n",
      "       0.01962967, 0.01898992, 0.02040358, 0.01875277, 0.02020585,\n",
      "       0.01847486, 0.02057127, 0.01821589, 0.02086684, 0.01923121,\n",
      "       0.01667517, 0.01301782, 0.01668685, 0.01304667, 0.01681911,\n",
      "       0.0130384 , 0.01686676, 0.0130384 , 0.01685646, 0.01303619,\n",
      "       0.0202974 , 0.01889856, 0.01954693, 0.01858871, 0.01960008,\n",
      "       0.01884136, 0.02024438, 0.01959382, 0.02060128, 0.02009947,\n",
      "       0.01938505, 0.01899847, 0.02009522, 0.01831725, 0.02012832,\n",
      "       0.01805545, 0.02020227, 0.01844496, 0.02060203, 0.0193223 ,\n",
      "       0.01961972, 0.0185826 , 0.02022155, 0.01841239, 0.02026384,\n",
      "       0.01826914, 0.02018785, 0.01813194, 0.02060203, 0.01945396,\n",
      "       0.02000053, 0.01883673, 0.02024962, 0.01875016, 0.02026384,\n",
      "       0.01867256, 0.02018785, 0.01816697, 0.02060203, 0.01946716,\n",
      "       0.02922016, 0.05211786, 0.01756943, 0.07533761, 0.01413032,\n",
      "       0.05098147, 0.01766874, 0.05443904, 0.01327911, 0.06713984,\n",
      "       0.0131157 , 0.06176192, 0.00630617, 0.04653327, 0.01596662,\n",
      "       0.05578617, 0.0145419 , 0.0496041 , 0.01519377, 0.03719813,\n",
      "       0.01122218, 0.03999495, 0.01099407, 0.03463101, 0.01922476,\n",
      "       0.04394272, 0.01156513, 0.03897849, 0.01778073, 0.0420824 ,\n",
      "       0.01724205, 0.0316293 , 0.00827343, 0.03864744, 0.02239719,\n",
      "       0.03599527, 0.01156513, 0.0341542 , 0.01778073, 0.02966453,\n",
      "       0.01724205, 0.03281045, 0.00827343, 0.03469365, 0.02239719,\n",
      "       0.02367078, 0.01156513, 0.03330776, 0.01778073, 0.03206204,\n",
      "       0.02618119, 0.05463729, 0.01729901, 0.07533761, 0.01427405,\n",
      "       0.05098147, 0.01766874, 0.05443904, 0.01327911, 0.06713984,\n",
      "       0.01897604, 0.05721014, 0.00862902, 0.04299735, 0.0230308 ,\n",
      "       0.04263643, 0.00963647, 0.05324782, 0.02386577, 0.03817588,\n",
      "       0.01293745, 0.03910147, 0.01705375, 0.04268747, 0.01706368,\n",
      "       0.04535911, 0.0220788 , 0.03973187, 0.01148   , 0.03976796,\n",
      "       0.02386263, 0.0362008 , 0.01468363, 0.03611288, 0.01661507,\n",
      "       0.03040058, 0.0220788 , 0.03116445, 0.01148   , 0.02724545,\n",
      "       0.01927499, 0.02995427, 0.01468363, 0.03916424, 0.01661507,\n",
      "       0.02349422, 0.0220788 , 0.0337049 , 0.01148   , 0.02956191])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.4, 'max_depth': 26, 'min_child_weight': 5, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  92\n",
      "Best AUC : 0.7814702970849985 ( std: 0.020249623985031783 ) \n",
      "\n",
      "running time:  4142.172626256943  detik. Dalam menit:  69.03621043761571  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:45:21] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "iterasi:  3 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76693795, 0.75742302, 0.76682351, 0.7574033 , 0.76674269,\n",
      "       0.75739124, 0.76703311, 0.75739124, 0.76696366, 0.75738932,\n",
      "       0.77861329, 0.77342111, 0.78017177, 0.77534777, 0.77994028,\n",
      "       0.77655868, 0.78015593, 0.77782613, 0.77993922, 0.77816035,\n",
      "       0.77833331, 0.76414509, 0.78067836, 0.77172854, 0.78044263,\n",
      "       0.77416272, 0.78080448, 0.77623289, 0.78054368, 0.77836333,\n",
      "       0.7784225 , 0.76176918, 0.7808739 , 0.77082424, 0.78054404,\n",
      "       0.77377902, 0.7808053 , 0.7758589 , 0.78054368, 0.77807455,\n",
      "       0.77795034, 0.76181435, 0.78090295, 0.76944992, 0.78054404,\n",
      "       0.77334843, 0.7808053 , 0.7759055 , 0.78054368, 0.77808203,\n",
      "       0.76693795, 0.75742302, 0.76682351, 0.7574033 , 0.76674269,\n",
      "       0.75739124, 0.76703311, 0.75739124, 0.76696366, 0.75738932,\n",
      "       0.77875419, 0.77349745, 0.78034932, 0.77560075, 0.78014154,\n",
      "       0.77654802, 0.7801629 , 0.777794  , 0.77986369, 0.7781299 ,\n",
      "       0.77788144, 0.76437268, 0.78115953, 0.77165548, 0.78051768,\n",
      "       0.77458095, 0.78083796, 0.77638832, 0.78040262, 0.77820307,\n",
      "       0.77813858, 0.76218311, 0.78143416, 0.77112508, 0.7804891 ,\n",
      "       0.77360856, 0.78085697, 0.77607629, 0.78040262, 0.77789526,\n",
      "       0.77815011, 0.7621898 , 0.7814703 , 0.77076272, 0.7804891 ,\n",
      "       0.77374801, 0.78085697, 0.77623722, 0.78040262, 0.77795838,\n",
      "       0.73760624, 0.70625848, 0.73118826, 0.69803496, 0.72143588,\n",
      "       0.70444771, 0.74672779, 0.71616087, 0.73623581, 0.71495119,\n",
      "       0.65572837, 0.66155891, 0.65978292, 0.66452146, 0.67660561,\n",
      "       0.66293823, 0.69743296, 0.66776602, 0.69724694, 0.67996019,\n",
      "       0.65678112, 0.67425204, 0.66647604, 0.67567222, 0.66993109,\n",
      "       0.67685276, 0.68091629, 0.67561723, 0.69401654, 0.68149117,\n",
      "       0.64375168, 0.68392086, 0.66746739, 0.67880534, 0.67515974,\n",
      "       0.68392384, 0.68091629, 0.67560317, 0.69401654, 0.6819423 ,\n",
      "       0.64375168, 0.69060742, 0.66746739, 0.68459754, 0.67515974,\n",
      "       0.68129041, 0.68091629, 0.67845951, 0.69401654, 0.69171488,\n",
      "       0.73408067, 0.70957499, 0.73155474, 0.69803496, 0.7215133 ,\n",
      "       0.70444771, 0.74672779, 0.71616087, 0.73623581, 0.71495119,\n",
      "       0.65749476, 0.65719219, 0.66723064, 0.65653791, 0.67705224,\n",
      "       0.66774594, 0.68324751, 0.66780959, 0.71015439, 0.68569496,\n",
      "       0.64778813, 0.67751446, 0.66661923, 0.67636089, 0.67277272,\n",
      "       0.67244254, 0.68559251, 0.67628605, 0.69586172, 0.67357605,\n",
      "       0.66022233, 0.68194016, 0.66800311, 0.67682711, 0.67357103,\n",
      "       0.68017432, 0.68559251, 0.6826058 , 0.69586172, 0.69103462,\n",
      "       0.65815064, 0.68242433, 0.66800311, 0.67478349, 0.67357103,\n",
      "       0.69144024, 0.68559251, 0.68988082, 0.69586172, 0.68625701])] \n",
      "\n",
      "mean AUC :  0.7295643194062087\n",
      "All std:  [array([0.01667517, 0.01301782, 0.01668685, 0.01304667, 0.01681911,\n",
      "       0.0130384 , 0.01686676, 0.0130384 , 0.01685646, 0.01303619,\n",
      "       0.0204837 , 0.01885647, 0.01947268, 0.01850775, 0.01972694,\n",
      "       0.01888035, 0.02044102, 0.01961132, 0.02071616, 0.02004127,\n",
      "       0.01944235, 0.01898667, 0.02032825, 0.01810822, 0.02022798,\n",
      "       0.01804645, 0.02057878, 0.01822331, 0.02086684, 0.01934854,\n",
      "       0.01980383, 0.0187816 , 0.02037615, 0.01854652, 0.02020585,\n",
      "       0.01876435, 0.02057127, 0.0180847 , 0.02086684, 0.01920681,\n",
      "       0.01962967, 0.01898992, 0.02040358, 0.01875277, 0.02020585,\n",
      "       0.01847486, 0.02057127, 0.01821589, 0.02086684, 0.01923121,\n",
      "       0.01667517, 0.01301782, 0.01668685, 0.01304667, 0.01681911,\n",
      "       0.0130384 , 0.01686676, 0.0130384 , 0.01685646, 0.01303619,\n",
      "       0.0202974 , 0.01889856, 0.01954693, 0.01858871, 0.01960008,\n",
      "       0.01884136, 0.02024438, 0.01959382, 0.02060128, 0.02009947,\n",
      "       0.01938505, 0.01899847, 0.02009522, 0.01831725, 0.02012832,\n",
      "       0.01805545, 0.02020227, 0.01844496, 0.02060203, 0.0193223 ,\n",
      "       0.01961972, 0.0185826 , 0.02022155, 0.01841239, 0.02026384,\n",
      "       0.01826914, 0.02018785, 0.01813194, 0.02060203, 0.01945396,\n",
      "       0.02000053, 0.01883673, 0.02024962, 0.01875016, 0.02026384,\n",
      "       0.01867256, 0.02018785, 0.01816697, 0.02060203, 0.01946716,\n",
      "       0.02922016, 0.05211786, 0.01756943, 0.07533761, 0.01413032,\n",
      "       0.05098147, 0.01766874, 0.05443904, 0.01327911, 0.06713984,\n",
      "       0.0131157 , 0.06176192, 0.00630617, 0.04653327, 0.01596662,\n",
      "       0.05578617, 0.0145419 , 0.0496041 , 0.01519377, 0.03719813,\n",
      "       0.01122218, 0.03999495, 0.01099407, 0.03463101, 0.01922476,\n",
      "       0.04394272, 0.01156513, 0.03897849, 0.01778073, 0.0420824 ,\n",
      "       0.01724205, 0.0316293 , 0.00827343, 0.03864744, 0.02239719,\n",
      "       0.03599527, 0.01156513, 0.0341542 , 0.01778073, 0.02966453,\n",
      "       0.01724205, 0.03281045, 0.00827343, 0.03469365, 0.02239719,\n",
      "       0.02367078, 0.01156513, 0.03330776, 0.01778073, 0.03206204,\n",
      "       0.02618119, 0.05463729, 0.01729901, 0.07533761, 0.01427405,\n",
      "       0.05098147, 0.01766874, 0.05443904, 0.01327911, 0.06713984,\n",
      "       0.01897604, 0.05721014, 0.00862902, 0.04299735, 0.0230308 ,\n",
      "       0.04263643, 0.00963647, 0.05324782, 0.02386577, 0.03817588,\n",
      "       0.01293745, 0.03910147, 0.01705375, 0.04268747, 0.01706368,\n",
      "       0.04535911, 0.0220788 , 0.03973187, 0.01148   , 0.03976796,\n",
      "       0.02386263, 0.0362008 , 0.01468363, 0.03611288, 0.01661507,\n",
      "       0.03040058, 0.0220788 , 0.03116445, 0.01148   , 0.02724545,\n",
      "       0.01927499, 0.02995427, 0.01468363, 0.03916424, 0.01661507,\n",
      "       0.02349422, 0.0220788 , 0.0337049 , 0.01148   , 0.02956191])] \n",
      "\n",
      "Best Hyperparameter:  {'eta': 0.01, 'gamma': 0.4, 'max_depth': 26, 'min_child_weight': 5, 'subsample': 0.1} \n",
      "\n",
      "Best index/iterasi :  92\n",
      "Best AUC : 0.7814702970849985 ( std: 0.020249623985031783 ) \n",
      "\n",
      "running time:  4278.0480489730835  detik. Dalam menit:  71.30080081621806  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8a11029b2329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_credit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_credit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper_space_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iterasi: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint_hasil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterasi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f7df020fa3a6>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(X, y, model, parameter, evalscore)\u001b[0m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mbest_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for i in range(0,10):\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=grid_search(X_credit,y_credit,model_x,hyper_space_1,eval_metric)\n",
    "    print(\"iterasi: \",i,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dataset 3(Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T03:29:35.461280Z",
     "start_time": "2020-11-18T03:29:35.452265Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Experiment 1: \n",
    "    - Random search \n",
    "    - Iterasi : 200\n",
    "    - random state= 1,12,22,32,42,52,62,72,82,92\n",
    "- Experiment 2: \n",
    "    - BO (gaussian process) \n",
    "    - iterasi : 200\n",
    "    - random state= 1,12,22,32,42,52,62,72,82,92\n",
    "- Experiment 3: \n",
    "    - GS \n",
    "    - 10 iterasi \n",
    "- Experiment 4: \n",
    "    - BOHB \n",
    "    - random state= 1,12,22,32,42,52,62,72,82,92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Experiment 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Dataset 1(Bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T03:03:22.388879Z",
     "start_time": "2020-12-29T02:31:41.473047Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.64934773, 0.60383765, 0.48596784, 0.52770184, 0.54911355,\n",
      "       0.49382919, 0.59260976, 0.49493149, 0.50105477, 0.4994429 ,\n",
      "       0.54965786, 0.57019378, 0.56532566, 0.53868043, 0.50046092,\n",
      "       0.5088446 , 0.57384636, 0.51602078, 0.51679386, 0.49581015,\n",
      "       0.60646803, 0.59648047, 0.56610731, 0.49369643, 0.56568432,\n",
      "       0.55104648, 0.59016253, 0.49510055, 0.49982082, 0.6403183 ,\n",
      "       0.50102917, 0.5773621 , 0.53615932, 0.58504053, 0.56138618,\n",
      "       0.52308665, 0.56661144, 0.6820052 , 0.47589831, 0.5179423 ,\n",
      "       0.57959536, 0.53730644, 0.57470243, 0.52029429, 0.50696387,\n",
      "       0.51647711, 0.61076777, 0.60966971, 0.51007086, 0.49298763,\n",
      "       0.50255045, 0.49366227, 0.57552585, 0.52121229, 0.59091478,\n",
      "       0.59024175, 0.53911108, 0.60636331, 0.49447606, 0.55418106,\n",
      "       0.52079291, 0.60014342, 0.57350955, 0.52187529, 0.56515413,\n",
      "       0.72747527, 0.5222693 , 0.52564239, 0.50645044, 0.54948718,\n",
      "       0.48518538, 0.51950252, 0.48034256, 0.53093759, 0.53239081,\n",
      "       0.57910223, 0.60252186, 0.52156359, 0.64853447, 0.5444917 ,\n",
      "       0.57224306, 0.51091458, 0.57893766, 0.59312383, 0.61673914,\n",
      "       0.53823217, 0.58015383, 0.50371005, 0.52387848, 0.52470539,\n",
      "       0.53677219, 0.63234584, 0.5041929 , 0.51976296, 0.70630407,\n",
      "       0.61966056, 0.50594532, 0.51685311, 0.51418109, 0.47394006,\n",
      "       0.53644186, 0.50774467, 0.62684759, 0.49903697, 0.54182072,\n",
      "       0.60554358, 0.5998859 , 0.49874888, 0.50143484, 0.49652173,\n",
      "       0.50474705, 0.56259726, 0.58296998, 0.54611417, 0.53185492,\n",
      "       0.4950004 , 0.49135543, 0.49277556, 0.54479789, 0.55844301,\n",
      "       0.56710547, 0.77313958, 0.5312412 , 0.4842451 , 0.50497372,\n",
      "       0.50539004, 0.50482722, 0.5409452 , 0.55272416, 0.54752539,\n",
      "       0.48364413, 0.50814782, 0.5613479 , 0.50046427, 0.50839412,\n",
      "       0.53023178, 0.50132379, 0.57895378, 0.54755339, 0.58184032,\n",
      "       0.53715268, 0.55252889, 0.54009266, 0.59993757, 0.52006443,\n",
      "       0.5166228 , 0.50009544, 0.57149165, 0.57314237, 0.52406442,\n",
      "       0.4894101 , 0.55642764, 0.48113462, 0.53069204, 0.56308211,\n",
      "       0.58545939, 0.61349136, 0.55360541, 0.50274339, 0.50581635,\n",
      "       0.59095546, 0.59491856, 0.61085937, 0.52634362, 0.56106332,\n",
      "       0.58959499, 0.54634581, 0.52207515, 0.53542333, 0.59228587,\n",
      "       0.52297568, 0.60305825, 0.56625774, 0.53727344, 0.63563765,\n",
      "       0.58742288, 0.53748704, 0.53332623, 0.50581689, 0.53931838,\n",
      "       0.51423963, 0.50480227, 0.58206883, 0.53143114, 0.52052952,\n",
      "       0.55679519, 0.53410384, 0.54480522, 0.59141601, 0.51537609,\n",
      "       0.54755695, 0.51671221, 0.56745737, 0.47799265, 0.60442817,\n",
      "       0.59252532, 0.57129132, 0.58015902, 0.49150453, 0.57853898])] \n",
      "\n",
      "mean AUC :  0.5471992544596452\n",
      "All std:  [array([0.12544568, 0.09968359, 0.07101369, 0.092247  , 0.09437343,\n",
      "       0.07638883, 0.07582283, 0.08973514, 0.09637876, 0.06311918,\n",
      "       0.0755752 , 0.05334742, 0.06659432, 0.071124  , 0.07168071,\n",
      "       0.09858725, 0.05434662, 0.07412362, 0.06780548, 0.07230272,\n",
      "       0.09762178, 0.08638479, 0.05585442, 0.10513542, 0.05160878,\n",
      "       0.04908104, 0.06605466, 0.05570771, 0.0931345 , 0.10996572,\n",
      "       0.09606764, 0.04146587, 0.11093257, 0.06396824, 0.08420061,\n",
      "       0.06870757, 0.07342458, 0.12190302, 0.1009728 , 0.05988402,\n",
      "       0.06703993, 0.07061876, 0.07292843, 0.06684085, 0.07061557,\n",
      "       0.06752391, 0.07963143, 0.09888043, 0.07851416, 0.06961083,\n",
      "       0.08850966, 0.0904497 , 0.059213  , 0.04474696, 0.08698785,\n",
      "       0.09458787, 0.06366193, 0.08159842, 0.09380693, 0.05288195,\n",
      "       0.07983865, 0.10012548, 0.05184791, 0.06054658, 0.05915496,\n",
      "       0.12866369, 0.04883391, 0.04788718, 0.08914464, 0.06731084,\n",
      "       0.09393396, 0.05391806, 0.08118869, 0.08095045, 0.06095856,\n",
      "       0.05779555, 0.08384213, 0.06690354, 0.06789677, 0.07798166,\n",
      "       0.05449363, 0.07045062, 0.05756665, 0.08759297, 0.08147693,\n",
      "       0.06857913, 0.09310949, 0.08799479, 0.09942607, 0.07429625,\n",
      "       0.07102195, 0.13548465, 0.07282936, 0.06980212, 0.15061079,\n",
      "       0.08574989, 0.06277854, 0.06511342, 0.06662442, 0.09357203,\n",
      "       0.06135725, 0.09233756, 0.09969935, 0.07254884, 0.06905131,\n",
      "       0.09899483, 0.08675445, 0.070282  , 0.07605088, 0.07755396,\n",
      "       0.07698596, 0.06947388, 0.07489186, 0.05991931, 0.06802574,\n",
      "       0.09249569, 0.08001515, 0.0847951 , 0.05914336, 0.08640856,\n",
      "       0.05450867, 0.11646851, 0.06763049, 0.10432364, 0.07175046,\n",
      "       0.06436462, 0.08045943, 0.08073059, 0.08360065, 0.07380911,\n",
      "       0.08184142, 0.07874973, 0.06679779, 0.07271963, 0.08626655,\n",
      "       0.07928634, 0.10211546, 0.07425188, 0.06009214, 0.06574496,\n",
      "       0.06472776, 0.07691009, 0.0647614 , 0.08372691, 0.06692887,\n",
      "       0.06077966, 0.06310963, 0.06670975, 0.08539336, 0.07908511,\n",
      "       0.07884901, 0.07769423, 0.07840679, 0.0639719 , 0.07401294,\n",
      "       0.0703346 , 0.10098107, 0.07946406, 0.08442358, 0.05589705,\n",
      "       0.08905381, 0.11415112, 0.1351072 , 0.07137169, 0.05685387,\n",
      "       0.08381579, 0.07503799, 0.10171875, 0.07316333, 0.09026283,\n",
      "       0.04755218, 0.10791606, 0.07786765, 0.09961523, 0.11799867,\n",
      "       0.0932795 , 0.06502581, 0.06283316, 0.08807345, 0.08078127,\n",
      "       0.06500296, 0.07229081, 0.09610042, 0.06930196, 0.10891477,\n",
      "       0.06301591, 0.05842407, 0.06205203, 0.06856305, 0.06368377,\n",
      "       0.06389662, 0.06441189, 0.08134565, 0.08425127, 0.09572086,\n",
      "       0.08706337, 0.04810235, 0.08970173, 0.0839897 , 0.05834279])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 56, 'min_data_in_leaf': 67, 'max_depth': 1, 'learning_rate': 0.016338538778098613, 'bagging_fraction': 0.19090909090909092} \n",
      "\n",
      "Best index/iterasi :  121\n",
      "Best AUC : 0.7731395750356287 ( std: 0.11646851273937191 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  12 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.61583574, 0.55397472, 0.4805158 , 0.52957731, 0.68279776,\n",
      "       0.47597362, 0.51306781, 0.50416815, 0.57901706, 0.55006793,\n",
      "       0.50689764, 0.47433109, 0.50061014, 0.51697488, 0.58211358,\n",
      "       0.52494056, 0.57695774, 0.63500593, 0.49777868, 0.5661713 ,\n",
      "       0.5815277 , 0.51394251, 0.5022569 , 0.54730398, 0.55409817,\n",
      "       0.58997226, 0.60770697, 0.52608255, 0.50575065, 0.55182178,\n",
      "       0.50355938, 0.50544499, 0.498625  , 0.60505959, 0.57729411,\n",
      "       0.57751684, 0.51052819, 0.56167525, 0.55511178, 0.49639489,\n",
      "       0.50860049, 0.47629633, 0.59729394, 0.56619881, 0.55086209,\n",
      "       0.50301375, 0.51596599, 0.50647143, 0.61305754, 0.59632323,\n",
      "       0.57952252, 0.50685352, 0.50660498, 0.51503893, 0.53354141,\n",
      "       0.58386381, 0.5591162 , 0.49940257, 0.50560912, 0.62875345,\n",
      "       0.53827301, 0.51904125, 0.51137403, 0.59439053, 0.7071246 ,\n",
      "       0.5750553 , 0.59475791, 0.7214441 , 0.52560589, 0.59388247,\n",
      "       0.49093255, 0.52392377, 0.51803259, 0.53921774, 0.59455933,\n",
      "       0.58399523, 0.50204751, 0.58513532, 0.5208045 , 0.49809895,\n",
      "       0.56563767, 0.49858787, 0.61127163, 0.56584494, 0.57849676,\n",
      "       0.57545173, 0.4961808 , 0.56451044, 0.59121921, 0.58882841,\n",
      "       0.5966338 , 0.5830259 , 0.58667059, 0.51991739, 0.55401183,\n",
      "       0.50107847, 0.61307807, 0.59316035, 0.49364609, 0.51352984,\n",
      "       0.48778651, 0.57914193, 0.53317885, 0.57341525, 0.48692802,\n",
      "       0.51146658, 0.68722833, 0.50749334, 0.61912072, 0.56232308,\n",
      "       0.53070878, 0.48318789, 0.59660404, 0.59237411, 0.50561452,\n",
      "       0.54983651, 0.52137177, 0.52811571, 0.59518849, 0.62359888,\n",
      "       0.51787023, 0.51049368, 0.49300884, 0.49986494, 0.50411531,\n",
      "       0.59864152, 0.51025221, 0.60295998, 0.51418793, 0.5877542 ,\n",
      "       0.62251829, 0.54855389, 0.56941426, 0.54207534, 0.56034332,\n",
      "       0.62291354, 0.50239506, 0.50268072, 0.58283021, 0.52734805,\n",
      "       0.60549169, 0.59032081, 0.5678075 , 0.59233032, 0.50805683,\n",
      "       0.50483851, 0.50549827, 0.54876452, 0.55243988, 0.59666843,\n",
      "       0.53982653, 0.54585449, 0.46571902, 0.49116755, 0.48930119,\n",
      "       0.57659557, 0.56670955, 0.53441505, 0.58164939, 0.55085685,\n",
      "       0.51465098, 0.58642811, 0.49156042, 0.49954061, 0.52524692,\n",
      "       0.65979937, 0.58294361, 0.77856448, 0.53676092, 0.50681363,\n",
      "       0.5029364 , 0.54524321, 0.59275627, 0.54351124, 0.50958541,\n",
      "       0.51196294, 0.58256611, 0.50905909, 0.46862071, 0.48083453,\n",
      "       0.51179706, 0.49406516, 0.49675912, 0.68279073, 0.62000098,\n",
      "       0.49703169, 0.55176686, 0.56668512, 0.57405901, 0.48955125,\n",
      "       0.51503441, 0.56358171, 0.56975554, 0.50135137, 0.50131419,\n",
      "       0.48304112, 0.58677601, 0.6335899 , 0.54056173, 0.59018109])] \n",
      "\n",
      "mean AUC :  0.5491380759574918\n",
      "All std:  [array([0.08015508, 0.07444985, 0.07883304, 0.06717037, 0.1642139 ,\n",
      "       0.07968641, 0.06928202, 0.07948321, 0.07722895, 0.04994431,\n",
      "       0.08578972, 0.08872706, 0.06790444, 0.05756675, 0.07132926,\n",
      "       0.10229498, 0.05782367, 0.0437744 , 0.07263761, 0.0678161 ,\n",
      "       0.09044549, 0.06984488, 0.0634401 , 0.06972025, 0.06383744,\n",
      "       0.0829782 , 0.09958269, 0.06348598, 0.09396258, 0.04886507,\n",
      "       0.03885617, 0.09332704, 0.04973599, 0.10044018, 0.08267156,\n",
      "       0.09979026, 0.06953196, 0.04874584, 0.06896731, 0.09697658,\n",
      "       0.06830543, 0.08032441, 0.08907909, 0.0708607 , 0.07452809,\n",
      "       0.06969474, 0.07682944, 0.07868108, 0.09459449, 0.0706138 ,\n",
      "       0.06438622, 0.06696952, 0.06569976, 0.08876718, 0.06265603,\n",
      "       0.0608457 , 0.07379524, 0.09788556, 0.07560837, 0.10485231,\n",
      "       0.0669342 , 0.06454927, 0.06909491, 0.09711213, 0.14890102,\n",
      "       0.09244319, 0.06965951, 0.14877583, 0.11187527, 0.07939608,\n",
      "       0.08320899, 0.06885156, 0.09588654, 0.04855489, 0.10322396,\n",
      "       0.06638579, 0.0797471 , 0.06518461, 0.06649886, 0.05392698,\n",
      "       0.06226495, 0.08969081, 0.10231219, 0.06573531, 0.07374549,\n",
      "       0.0890084 , 0.09024757, 0.05735301, 0.10119912, 0.062177  ,\n",
      "       0.08421353, 0.06284413, 0.07307031, 0.05920614, 0.06460336,\n",
      "       0.09954048, 0.10878089, 0.07225902, 0.1099059 , 0.07377786,\n",
      "       0.06365929, 0.0580395 , 0.05358916, 0.05307324, 0.07985409,\n",
      "       0.06359072, 0.16391387, 0.09154381, 0.08933804, 0.06758731,\n",
      "       0.0650318 , 0.06832216, 0.10261675, 0.09016993, 0.06542669,\n",
      "       0.05357893, 0.08983511, 0.11079682, 0.08905946, 0.0734046 ,\n",
      "       0.0689614 , 0.0677074 , 0.07792512, 0.0656702 , 0.07580559,\n",
      "       0.09032724, 0.09227129, 0.10234204, 0.07649106, 0.0768064 ,\n",
      "       0.10634163, 0.09054935, 0.07197662, 0.06768563, 0.07139699,\n",
      "       0.11606157, 0.07512356, 0.103731  , 0.06785333, 0.08277521,\n",
      "       0.06689729, 0.06894338, 0.08943751, 0.06997676, 0.10051589,\n",
      "       0.08426494, 0.06253897, 0.07861252, 0.08342696, 0.09159137,\n",
      "       0.06072973, 0.07234416, 0.08853007, 0.07830076, 0.07096113,\n",
      "       0.08878568, 0.07242871, 0.06392324, 0.06108674, 0.04633942,\n",
      "       0.04948368, 0.07183254, 0.07907657, 0.03317302, 0.07643659,\n",
      "       0.12576107, 0.07321814, 0.11672637, 0.05290056, 0.09726812,\n",
      "       0.05639498, 0.07644935, 0.07747022, 0.0587299 , 0.04807848,\n",
      "       0.09015994, 0.09075516, 0.07891988, 0.07606644, 0.07553757,\n",
      "       0.07688167, 0.07029906, 0.09200072, 0.16532242, 0.10227338,\n",
      "       0.05898204, 0.05972467, 0.0705875 , 0.07704674, 0.08080895,\n",
      "       0.06151592, 0.06522144, 0.07706521, 0.08044437, 0.06892837,\n",
      "       0.0684492 , 0.08351096, 0.12911221, 0.06750578, 0.0914345 ])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 31, 'min_data_in_leaf': 12, 'max_depth': 1, 'learning_rate': 0.012650337203959031, 'bagging_fraction': 0.9272727272727272} \n",
      "\n",
      "Best index/iterasi :  167\n",
      "Best AUC : 0.778564480648165 ( std: 0.11672636678825624 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  22 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.59733844, 0.51310656, 0.54816632, 0.62757533, 0.50600204,\n",
      "       0.49770016, 0.59680748, 0.58312666, 0.48768166, 0.54646525,\n",
      "       0.51845527, 0.56937413, 0.51208146, 0.4962601 , 0.75857744,\n",
      "       0.54414663, 0.57185168, 0.57879337, 0.55634344, 0.51697235,\n",
      "       0.50567972, 0.5967858 , 0.60067608, 0.49358728, 0.54932128,\n",
      "       0.48462539, 0.59457739, 0.58930577, 0.56417529, 0.51995666,\n",
      "       0.57996579, 0.58493518, 0.55917792, 0.58063404, 0.49655693,\n",
      "       0.48410164, 0.58361137, 0.62094025, 0.5932623 , 0.48501428,\n",
      "       0.50637674, 0.54405639, 0.57410672, 0.51208829, 0.48585149,\n",
      "       0.62379837, 0.51660615, 0.54879221, 0.58900412, 0.57682332,\n",
      "       0.49929406, 0.55540285, 0.5717615 , 0.56080826, 0.50489082,\n",
      "       0.61187802, 0.53994276, 0.47723654, 0.7762634 , 0.47734497,\n",
      "       0.59113022, 0.56977697, 0.52582627, 0.62273307, 0.54368629,\n",
      "       0.57608216, 0.55010269, 0.50007677, 0.47254262, 0.52128206,\n",
      "       0.51406218, 0.63247431, 0.50776794, 0.46568367, 0.5132748 ,\n",
      "       0.52048243, 0.50226531, 0.68387192, 0.54421121, 0.49361322,\n",
      "       0.50647169, 0.52032106, 0.55704098, 0.58266083, 0.6055224 ,\n",
      "       0.58528383, 0.56425466, 0.48723882, 0.5018333 , 0.59355755,\n",
      "       0.62825062, 0.54068612, 0.58175358, 0.60879824, 0.52203943,\n",
      "       0.59504607, 0.508455  , 0.54741831, 0.61050781, 0.53749199,\n",
      "       0.56563489, 0.566086  , 0.56626019, 0.50290294, 0.52990396,\n",
      "       0.53220682, 0.56709769, 0.4866989 , 0.5329036 , 0.62865324,\n",
      "       0.52274502, 0.53398016, 0.59959421, 0.59802374, 0.50272302,\n",
      "       0.51387852, 0.60114244, 0.53420353, 0.53547342, 0.50097204,\n",
      "       0.54967364, 0.52150788, 0.54172499, 0.61476873, 0.54471201,\n",
      "       0.50875685, 0.53285886, 0.57502297, 0.4943817 , 0.50248385,\n",
      "       0.55791284, 0.58129539, 0.57229605, 0.62410577, 0.57278103,\n",
      "       0.50042811, 0.4779578 , 0.51380379, 0.52378974, 0.58297999,\n",
      "       0.49049996, 0.49899373, 0.60583648, 0.51400496, 0.52696121,\n",
      "       0.52793205, 0.55145308, 0.54423713, 0.56852354, 0.54319353,\n",
      "       0.50683591, 0.53244428, 0.59085934, 0.51336548, 0.51715895,\n",
      "       0.56603802, 0.58781169, 0.53234074, 0.50659387, 0.52848477,\n",
      "       0.56506242, 0.4645206 , 0.58483538, 0.51998008, 0.58184216,\n",
      "       0.5216278 , 0.59286729, 0.56802921, 0.51049018, 0.52474222,\n",
      "       0.55384639, 0.49667577, 0.59416084, 0.56751538, 0.58414843,\n",
      "       0.61045798, 0.5288042 , 0.4999024 , 0.56824958, 0.52849916,\n",
      "       0.55126376, 0.55382711, 0.57747256, 0.47169957, 0.52012604,\n",
      "       0.53440262, 0.57904053, 0.5223053 , 0.58010773, 0.49911942,\n",
      "       0.46799817, 0.59292755, 0.50658349, 0.50236264, 0.50959537,\n",
      "       0.51470206, 0.54557149, 0.49504426, 0.59349634, 0.56667171])] \n",
      "\n",
      "mean AUC :  0.5475004584874487\n",
      "All std:  [array([0.09064581, 0.08264723, 0.07948303, 0.11773422, 0.0707397 ,\n",
      "       0.08962454, 0.11022799, 0.05823713, 0.0860385 , 0.05995917,\n",
      "       0.06480228, 0.0509935 , 0.06845459, 0.06941493, 0.13101673,\n",
      "       0.07535767, 0.05701589, 0.08925106, 0.07277861, 0.05090946,\n",
      "       0.07358149, 0.08941153, 0.10212274, 0.08858054, 0.0673682 ,\n",
      "       0.08130013, 0.0673368 , 0.069615  , 0.05035233, 0.06902117,\n",
      "       0.08865777, 0.07344   , 0.05873873, 0.06854975, 0.11079862,\n",
      "       0.09713478, 0.07350345, 0.10027465, 0.08977938, 0.06507317,\n",
      "       0.06458017, 0.09130694, 0.05646128, 0.06805355, 0.09508961,\n",
      "       0.10082592, 0.05941604, 0.05826385, 0.07139633, 0.05795797,\n",
      "       0.09095629, 0.07799587, 0.09500236, 0.0698756 , 0.06534629,\n",
      "       0.10013221, 0.06971035, 0.070975  , 0.13336304, 0.09502994,\n",
      "       0.07319962, 0.05247624, 0.07662185, 0.10805697, 0.06756145,\n",
      "       0.07695898, 0.04945131, 0.0695139 , 0.06674921, 0.06487922,\n",
      "       0.07691119, 0.13511282, 0.06518406, 0.08942906, 0.06843685,\n",
      "       0.11150183, 0.0641897 , 0.11851856, 0.06865347, 0.08460887,\n",
      "       0.10665952, 0.04755511, 0.07789161, 0.06582547, 0.0912292 ,\n",
      "       0.06523587, 0.05720902, 0.08545677, 0.10371729, 0.07844834,\n",
      "       0.09395148, 0.05469029, 0.06379483, 0.10002185, 0.10552431,\n",
      "       0.09031329, 0.06091776, 0.0483406 , 0.09958202, 0.06433362,\n",
      "       0.09946928, 0.04643857, 0.06862526, 0.05089883, 0.08180723,\n",
      "       0.07717679, 0.05102998, 0.09448782, 0.06941713, 0.10250767,\n",
      "       0.06911794, 0.06448794, 0.0893494 , 0.09828051, 0.07697644,\n",
      "       0.06516039, 0.06974052, 0.08492308, 0.11929835, 0.06803137,\n",
      "       0.07160756, 0.0503841 , 0.05291531, 0.09915525, 0.08051783,\n",
      "       0.0928282 , 0.08823251, 0.05791696, 0.08687083, 0.08430124,\n",
      "       0.06319101, 0.09770277, 0.05759289, 0.03691454, 0.05395738,\n",
      "       0.07087656, 0.06493123, 0.07931371, 0.06397463, 0.06587717,\n",
      "       0.09579389, 0.0825047 , 0.07631942, 0.06813133, 0.06183439,\n",
      "       0.05918788, 0.06125198, 0.05769374, 0.07990406, 0.1068343 ,\n",
      "       0.0349026 , 0.06932641, 0.11053384, 0.06182699, 0.06093693,\n",
      "       0.06998966, 0.06433837, 0.05708307, 0.06141839, 0.07066615,\n",
      "       0.06977581, 0.07108024, 0.09111459, 0.06474398, 0.06234328,\n",
      "       0.05704968, 0.08905863, 0.04938811, 0.09149852, 0.05851107,\n",
      "       0.07471198, 0.07432933, 0.07367758, 0.10707279, 0.07013618,\n",
      "       0.09443917, 0.04483124, 0.05866696, 0.05059269, 0.07867343,\n",
      "       0.07835732, 0.09360768, 0.09574804, 0.08748435, 0.06560731,\n",
      "       0.06043192, 0.08387984, 0.06289765, 0.05573953, 0.0779676 ,\n",
      "       0.0771822 , 0.10432236, 0.08391443, 0.07244948, 0.08661599,\n",
      "       0.09010619, 0.06565115, 0.07701322, 0.09455822, 0.05084158])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 96, 'min_data_in_leaf': 1, 'max_depth': 2, 'learning_rate': 0.007742636826811269, 'bagging_fraction': 0.14545454545454545} \n",
      "\n",
      "Best index/iterasi :  58\n",
      "Best AUC : 0.7762633985164809 ( std: 0.1333630381644924 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  32 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.50795555, 0.56097608, 0.53584572, 0.53170747, 0.50151599,\n",
      "       0.49510132, 0.48323191, 0.5387927 , 0.62966204, 0.57475181,\n",
      "       0.54566598, 0.53534497, 0.48253659, 0.50638011, 0.5227714 ,\n",
      "       0.53485958, 0.46205973, 0.54641985, 0.65657542, 0.61634101,\n",
      "       0.52656664, 0.57942785, 0.61628894, 0.5049718 , 0.49741218,\n",
      "       0.46914094, 0.58903742, 0.52192264, 0.57096049, 0.55394813,\n",
      "       0.50005569, 0.50398846, 0.57788822, 0.58192455, 0.57466857,\n",
      "       0.51657641, 0.58221429, 0.54574626, 0.55809678, 0.57749155,\n",
      "       0.5738071 , 0.49382271, 0.5052673 , 0.54685073, 0.62218808,\n",
      "       0.57617488, 0.56813013, 0.50718292, 0.49788299, 0.56304525,\n",
      "       0.54744264, 0.50000431, 0.53353583, 0.52312593, 0.49713251,\n",
      "       0.51088561, 0.59496037, 0.50878227, 0.50152427, 0.57143766,\n",
      "       0.51069651, 0.51008464, 0.57903862, 0.50974238, 0.58416416,\n",
      "       0.54641707, 0.5449151 , 0.5013156 , 0.53345532, 0.60774158,\n",
      "       0.52365336, 0.60629217, 0.55088655, 0.49369891, 0.49029531,\n",
      "       0.6135475 , 0.51424475, 0.5530293 , 0.5452429 , 0.49942766,\n",
      "       0.50256548, 0.52948547, 0.47266507, 0.56209634, 0.51083722,\n",
      "       0.53519696, 0.62102931, 0.57324142, 0.59743553, 0.52366784,\n",
      "       0.54188458, 0.50086075, 0.54583916, 0.58997137, 0.48042515,\n",
      "       0.56705499, 0.50102457, 0.73305877, 0.50358055, 0.49720938,\n",
      "       0.53122792, 0.46756886, 0.51230311, 0.61333117, 0.48854934,\n",
      "       0.488902  , 0.58787769, 0.54760334, 0.78190814, 0.49824002,\n",
      "       0.5828377 , 0.48978157, 0.50027647, 0.56843778, 0.57647369,\n",
      "       0.51756877, 0.51260759, 0.50960371, 0.56331702, 0.48233838,\n",
      "       0.58313503, 0.52968748, 0.57409147, 0.58060957, 0.53054485,\n",
      "       0.57089884, 0.53127066, 0.56736105, 0.5064969 , 0.51764455,\n",
      "       0.53722704, 0.77357873, 0.4944329 , 0.55698232, 0.58210761,\n",
      "       0.54667411, 0.59921168, 0.50967374, 0.52850434, 0.54487203,\n",
      "       0.56376917, 0.501803  , 0.58173422, 0.49409132, 0.57252876,\n",
      "       0.50272384, 0.60515101, 0.52085984, 0.52552275, 0.58119071,\n",
      "       0.60943412, 0.53051669, 0.51784472, 0.52502909, 0.58965782,\n",
      "       0.54974471, 0.59460627, 0.55021455, 0.46418361, 0.56482255,\n",
      "       0.50469653, 0.57651496, 0.55654805, 0.5392139 , 0.77652412,\n",
      "       0.49076546, 0.61468119, 0.49138165, 0.5728861 , 0.51258239,\n",
      "       0.74418824, 0.51622838, 0.62239602, 0.60892781, 0.54043358,\n",
      "       0.49855078, 0.57455103, 0.5603463 , 0.57740512, 0.53881684,\n",
      "       0.48283286, 0.57142354, 0.5079782 , 0.52917022, 0.56703815,\n",
      "       0.57047408, 0.59463766, 0.55052886, 0.62758673, 0.57038777,\n",
      "       0.57227849, 0.48692857, 0.5472143 , 0.60418833, 0.57325067,\n",
      "       0.61340292, 0.58844054, 0.49543679, 0.48666115, 0.5140671 ])] \n",
      "\n",
      "mean AUC :  0.5478488956417493\n",
      "All std:  [array([0.07018849, 0.06945262, 0.06410081, 0.0589622 , 0.06005368,\n",
      "       0.09057268, 0.0851972 , 0.06305391, 0.12500188, 0.05672243,\n",
      "       0.06539027, 0.0632973 , 0.08346059, 0.07291616, 0.06535382,\n",
      "       0.06054465, 0.0823471 , 0.04594257, 0.12427486, 0.098908  ,\n",
      "       0.08063262, 0.0628777 , 0.09805629, 0.07592012, 0.07219627,\n",
      "       0.09022309, 0.08627165, 0.0603172 , 0.07041129, 0.07141592,\n",
      "       0.0751525 , 0.08090751, 0.06190947, 0.05820784, 0.05836237,\n",
      "       0.07523248, 0.09467105, 0.0853264 , 0.06475409, 0.09865279,\n",
      "       0.06151855, 0.09979705, 0.07507932, 0.07016267, 0.10396521,\n",
      "       0.09136976, 0.0511374 , 0.07774359, 0.09409385, 0.04884659,\n",
      "       0.06894973, 0.07982374, 0.0698188 , 0.07145954, 0.08661974,\n",
      "       0.08986685, 0.07215879, 0.08931785, 0.10735651, 0.06363587,\n",
      "       0.06433881, 0.06653585, 0.06246416, 0.08904023, 0.07128387,\n",
      "       0.05142605, 0.07033498, 0.07068275, 0.08403684, 0.08817135,\n",
      "       0.04942185, 0.07934797, 0.07732265, 0.09139891, 0.07467074,\n",
      "       0.10335736, 0.06992364, 0.05290967, 0.0719819 , 0.05882622,\n",
      "       0.07685671, 0.06149069, 0.07902608, 0.07799654, 0.06580555,\n",
      "       0.06620829, 0.06551757, 0.08760863, 0.09017224, 0.06440701,\n",
      "       0.07837463, 0.0822744 , 0.07689964, 0.05724224, 0.08095064,\n",
      "       0.05136572, 0.07175174, 0.14381575, 0.08903967, 0.07206732,\n",
      "       0.0739712 , 0.07958932, 0.10674002, 0.07948727, 0.08566706,\n",
      "       0.08021122, 0.09171736, 0.09117433, 0.11629331, 0.07756465,\n",
      "       0.07038473, 0.08938077, 0.07690739, 0.05066144, 0.06916787,\n",
      "       0.07373562, 0.06820326, 0.06830047, 0.06000885, 0.0951157 ,\n",
      "       0.0715621 , 0.05368876, 0.06802512, 0.09461255, 0.05646728,\n",
      "       0.08877183, 0.06553553, 0.11913125, 0.09541564, 0.06458654,\n",
      "       0.06391399, 0.11604226, 0.07946877, 0.06468924, 0.08180483,\n",
      "       0.06659867, 0.08358625, 0.07521128, 0.06606019, 0.05505644,\n",
      "       0.0623784 , 0.09950178, 0.05254152, 0.07938092, 0.05958116,\n",
      "       0.08098231, 0.07791602, 0.09339962, 0.07205715, 0.08857944,\n",
      "       0.09172402, 0.06562482, 0.07530359, 0.06508266, 0.06532105,\n",
      "       0.08288458, 0.08284821, 0.0497132 , 0.08291925, 0.08982502,\n",
      "       0.06777688, 0.07207751, 0.05147398, 0.05831203, 0.13283267,\n",
      "       0.08353869, 0.1164838 , 0.07334462, 0.05938827, 0.08552379,\n",
      "       0.129927  , 0.0655067 , 0.10361206, 0.09413909, 0.06445557,\n",
      "       0.07369148, 0.07090476, 0.06550061, 0.08941165, 0.06618017,\n",
      "       0.07303188, 0.04935371, 0.08439495, 0.06876588, 0.05100988,\n",
      "       0.06229606, 0.10823607, 0.06624757, 0.12553349, 0.05491213,\n",
      "       0.09312062, 0.0952165 , 0.05653606, 0.10081107, 0.07960344,\n",
      "       0.10965397, 0.08096168, 0.08721384, 0.07619128, 0.08413796])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 82, 'min_data_in_leaf': 77, 'max_depth': 1, 'learning_rate': 0.008648423275731726, 'bagging_fraction': 0.2090909090909091} \n",
      "\n",
      "Best index/iterasi :  108\n",
      "Best AUC : 0.7819081367961191 ( std: 0.11629331112089154 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  42 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.59201316, 0.48959546, 0.49944097, 0.52909303, 0.55066607,\n",
      "       0.51527238, 0.5596265 , 0.58776583, 0.69094964, 0.51258478,\n",
      "       0.54781727, 0.51070681, 0.52534991, 0.68326533, 0.59668928,\n",
      "       0.50362736, 0.48517474, 0.56663325, 0.5123816 , 0.5385737 ,\n",
      "       0.56841559, 0.58580674, 0.54076702, 0.51170872, 0.57718607,\n",
      "       0.47879492, 0.55451644, 0.48816809, 0.57644653, 0.58250047,\n",
      "       0.49145675, 0.55375938, 0.53094454, 0.50558948, 0.50629562,\n",
      "       0.50986049, 0.60976249, 0.56778367, 0.51173503, 0.49758928,\n",
      "       0.53722833, 0.52242034, 0.60040736, 0.54808031, 0.46926387,\n",
      "       0.52910569, 0.59501631, 0.50271598, 0.61071651, 0.53269762,\n",
      "       0.58242209, 0.63017287, 0.48256577, 0.58670303, 0.49381304,\n",
      "       0.52726413, 0.51258684, 0.62579119, 0.51122756, 0.5751698 ,\n",
      "       0.58460412, 0.50734606, 0.6342028 , 0.57406513, 0.50387723,\n",
      "       0.55584971, 0.6784967 , 0.55007583, 0.59249304, 0.55272562,\n",
      "       0.51470728, 0.5918371 , 0.50061172, 0.49965387, 0.58900523,\n",
      "       0.56589416, 0.57911781, 0.54492226, 0.4976831 , 0.59645182,\n",
      "       0.49791679, 0.70991373, 0.50581045, 0.51247055, 0.58147896,\n",
      "       0.56988762, 0.56362414, 0.59414689, 0.52413188, 0.60823099,\n",
      "       0.58847109, 0.54931126, 0.59559323, 0.46152142, 0.49769279,\n",
      "       0.47002437, 0.47716045, 0.50658548, 0.60727145, 0.56213763,\n",
      "       0.57298104, 0.46760789, 0.55984455, 0.51683608, 0.56960537,\n",
      "       0.52638694, 0.60921392, 0.54645844, 0.58312482, 0.61235167,\n",
      "       0.53710262, 0.51477281, 0.57953987, 0.50956124, 0.60336528,\n",
      "       0.53046493, 0.48989815, 0.50555918, 0.56549273, 0.59026221,\n",
      "       0.5850094 , 0.70873451, 0.5661176 , 0.51308895, 0.5176389 ,\n",
      "       0.56125836, 0.57639578, 0.54455498, 0.56924329, 0.57434932,\n",
      "       0.60158139, 0.5892706 , 0.47488028, 0.50555243, 0.52831794,\n",
      "       0.49173567, 0.52193333, 0.52284497, 0.53229108, 0.58575102,\n",
      "       0.59182434, 0.51794431, 0.54138274, 0.51293292, 0.53715633,\n",
      "       0.57488101, 0.54760669, 0.49482079, 0.52262904, 0.61773654,\n",
      "       0.49762271, 0.57946349, 0.53278706, 0.58236364, 0.57029125,\n",
      "       0.51065419, 0.71196381, 0.59824958, 0.48542421, 0.59313249,\n",
      "       0.52011087, 0.54152495, 0.50800048, 0.50432012, 0.58887701,\n",
      "       0.59045908, 0.61099964, 0.58307707, 0.55859411, 0.56930064,\n",
      "       0.56637483, 0.55370247, 0.62714631, 0.51252056, 0.50980693,\n",
      "       0.50987327, 0.53287803, 0.51557484, 0.68406935, 0.51873287,\n",
      "       0.53657441, 0.60758943, 0.58721837, 0.46090868, 0.46799566,\n",
      "       0.58253124, 0.51613731, 0.50536838, 0.53429566, 0.56738448,\n",
      "       0.59061538, 0.52600122, 0.51449889, 0.5633423 , 0.57912729,\n",
      "       0.57155878, 0.50473866, 0.49043327, 0.50981761, 0.58722982])] \n",
      "\n",
      "mean AUC :  0.5500492083222565\n",
      "All std:  [array([0.09813223, 0.09655403, 0.03553226, 0.08026172, 0.06510244,\n",
      "       0.08290848, 0.07879811, 0.08309853, 0.14578373, 0.07276443,\n",
      "       0.07056692, 0.09595999, 0.07070271, 0.12068716, 0.13968502,\n",
      "       0.06563051, 0.07668009, 0.10794308, 0.07723845, 0.06343515,\n",
      "       0.07632277, 0.07185399, 0.06766739, 0.07088558, 0.08885144,\n",
      "       0.11568012, 0.05903974, 0.07283077, 0.05921754, 0.0912588 ,\n",
      "       0.08504053, 0.08814192, 0.072262  , 0.07074443, 0.08464501,\n",
      "       0.07326457, 0.11303082, 0.08216007, 0.07249157, 0.10087233,\n",
      "       0.04848517, 0.08069249, 0.09886994, 0.06149198, 0.09264762,\n",
      "       0.06410046, 0.06855011, 0.07997543, 0.08678527, 0.05361142,\n",
      "       0.06635734, 0.12202512, 0.0988898 , 0.08400086, 0.09301518,\n",
      "       0.08171076, 0.03999154, 0.0953042 , 0.05539395, 0.07626982,\n",
      "       0.11825448, 0.06851767, 0.11915713, 0.05581735, 0.08228663,\n",
      "       0.06706638, 0.12640458, 0.05727525, 0.069233  , 0.06127878,\n",
      "       0.06783971, 0.06962632, 0.06409312, 0.07774799, 0.06834955,\n",
      "       0.067981  , 0.05763492, 0.07208921, 0.07697571, 0.08363082,\n",
      "       0.06843138, 0.1483377 , 0.07983033, 0.06702376, 0.08004446,\n",
      "       0.0545346 , 0.07157964, 0.07651716, 0.06242311, 0.10083755,\n",
      "       0.07510417, 0.06587509, 0.08872003, 0.10226497, 0.06839113,\n",
      "       0.07516919, 0.0751328 , 0.10466115, 0.08390854, 0.08405796,\n",
      "       0.056073  , 0.09343169, 0.08473463, 0.07490937, 0.07404301,\n",
      "       0.06404574, 0.11560674, 0.0703125 , 0.05883319, 0.08718767,\n",
      "       0.0622419 , 0.07598503, 0.05788972, 0.09908255, 0.10801208,\n",
      "       0.06064906, 0.07279691, 0.08340224, 0.08091723, 0.07153427,\n",
      "       0.07652857, 0.13924014, 0.07311481, 0.09113477, 0.0764517 ,\n",
      "       0.05885656, 0.07106036, 0.0600899 , 0.05142002, 0.06742329,\n",
      "       0.09764898, 0.10036371, 0.08470564, 0.07168484, 0.07138454,\n",
      "       0.07502509, 0.07596697, 0.09551603, 0.06448263, 0.06775671,\n",
      "       0.09325196, 0.06354558, 0.0615512 , 0.0632882 , 0.06322121,\n",
      "       0.0872018 , 0.06736358, 0.05270311, 0.06958966, 0.10425309,\n",
      "       0.06976084, 0.06188892, 0.0774148 , 0.1149078 , 0.05466723,\n",
      "       0.08589693, 0.13636291, 0.07384814, 0.07676487, 0.08306676,\n",
      "       0.0663618 , 0.06509097, 0.07275179, 0.11095269, 0.07021535,\n",
      "       0.07912676, 0.08352891, 0.09230852, 0.04957036, 0.05177984,\n",
      "       0.08591308, 0.09284413, 0.11845807, 0.06080515, 0.05942257,\n",
      "       0.06761526, 0.06319587, 0.07534112, 0.11957455, 0.06057467,\n",
      "       0.04658672, 0.08863125, 0.09987132, 0.08671709, 0.08038545,\n",
      "       0.1308948 , 0.08083484, 0.06746974, 0.06847486, 0.07557476,\n",
      "       0.07966081, 0.05995928, 0.07317124, 0.0488694 , 0.05861808,\n",
      "       0.05698042, 0.04824051, 0.09262361, 0.09340645, 0.09742364])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 54, 'min_data_in_leaf': 49, 'max_depth': 3, 'learning_rate': 0.01309535020482667, 'bagging_fraction': 0.15454545454545454} \n",
      "\n",
      "Best index/iterasi :  156\n",
      "Best AUC : 0.7119638075085053 ( std: 0.1363629135101108 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  52 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.50240785, 0.5310961 , 0.53878506, 0.54188269, 0.57938798,\n",
      "       0.47409636, 0.56670548, 0.578807  , 0.51808408, 0.50104216,\n",
      "       0.50858784, 0.57033035, 0.55693609, 0.49393633, 0.5220047 ,\n",
      "       0.58274683, 0.49973783, 0.58914923, 0.50377506, 0.5172099 ,\n",
      "       0.48714603, 0.58328005, 0.49986153, 0.46417434, 0.55591422,\n",
      "       0.48148462, 0.4982166 , 0.53959128, 0.57120131, 0.54557834,\n",
      "       0.48655582, 0.56116041, 0.58439661, 0.57051378, 0.49512566,\n",
      "       0.50715986, 0.59166277, 0.52368532, 0.54410002, 0.56396787,\n",
      "       0.53362847, 0.50485176, 0.53168463, 0.77005076, 0.50948463,\n",
      "       0.62836387, 0.58427509, 0.49865935, 0.60596343, 0.52200679,\n",
      "       0.52335493, 0.45222413, 0.50726016, 0.50716487, 0.56258768,\n",
      "       0.50271735, 0.57561823, 0.49443557, 0.60958107, 0.56487021,\n",
      "       0.48342092, 0.53852999, 0.52309679, 0.57139604, 0.58807564,\n",
      "       0.48365231, 0.51715826, 0.56699163, 0.62561926, 0.4739543 ,\n",
      "       0.48945873, 0.5301081 , 0.6104717 , 0.60077399, 0.57191047,\n",
      "       0.64562867, 0.57336828, 0.56596276, 0.61258259, 0.53541593,\n",
      "       0.59845275, 0.51892351, 0.48097893, 0.49666579, 0.52427083,\n",
      "       0.59183845, 0.7100463 , 0.51043729, 0.5198354 , 0.61559929,\n",
      "       0.55828472, 0.5341458 , 0.49651692, 0.51342136, 0.62082332,\n",
      "       0.55272913, 0.59085927, 0.51026766, 0.51169113, 0.60573234,\n",
      "       0.53263769, 0.62471571, 0.61236072, 0.51587466, 0.56696202,\n",
      "       0.49963623, 0.54026299, 0.58347218, 0.50398865, 0.57415787,\n",
      "       0.57248468, 0.61241805, 0.58611411, 0.55996254, 0.48260646,\n",
      "       0.5422759 , 0.55878589, 0.60036566, 0.61399095, 0.58133935,\n",
      "       0.50741923, 0.55909557, 0.6096862 , 0.59611343, 0.5048058 ,\n",
      "       0.54284203, 0.49840522, 0.6675274 , 0.58218009, 0.52591774,\n",
      "       0.49385748, 0.53576919, 0.50083354, 0.56546209, 0.71647469,\n",
      "       0.50630076, 0.50884024, 0.57278743, 0.50414199, 0.5821614 ,\n",
      "       0.56781067, 0.52147091, 0.57760879, 0.53337417, 0.5845328 ,\n",
      "       0.52661872, 0.70923867, 0.49677401, 0.58119194, 0.51738211,\n",
      "       0.58578995, 0.52061683, 0.59869176, 0.60822854, 0.47593947,\n",
      "       0.59356051, 0.53068288, 0.49815447, 0.68427903, 0.50420164,\n",
      "       0.53888261, 0.58730162, 0.60232203, 0.56843249, 0.6162764 ,\n",
      "       0.48176485, 0.60329226, 0.53453994, 0.49441475, 0.54562904,\n",
      "       0.50534504, 0.52918815, 0.50912101, 0.51579758, 0.50576443,\n",
      "       0.50088468, 0.6017975 , 0.58097553, 0.71320929, 0.50718413,\n",
      "       0.50531278, 0.57891644, 0.49046663, 0.48810454, 0.51932952,\n",
      "       0.5251809 , 0.60681706, 0.61290918, 0.52583026, 0.58280685,\n",
      "       0.62387079, 0.50301595, 0.54535943, 0.53141253, 0.56979121,\n",
      "       0.51277201, 0.55912999, 0.46866373, 0.58527103, 0.49158864])] \n",
      "\n",
      "mean AUC :  0.5495960970704025\n",
      "All std:  [array([0.06993069, 0.09051678, 0.06538057, 0.06194905, 0.0888839 ,\n",
      "       0.09676974, 0.07220542, 0.06056209, 0.06908252, 0.07971693,\n",
      "       0.06717081, 0.07434633, 0.09300759, 0.06947897, 0.07822585,\n",
      "       0.07101933, 0.08949924, 0.11067508, 0.06159649, 0.06182698,\n",
      "       0.09389982, 0.06885282, 0.07972465, 0.07061071, 0.04898669,\n",
      "       0.08821475, 0.07619678, 0.05430025, 0.05575838, 0.05342589,\n",
      "       0.09250416, 0.07404588, 0.08836468, 0.09529416, 0.07653338,\n",
      "       0.09260618, 0.07458435, 0.06528974, 0.05878909, 0.05099642,\n",
      "       0.06233252, 0.08687817, 0.07979654, 0.11678377, 0.05120247,\n",
      "       0.09894994, 0.11987122, 0.07878904, 0.09892543, 0.0751633 ,\n",
      "       0.09268255, 0.08869243, 0.08133528, 0.08741857, 0.07532163,\n",
      "       0.06735775, 0.06064547, 0.07526586, 0.08246972, 0.05168094,\n",
      "       0.09414138, 0.03294009, 0.06461638, 0.07056315, 0.06742166,\n",
      "       0.07847438, 0.10183188, 0.07843368, 0.09855667, 0.10013846,\n",
      "       0.07222105, 0.07181574, 0.05193404, 0.06341055, 0.04887929,\n",
      "       0.11581301, 0.05586553, 0.0764009 , 0.09463513, 0.06691683,\n",
      "       0.08910269, 0.10394174, 0.09674607, 0.09080106, 0.06723859,\n",
      "       0.09282235, 0.14712622, 0.08426506, 0.07887003, 0.09467126,\n",
      "       0.08143342, 0.06796712, 0.07372908, 0.07041115, 0.0997931 ,\n",
      "       0.05196069, 0.06288178, 0.06981646, 0.07313844, 0.09990054,\n",
      "       0.08395631, 0.06775779, 0.08843965, 0.04158734, 0.05080711,\n",
      "       0.06986277, 0.07813019, 0.07120286, 0.08109077, 0.06907319,\n",
      "       0.06875839, 0.08376425, 0.06539295, 0.07512915, 0.10364618,\n",
      "       0.12504538, 0.05673546, 0.10505773, 0.09232456, 0.07390071,\n",
      "       0.07352677, 0.05344141, 0.11140215, 0.08882773, 0.0792954 ,\n",
      "       0.07584834, 0.05095784, 0.12007108, 0.0947764 , 0.07486057,\n",
      "       0.08362005, 0.06539927, 0.06767363, 0.07324161, 0.14204505,\n",
      "       0.06099435, 0.081992  , 0.04815816, 0.06644841, 0.08846006,\n",
      "       0.08989761, 0.06993316, 0.08785973, 0.06735975, 0.08635848,\n",
      "       0.06345817, 0.11871517, 0.07364728, 0.08901167, 0.06306481,\n",
      "       0.08900646, 0.06915938, 0.0824788 , 0.08560779, 0.09852731,\n",
      "       0.0757262 , 0.0584974 , 0.07448264, 0.16208811, 0.05245548,\n",
      "       0.0637386 , 0.08763651, 0.09827713, 0.05045542, 0.0761616 ,\n",
      "       0.04696831, 0.08896412, 0.05917296, 0.07937322, 0.06115889,\n",
      "       0.07207409, 0.0692075 , 0.0631025 , 0.06544655, 0.06206215,\n",
      "       0.08111162, 0.10656398, 0.12240707, 0.1427594 , 0.06768253,\n",
      "       0.05849657, 0.08470604, 0.0814987 , 0.09177456, 0.08774868,\n",
      "       0.06562941, 0.07240918, 0.09525783, 0.10057093, 0.07347598,\n",
      "       0.08856645, 0.07038364, 0.09694514, 0.0645253 , 0.08171209,\n",
      "       0.07315411, 0.0735575 , 0.07926092, 0.09314832, 0.08384681])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 46, 'min_data_in_leaf': 40, 'max_depth': 1, 'learning_rate': 0.017752080117176352, 'bagging_fraction': 0.47272727272727266} \n",
      "\n",
      "Best index/iterasi :  43\n",
      "Best AUC : 0.7700507640218764 ( std: 0.11678377093553091 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  62 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.53908118, 0.55257418, 0.50294679, 0.5418853 , 0.57236711,\n",
      "       0.50980213, 0.56891756, 0.52267552, 0.54724182, 0.49721578,\n",
      "       0.58948927, 0.60988591, 0.62951844, 0.53510707, 0.57422096,\n",
      "       0.56658383, 0.57833082, 0.54270404, 0.63073235, 0.59086511,\n",
      "       0.47756773, 0.53871986, 0.5767511 , 0.50502278, 0.56648598,\n",
      "       0.62605494, 0.53142116, 0.4893703 , 0.59713654, 0.53086965,\n",
      "       0.58007635, 0.57168666, 0.57261847, 0.56829087, 0.52587693,\n",
      "       0.54123228, 0.56994538, 0.52861759, 0.59215516, 0.51223911,\n",
      "       0.47890228, 0.70794895, 0.57142799, 0.55767651, 0.5766993 ,\n",
      "       0.487903  , 0.77210483, 0.51461531, 0.50156569, 0.56635989,\n",
      "       0.6029419 , 0.53114179, 0.53825348, 0.48292888, 0.49856786,\n",
      "       0.50138514, 0.50864209, 0.47488317, 0.56146615, 0.50842822,\n",
      "       0.52427907, 0.50900299, 0.48410024, 0.59541532, 0.50546904,\n",
      "       0.54400109, 0.50442836, 0.57595946, 0.6234713 , 0.5345428 ,\n",
      "       0.51193058, 0.5793463 , 0.5536016 , 0.54731602, 0.51264079,\n",
      "       0.50261351, 0.49073305, 0.5254005 , 0.57308133, 0.52986729,\n",
      "       0.51314641, 0.48486266, 0.48000497, 0.50963885, 0.547905  ,\n",
      "       0.55985359, 0.48991608, 0.57677477, 0.59490875, 0.58305255,\n",
      "       0.59203034, 0.59407208, 0.47987432, 0.56970773, 0.59492087,\n",
      "       0.60044173, 0.5418936 , 0.59570351, 0.65048115, 0.62876563,\n",
      "       0.53939594, 0.47686932, 0.52567088, 0.59044223, 0.53343192,\n",
      "       0.53291184, 0.60140232, 0.50963464, 0.5399024 , 0.50310773,\n",
      "       0.4960273 , 0.50482917, 0.61820231, 0.51514775, 0.51638816,\n",
      "       0.60347793, 0.52467436, 0.5747994 , 0.55463551, 0.62262263,\n",
      "       0.49418603, 0.63137912, 0.52132675, 0.49185737, 0.57263251,\n",
      "       0.61087664, 0.51959251, 0.70708105, 0.50964626, 0.60326914,\n",
      "       0.48805027, 0.5778824 , 0.58837732, 0.5198173 , 0.52523313,\n",
      "       0.59801172, 0.5864249 , 0.50648239, 0.61951577, 0.62086799,\n",
      "       0.49829017, 0.48913396, 0.60818311, 0.54086777, 0.48109419,\n",
      "       0.53698866, 0.57024138, 0.56107784, 0.57622478, 0.50603266,\n",
      "       0.50072882, 0.59568928, 0.57127054, 0.47194533, 0.55075836,\n",
      "       0.55022972, 0.48147891, 0.5198956 , 0.5421263 , 0.52606531,\n",
      "       0.5177334 , 0.58184514, 0.64731993, 0.56792247, 0.66319496,\n",
      "       0.53747561, 0.57273321, 0.53753998, 0.51332317, 0.51888669,\n",
      "       0.54145619, 0.57709427, 0.51416416, 0.51395512, 0.57605382,\n",
      "       0.49498938, 0.57961302, 0.58763571, 0.57336639, 0.50065363,\n",
      "       0.4826339 , 0.49899488, 0.48893016, 0.60844279, 0.59684691,\n",
      "       0.51873299, 0.58357638, 0.51826624, 0.499633  , 0.51470365,\n",
      "       0.4746548 , 0.56605547, 0.50634872, 0.48915089, 0.49531874,\n",
      "       0.56951847, 0.5411005 , 0.5113805 , 0.53614967, 0.55234335])] \n",
      "\n",
      "mean AUC :  0.5479371346002958\n",
      "All std:  [array([0.06314615, 0.07754585, 0.07598005, 0.06510101, 0.06360671,\n",
      "       0.08354458, 0.0546655 , 0.04103899, 0.04494277, 0.12186891,\n",
      "       0.09395182, 0.06438935, 0.10872366, 0.05993585, 0.05499814,\n",
      "       0.08213421, 0.08754121, 0.06023139, 0.11749635, 0.06725398,\n",
      "       0.07130735, 0.06219575, 0.09578709, 0.06952026, 0.07337369,\n",
      "       0.12741848, 0.06269793, 0.07891079, 0.08718794, 0.08127724,\n",
      "       0.09327002, 0.09457629, 0.06553925, 0.052793  , 0.06536642,\n",
      "       0.0546148 , 0.05100553, 0.10772441, 0.08055356, 0.06932551,\n",
      "       0.07946671, 0.15393937, 0.05455627, 0.05442717, 0.07497728,\n",
      "       0.08689875, 0.11595869, 0.06555064, 0.09782839, 0.06128911,\n",
      "       0.09794963, 0.07268925, 0.07012874, 0.07585131, 0.08759308,\n",
      "       0.07608983, 0.06850384, 0.08636853, 0.05029865, 0.10399156,\n",
      "       0.06669506, 0.10609598, 0.09848683, 0.09761069, 0.07600407,\n",
      "       0.05365464, 0.07866351, 0.05820691, 0.10377947, 0.06274336,\n",
      "       0.09003476, 0.06546677, 0.06263517, 0.07131308, 0.07929999,\n",
      "       0.0738105 , 0.07276152, 0.06912997, 0.05518268, 0.0801483 ,\n",
      "       0.06398436, 0.06673298, 0.08076207, 0.09978742, 0.06722989,\n",
      "       0.05257944, 0.06513186, 0.08262223, 0.09112099, 0.06600717,\n",
      "       0.08897697, 0.0726507 , 0.08122   , 0.04786376, 0.06282081,\n",
      "       0.09874881, 0.05661904, 0.08749833, 0.11770422, 0.10224124,\n",
      "       0.06695599, 0.06678284, 0.07132401, 0.09216725, 0.06548856,\n",
      "       0.06281887, 0.08461041, 0.06732871, 0.07303917, 0.07481516,\n",
      "       0.09819609, 0.06055701, 0.09347973, 0.05514022, 0.07419224,\n",
      "       0.1030534 , 0.07570237, 0.095772  , 0.07708508, 0.10666304,\n",
      "       0.07425877, 0.10097206, 0.06038379, 0.07988537, 0.08026413,\n",
      "       0.08414655, 0.07578585, 0.1252651 , 0.06749041, 0.09895742,\n",
      "       0.08715666, 0.06169528, 0.06447614, 0.07721647, 0.04587335,\n",
      "       0.09187093, 0.06834598, 0.06907697, 0.0901346 , 0.11086275,\n",
      "       0.07514225, 0.10128085, 0.08540782, 0.06396836, 0.07007499,\n",
      "       0.06677933, 0.056115  , 0.08561377, 0.06162468, 0.07215269,\n",
      "       0.08819676, 0.10004429, 0.05382525, 0.09193249, 0.05771841,\n",
      "       0.07221749, 0.10374644, 0.08672688, 0.08062818, 0.06493382,\n",
      "       0.06351049, 0.07933514, 0.12875932, 0.054665  , 0.05912167,\n",
      "       0.06296193, 0.04024008, 0.06571638, 0.09363025, 0.04984827,\n",
      "       0.07524626, 0.08160417, 0.04996271, 0.08266292, 0.06125877,\n",
      "       0.07119607, 0.07216333, 0.09110909, 0.07553853, 0.0737682 ,\n",
      "       0.07831607, 0.07700857, 0.07783841, 0.10396318, 0.08377073,\n",
      "       0.06692263, 0.07024341, 0.06635973, 0.05174942, 0.06069823,\n",
      "       0.1011487 , 0.04902528, 0.07063142, 0.08255653, 0.07285807,\n",
      "       0.05752045, 0.0544351 , 0.07516345, 0.07551259, 0.05452807])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 16, 'min_data_in_leaf': 89, 'max_depth': 1, 'learning_rate': 0.01567455410205595, 'bagging_fraction': 0.18181818181818182} \n",
      "\n",
      "Best index/iterasi :  46\n",
      "Best AUC : 0.772104825982079 ( std: 0.11595868897138875 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  72 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.53452087, 0.54912374, 0.51114166, 0.62013541, 0.4809594 ,\n",
      "       0.57826834, 0.56356473, 0.55094385, 0.51831545, 0.5660709 ,\n",
      "       0.49366477, 0.5705537 , 0.5977996 , 0.54440054, 0.59480062,\n",
      "       0.54117586, 0.49683417, 0.52472859, 0.58697733, 0.51231593,\n",
      "       0.54235981, 0.54318574, 0.59336801, 0.53617058, 0.4923071 ,\n",
      "       0.48280967, 0.46476502, 0.61266775, 0.57233013, 0.48069312,\n",
      "       0.57687953, 0.52246737, 0.56794954, 0.57303079, 0.56277092,\n",
      "       0.58991855, 0.60691533, 0.59421701, 0.49213156, 0.57109754,\n",
      "       0.500759  , 0.56652811, 0.60726657, 0.56787756, 0.4945675 ,\n",
      "       0.49308401, 0.57161101, 0.5450045 , 0.49373715, 0.50716173,\n",
      "       0.59491529, 0.54183967, 0.59424826, 0.46943939, 0.55354132,\n",
      "       0.57984703, 0.48566777, 0.5961793 , 0.56885461, 0.48224904,\n",
      "       0.50471365, 0.59004934, 0.54802581, 0.53152564, 0.61601705,\n",
      "       0.52822555, 0.50786218, 0.53763711, 0.74684633, 0.50151931,\n",
      "       0.48885639, 0.56718558, 0.57159694, 0.48953368, 0.54182543,\n",
      "       0.47693736, 0.58711161, 0.49981647, 0.5358566 , 0.52011864,\n",
      "       0.46254278, 0.53149734, 0.53834135, 0.47647165, 0.54328137,\n",
      "       0.60630842, 0.49414245, 0.52498571, 0.53058598, 0.57068701,\n",
      "       0.48920497, 0.51560384, 0.50898137, 0.51716022, 0.57778615,\n",
      "       0.62174235, 0.53084582, 0.51876774, 0.5411856 , 0.57393655,\n",
      "       0.48011624, 0.51937381, 0.53858563, 0.54364087, 0.53024089,\n",
      "       0.51755575, 0.60348516, 0.45854709, 0.55208758, 0.58128988,\n",
      "       0.5754532 , 0.53460317, 0.55482218, 0.50432565, 0.54369053,\n",
      "       0.72469259, 0.54381846, 0.52613969, 0.51244697, 0.4922024 ,\n",
      "       0.50414582, 0.57075682, 0.5071179 , 0.50811162, 0.49860165,\n",
      "       0.46252633, 0.59421514, 0.50667426, 0.49335924, 0.56996018,\n",
      "       0.53677851, 0.54077699, 0.55436805, 0.50774968, 0.57013102,\n",
      "       0.54024289, 0.55734144, 0.52896306, 0.51233476, 0.55275963,\n",
      "       0.56207502, 0.57291101, 0.77272187, 0.50566873, 0.61252895,\n",
      "       0.47944147, 0.58122093, 0.53918203, 0.54207705, 0.55384524,\n",
      "       0.5734779 , 0.50782436, 0.49123763, 0.52315875, 0.52560037,\n",
      "       0.58242382, 0.5378108 , 0.52944901, 0.52093963, 0.58985305,\n",
      "       0.72348082, 0.57860402, 0.58596554, 0.57455082, 0.59417785,\n",
      "       0.58059773, 0.52844295, 0.59376858, 0.49105591, 0.5854794 ,\n",
      "       0.50298097, 0.50362626, 0.58370855, 0.57708099, 0.60162031,\n",
      "       0.50244309, 0.55760832, 0.54617421, 0.59270978, 0.54124993,\n",
      "       0.5018457 , 0.57273725, 0.59091564, 0.47082122, 0.65475581,\n",
      "       0.5017461 , 0.48749332, 0.5569525 , 0.54144391, 0.50560302,\n",
      "       0.50871173, 0.75166493, 0.61647473, 0.5862069 , 0.52522142,\n",
      "       0.61096639, 0.58915204, 0.50952543, 0.54903927, 0.55938451])] \n",
      "\n",
      "mean AUC :  0.5469374844287137\n",
      "All std:  [array([0.06987195, 0.10887393, 0.06704429, 0.10490259, 0.07651479,\n",
      "       0.10833216, 0.07423107, 0.07818045, 0.0739109 , 0.10981291,\n",
      "       0.05228321, 0.08610651, 0.0953199 , 0.090783  , 0.09809294,\n",
      "       0.05023009, 0.07808194, 0.07138807, 0.07295443, 0.09010209,\n",
      "       0.08353299, 0.07628592, 0.08154009, 0.06322018, 0.08002527,\n",
      "       0.0820027 , 0.099785  , 0.07944073, 0.07429082, 0.07497291,\n",
      "       0.05803283, 0.06527871, 0.05351432, 0.06155708, 0.07525352,\n",
      "       0.09038934, 0.0946954 , 0.09739301, 0.08070917, 0.08663121,\n",
      "       0.08984772, 0.10714547, 0.08723008, 0.10090364, 0.08325061,\n",
      "       0.10898337, 0.05909683, 0.05991379, 0.07215177, 0.03665179,\n",
      "       0.06784833, 0.07013609, 0.06526375, 0.09450858, 0.06543159,\n",
      "       0.06903962, 0.11343085, 0.09645874, 0.06375659, 0.08003172,\n",
      "       0.08140275, 0.10931512, 0.05902786, 0.05539844, 0.05601168,\n",
      "       0.09686999, 0.08698766, 0.06029662, 0.13309897, 0.09369785,\n",
      "       0.08681509, 0.04744961, 0.06733228, 0.0671954 , 0.06865569,\n",
      "       0.08712259, 0.06840901, 0.09087148, 0.06955585, 0.09670849,\n",
      "       0.09934345, 0.0569809 , 0.08567795, 0.08075715, 0.08116861,\n",
      "       0.08184714, 0.0802881 , 0.07684453, 0.0687639 , 0.07166728,\n",
      "       0.08608098, 0.06653554, 0.07290864, 0.06855964, 0.05834624,\n",
      "       0.10547199, 0.09910852, 0.09717658, 0.07073776, 0.06464754,\n",
      "       0.0809887 , 0.05926455, 0.0894366 , 0.06739709, 0.08669921,\n",
      "       0.11384614, 0.09710135, 0.04628122, 0.07880045, 0.08363555,\n",
      "       0.06019321, 0.07084759, 0.07326137, 0.05369846, 0.05887477,\n",
      "       0.15031266, 0.07190503, 0.06719257, 0.05837114, 0.09147017,\n",
      "       0.07216301, 0.05486418, 0.07471051, 0.07648322, 0.07417039,\n",
      "       0.10971922, 0.10215577, 0.05156421, 0.08432611, 0.07149366,\n",
      "       0.0688025 , 0.07159608, 0.07628379, 0.08092091, 0.07388814,\n",
      "       0.06445634, 0.05124501, 0.06892129, 0.07302888, 0.06279417,\n",
      "       0.15011083, 0.06949822, 0.12908343, 0.08976544, 0.09228173,\n",
      "       0.08134139, 0.06281195, 0.06276652, 0.10077828, 0.04793867,\n",
      "       0.10271294, 0.06718971, 0.10134925, 0.04565577, 0.07325487,\n",
      "       0.06812406, 0.08244039, 0.06468042, 0.0725126 , 0.06543926,\n",
      "       0.14571601, 0.06863955, 0.09400684, 0.06009395, 0.08111704,\n",
      "       0.07022389, 0.07226475, 0.09066501, 0.08052499, 0.07149951,\n",
      "       0.07126562, 0.10223102, 0.07422164, 0.08900211, 0.08909758,\n",
      "       0.08124984, 0.06536393, 0.08128615, 0.07071162, 0.06031473,\n",
      "       0.10547639, 0.05683589, 0.08474139, 0.07612557, 0.08320454,\n",
      "       0.07889895, 0.08663781, 0.07593945, 0.05895059, 0.09139202,\n",
      "       0.08665818, 0.14489689, 0.10395129, 0.07603558, 0.04389538,\n",
      "       0.07937694, 0.07490135, 0.06459112, 0.04836045, 0.0538291 ])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 21, 'min_data_in_leaf': 67, 'max_depth': 2, 'learning_rate': 0.010209606623060466, 'bagging_fraction': 0.9818181818181817} \n",
      "\n",
      "Best index/iterasi :  142\n",
      "Best AUC : 0.772721869952754 ( std: 0.1290834266973954 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  82 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.50582292, 0.5938384 , 0.60571711, 0.54680557, 0.61506765,\n",
      "       0.55335285, 0.48610258, 0.5563513 , 0.49017601, 0.51973326,\n",
      "       0.54039324, 0.52139291, 0.52204339, 0.51828561, 0.64010633,\n",
      "       0.54874801, 0.57054621, 0.53962034, 0.52228365, 0.58260412,\n",
      "       0.66932111, 0.58403849, 0.63601295, 0.53502256, 0.58256394,\n",
      "       0.54195157, 0.61086446, 0.49294516, 0.55293552, 0.56611803,\n",
      "       0.47751083, 0.47919528, 0.48143283, 0.57147829, 0.49211923,\n",
      "       0.56396264, 0.5265486 , 0.54671621, 0.58601905, 0.53772742,\n",
      "       0.53893694, 0.49314756, 0.59970856, 0.55444399, 0.59353697,\n",
      "       0.50217919, 0.48637039, 0.44123884, 0.51562239, 0.51243254,\n",
      "       0.50477755, 0.49369785, 0.53768567, 0.48789325, 0.50886842,\n",
      "       0.52169376, 0.62102647, 0.58064672, 0.61649822, 0.49428998,\n",
      "       0.62325276, 0.55028308, 0.54985893, 0.52730073, 0.50572001,\n",
      "       0.61926204, 0.47905575, 0.77804063, 0.52631991, 0.50128255,\n",
      "       0.59848686, 0.75309074, 0.49373444, 0.57288071, 0.62773579,\n",
      "       0.58264868, 0.49869377, 0.51642265, 0.57130299, 0.51292696,\n",
      "       0.60079751, 0.48985972, 0.52943782, 0.54226842, 0.52705263,\n",
      "       0.4908264 , 0.59797983, 0.51681548, 0.56658847, 0.65403151,\n",
      "       0.61359026, 0.48379049, 0.4797666 , 0.55993115, 0.57898709,\n",
      "       0.49416196, 0.49767437, 0.47455656, 0.53010601, 0.52317982,\n",
      "       0.52778182, 0.53431132, 0.48625065, 0.53016011, 0.55669349,\n",
      "       0.48527008, 0.51380705, 0.51408002, 0.5127451 , 0.54627381,\n",
      "       0.4867367 , 0.50708409, 0.58423652, 0.52055307, 0.61832104,\n",
      "       0.48430195, 0.52520757, 0.52781778, 0.57785263, 0.59035978,\n",
      "       0.46550625, 0.53433138, 0.51072256, 0.52084958, 0.53462029,\n",
      "       0.51916702, 0.52508803, 0.49560379, 0.58014664, 0.56810154,\n",
      "       0.55381466, 0.56430813, 0.48512723, 0.51995445, 0.50085837,\n",
      "       0.59260645, 0.55978155, 0.54012993, 0.63365612, 0.57062495,\n",
      "       0.47819209, 0.48839512, 0.56930176, 0.52028094, 0.4989244 ,\n",
      "       0.56892245, 0.58087932, 0.53858088, 0.54557564, 0.53435963,\n",
      "       0.5155192 , 0.54859121, 0.57243632, 0.5534334 , 0.51306228,\n",
      "       0.51570837, 0.56011709, 0.60111329, 0.58498255, 0.48359198,\n",
      "       0.50149912, 0.52390103, 0.50280418, 0.54297138, 0.54518769,\n",
      "       0.55909832, 0.49970668, 0.51605802, 0.58837566, 0.52511738,\n",
      "       0.46244292, 0.51225333, 0.58089403, 0.57666491, 0.50859296,\n",
      "       0.55686843, 0.49222487, 0.61323407, 0.54042401, 0.53610433,\n",
      "       0.54366586, 0.59155442, 0.61375037, 0.57083915, 0.60482387,\n",
      "       0.58156254, 0.59005432, 0.59381948, 0.51825165, 0.49892382,\n",
      "       0.46071642, 0.64754403, 0.53093042, 0.49860869, 0.49569958,\n",
      "       0.47304354, 0.59917882, 0.64775448, 0.56556156, 0.49136861])] \n",
      "\n",
      "mean AUC :  0.5436837967045903\n",
      "All std:  [array([0.06702752, 0.09239348, 0.10219603, 0.06548224, 0.07942868,\n",
      "       0.07467779, 0.07573703, 0.06199201, 0.0911703 , 0.09215539,\n",
      "       0.07474321, 0.06064299, 0.0596562 , 0.07215789, 0.11501117,\n",
      "       0.06429622, 0.05188674, 0.07196585, 0.06640114, 0.0941644 ,\n",
      "       0.16618758, 0.06790282, 0.13846129, 0.06263406, 0.09513728,\n",
      "       0.06664161, 0.09223564, 0.07615145, 0.07248095, 0.05931591,\n",
      "       0.07273538, 0.08209093, 0.08232075, 0.07161151, 0.08170698,\n",
      "       0.0840602 , 0.06084406, 0.06432289, 0.07690264, 0.06624382,\n",
      "       0.06148152, 0.07318662, 0.09312712, 0.06000545, 0.09605204,\n",
      "       0.07244304, 0.07120282, 0.05715052, 0.06542981, 0.08920975,\n",
      "       0.07115013, 0.06722562, 0.07808235, 0.07402256, 0.05807251,\n",
      "       0.08047559, 0.09427732, 0.06973496, 0.09708324, 0.07545735,\n",
      "       0.12242515, 0.05905962, 0.05798194, 0.10044461, 0.07330744,\n",
      "       0.08244848, 0.06563785, 0.11668418, 0.05157452, 0.0877033 ,\n",
      "       0.11332975, 0.14124746, 0.06565053, 0.05662351, 0.0995591 ,\n",
      "       0.06427706, 0.0699649 , 0.06660135, 0.08635882, 0.05582843,\n",
      "       0.09950942, 0.10264233, 0.06509295, 0.06388518, 0.04580825,\n",
      "       0.07995572, 0.09616722, 0.0930016 , 0.10673925, 0.10271358,\n",
      "       0.09496334, 0.08522211, 0.09560235, 0.07057497, 0.06336338,\n",
      "       0.08349709, 0.07721454, 0.0807568 , 0.06715246, 0.06150311,\n",
      "       0.08157157, 0.05720022, 0.07542405, 0.0597864 , 0.06423659,\n",
      "       0.0723667 , 0.0716156 , 0.07176565, 0.06770317, 0.06674928,\n",
      "       0.08850762, 0.08722144, 0.06432771, 0.06273827, 0.0867662 ,\n",
      "       0.07005408, 0.06451733, 0.07075881, 0.06293223, 0.07888267,\n",
      "       0.08260817, 0.06578344, 0.07422859, 0.0477634 , 0.06010517,\n",
      "       0.06837224, 0.06300572, 0.10063047, 0.07030169, 0.05316879,\n",
      "       0.07000109, 0.06244751, 0.07418494, 0.06692551, 0.09603978,\n",
      "       0.08401402, 0.06747188, 0.06064806, 0.0908154 , 0.05854323,\n",
      "       0.10102142, 0.06379277, 0.0536102 , 0.07019193, 0.07277213,\n",
      "       0.08315388, 0.06211754, 0.06671945, 0.08275188, 0.07085556,\n",
      "       0.08782247, 0.05683028, 0.06185638, 0.06540694, 0.0763452 ,\n",
      "       0.09644781, 0.09440678, 0.10230309, 0.09149664, 0.08567021,\n",
      "       0.07057443, 0.06559133, 0.07219157, 0.08843839, 0.05354216,\n",
      "       0.0774529 , 0.08420861, 0.07313154, 0.06682045, 0.06786961,\n",
      "       0.0986632 , 0.06196774, 0.08956164, 0.07056842, 0.0522727 ,\n",
      "       0.07555291, 0.07536975, 0.09447721, 0.08000838, 0.06638719,\n",
      "       0.06941467, 0.06577842, 0.0947194 , 0.04663454, 0.08821953,\n",
      "       0.05859328, 0.07374351, 0.09297813, 0.06280489, 0.06229107,\n",
      "       0.0809812 , 0.13213763, 0.07548959, 0.07615549, 0.09395195,\n",
      "       0.07511747, 0.09175902, 0.09304679, 0.05162351, 0.06985614])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 97, 'min_data_in_leaf': 5, 'max_depth': 1, 'learning_rate': 0.007742636826811269, 'bagging_fraction': 0.7909090909090909} \n",
      "\n",
      "Best index/iterasi :  67\n",
      "Best AUC : 0.7780406254196934 ( std: 0.11668417930714656 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  92 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.52443617, 0.4973745 , 0.47265871, 0.53226787, 0.47997459,\n",
      "       0.50881428, 0.56035648, 0.53522151, 0.49559944, 0.57916228,\n",
      "       0.53973499, 0.56922427, 0.58495999, 0.60555307, 0.58036244,\n",
      "       0.58304388, 0.59464317, 0.5816488 , 0.57552919, 0.52392458,\n",
      "       0.56892687, 0.50424715, 0.53378936, 0.56581315, 0.57395907,\n",
      "       0.51287896, 0.57363602, 0.59480091, 0.56774225, 0.50082289,\n",
      "       0.57940812, 0.58144776, 0.60271853, 0.53232693, 0.4957849 ,\n",
      "       0.57592627, 0.58093617, 0.49192232, 0.53132586, 0.51522965,\n",
      "       0.51598486, 0.51781651, 0.47293488, 0.54284108, 0.51714063,\n",
      "       0.62370513, 0.50975436, 0.53118237, 0.56778147, 0.55128085,\n",
      "       0.56465344, 0.50460013, 0.51212341, 0.49030767, 0.51900031,\n",
      "       0.53979687, 0.68713148, 0.49392033, 0.54134503, 0.47564645,\n",
      "       0.54376287, 0.49864747, 0.5350731 , 0.58119254, 0.57785539,\n",
      "       0.49099292, 0.51168212, 0.50152983, 0.52283529, 0.6047372 ,\n",
      "       0.57461932, 0.5042172 , 0.56741432, 0.5200339 , 0.51443925,\n",
      "       0.55876078, 0.51159088, 0.56933886, 0.46644873, 0.58771775,\n",
      "       0.5097704 , 0.5755442 , 0.59614533, 0.48269395, 0.48991544,\n",
      "       0.56930999, 0.75669157, 0.56636708, 0.51518541, 0.57068838,\n",
      "       0.60754035, 0.51386955, 0.59337586, 0.5530016 , 0.55944527,\n",
      "       0.50119795, 0.56389362, 0.51519196, 0.55163928, 0.51330132,\n",
      "       0.54409464, 0.51727317, 0.49227032, 0.53394205, 0.60081155,\n",
      "       0.48008224, 0.58004797, 0.50886562, 0.49446926, 0.57730282,\n",
      "       0.57085148, 0.5975855 , 0.4886406 , 0.557768  , 0.72488201,\n",
      "       0.54341488, 0.5886065 , 0.4960579 , 0.50406704, 0.56846172,\n",
      "       0.57279316, 0.57657397, 0.52384753, 0.57305595, 0.53680879,\n",
      "       0.55571761, 0.52840953, 0.50308942, 0.60400714, 0.52805914,\n",
      "       0.49287807, 0.51101235, 0.60409692, 0.70723593, 0.5164207 ,\n",
      "       0.59739123, 0.61648845, 0.49480047, 0.53480226, 0.53818363,\n",
      "       0.55832111, 0.52763238, 0.47230822, 0.51743959, 0.49665796,\n",
      "       0.61822304, 0.49171049, 0.56215142, 0.50843588, 0.51203292,\n",
      "       0.50722857, 0.52869661, 0.69437408, 0.73778768, 0.5645377 ,\n",
      "       0.51765204, 0.54230388, 0.51164245, 0.58656104, 0.47535906,\n",
      "       0.5756073 , 0.62969452, 0.48620549, 0.56856236, 0.51617136,\n",
      "       0.60401528, 0.6255914 , 0.60663673, 0.51804088, 0.47604424,\n",
      "       0.49233881, 0.56908243, 0.47859076, 0.48097411, 0.56945133,\n",
      "       0.61211439, 0.50564987, 0.58673842, 0.58179155, 0.53868209,\n",
      "       0.56221623, 0.60435459, 0.53046765, 0.57378481, 0.49854404,\n",
      "       0.59309807, 0.49756058, 0.57890859, 0.59294968, 0.57631366,\n",
      "       0.50194823, 0.56822715, 0.49285463, 0.55461199, 0.61064506,\n",
      "       0.49967417, 0.5816744 , 0.50583073, 0.56280451, 0.48569018])] \n",
      "\n",
      "mean AUC :  0.547225523811611\n",
      "All std:  [array([0.06447948, 0.06926119, 0.08819754, 0.06828765, 0.09290907,\n",
      "       0.07068113, 0.0606283 , 0.07426558, 0.05367015, 0.06844277,\n",
      "       0.05182698, 0.07153217, 0.06703459, 0.09527274, 0.06533564,\n",
      "       0.07999632, 0.0890057 , 0.0694595 , 0.060896  , 0.06060129,\n",
      "       0.0660794 , 0.08886317, 0.08025006, 0.07518806, 0.07638259,\n",
      "       0.0982961 , 0.04982385, 0.09948301, 0.06229689, 0.07087804,\n",
      "       0.08186939, 0.07485018, 0.09992482, 0.06202092, 0.06975854,\n",
      "       0.05831663, 0.0825109 , 0.07607579, 0.09078107, 0.06974953,\n",
      "       0.06507143, 0.09552256, 0.07928202, 0.05613974, 0.07066824,\n",
      "       0.098401  , 0.06319594, 0.06578199, 0.06371855, 0.05726521,\n",
      "       0.09472099, 0.07390702, 0.0784175 , 0.07949444, 0.06904318,\n",
      "       0.06238674, 0.16338167, 0.06497676, 0.08476108, 0.08118041,\n",
      "       0.05850847, 0.0719917 , 0.06414559, 0.07303661, 0.05639841,\n",
      "       0.09441771, 0.07125176, 0.07627861, 0.07097223, 0.07666244,\n",
      "       0.05740771, 0.06961571, 0.05238152, 0.06435792, 0.08423368,\n",
      "       0.0734479 , 0.08308816, 0.07088849, 0.08954251, 0.06663248,\n",
      "       0.07295394, 0.05931587, 0.08697051, 0.08392261, 0.06979542,\n",
      "       0.07020665, 0.13675554, 0.07915554, 0.06507263, 0.05698879,\n",
      "       0.09399594, 0.08129317, 0.09523406, 0.07804924, 0.05570902,\n",
      "       0.09486798, 0.06643715, 0.07119092, 0.06760518, 0.05957342,\n",
      "       0.07575923, 0.0962662 , 0.0945179 , 0.06879763, 0.11893805,\n",
      "       0.07366602, 0.05889035, 0.07452572, 0.07861243, 0.06164741,\n",
      "       0.05086317, 0.0948365 , 0.0678862 , 0.08065943, 0.13714864,\n",
      "       0.0702085 , 0.06391342, 0.07513772, 0.06721414, 0.05390597,\n",
      "       0.09164788, 0.05813559, 0.21117865, 0.05452322, 0.07985161,\n",
      "       0.05470777, 0.08441133, 0.07184832, 0.09955236, 0.06474653,\n",
      "       0.06953771, 0.10722714, 0.10104826, 0.14914276, 0.08424681,\n",
      "       0.06255882, 0.11445319, 0.09733401, 0.0877841 , 0.05998028,\n",
      "       0.08778272, 0.13236631, 0.08926281, 0.06164126, 0.07379652,\n",
      "       0.09091122, 0.09622081, 0.1145979 , 0.09997934, 0.07952687,\n",
      "       0.06380106, 0.06813201, 0.1321013 , 0.13583235, 0.07311234,\n",
      "       0.0703848 , 0.0647812 , 0.07052728, 0.06582617, 0.08462282,\n",
      "       0.09285028, 0.10599546, 0.07101716, 0.06806419, 0.09055719,\n",
      "       0.09760727, 0.10335854, 0.10042861, 0.06471471, 0.09250132,\n",
      "       0.0776538 , 0.05455631, 0.08006247, 0.06784141, 0.0939787 ,\n",
      "       0.10951724, 0.06857764, 0.09541838, 0.06483772, 0.10409704,\n",
      "       0.07827978, 0.09697957, 0.04670123, 0.11468707, 0.09247442,\n",
      "       0.11246428, 0.0701044 , 0.08322385, 0.04721852, 0.06082274,\n",
      "       0.06988909, 0.10075128, 0.08624993, 0.07552874, 0.1057998 ,\n",
      "       0.05931078, 0.07968355, 0.06314716, 0.08456244, 0.10346022])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 99, 'min_data_in_leaf': 39, 'max_depth': 1, 'learning_rate': 0.04042095839796308, 'bagging_fraction': 0.26363636363636367} \n",
      "\n",
      "Best index/iterasi :  86\n",
      "Best AUC : 0.7566915687635525 ( std: 0.1367555425186671 ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds=[1,12,22,32,42,52,62,72,82,92]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    auc,std,best_index,best_param=random_search(X_bank,y_bank,model_l,hyper_space_6,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dataset 2(Credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8454545454545453, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8454545454545453\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=97, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=97\n",
      "Seed:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.77279196, 0.77021032, 0.74516184, 0.6974621 , 0.77754732,\n",
      "       0.76242693, 0.77755377, 0.71888004, 0.68963802, 0.76818505,\n",
      "       0.76927403, 0.77355196, 0.77017712, 0.76926384, 0.74891434,\n",
      "       0.73230648, 0.7743511 , 0.73310595, 0.74468057, 0.74848561,\n",
      "       0.7688802 , 0.77354914, 0.77069053, 0.69989698, 0.77049258,\n",
      "       0.76816503, 0.77741122, 0.76532236, 0.70329545, 0.77263966,\n",
      "       0.7032822 , 0.62673241, 0.69528617, 0.77303653, 0.77637582,\n",
      "       0.59649988, 0.7687838 , 0.75632748, 0.71048422, 0.766015  ,\n",
      "       0.77156312, 0.77405354, 0.7704965 , 0.76239915, 0.75964224,\n",
      "       0.75689274, 0.77010443, 0.77085532, 0.72936128, 0.7572233 ,\n",
      "       0.70857127, 0.71648296, 0.76931226, 0.76785107, 0.76860363,\n",
      "       0.76590667, 0.76954633, 0.67983738, 0.69726022, 0.76955608,\n",
      "       0.72941948, 0.76973982, 0.77464898, 0.76487514, 0.76931592,\n",
      "       0.75063627, 0.76593344, 0.76817338, 0.71135129, 0.77739945,\n",
      "       0.72037595, 0.6824508 , 0.72964677, 0.68065213, 0.76912554,\n",
      "       0.6793544 , 0.7717107 , 0.76626585, 0.68030249, 0.77718011,\n",
      "       0.77021843, 0.75712921, 0.77255839, 0.77484571, 0.66516828,\n",
      "       0.76601192, 0.76856936, 0.73211024, 0.71247559, 0.71371665,\n",
      "       0.77482875, 0.76959717, 0.71837071, 0.76442607, 0.77131071,\n",
      "       0.77548293, 0.7557897 , 0.75065583, 0.74831327, 0.71182042,\n",
      "       0.77048179, 0.72388427, 0.7739544 , 0.75744777, 0.77429992,\n",
      "       0.77190778, 0.77096806, 0.74743215, 0.74339408, 0.75383718,\n",
      "       0.73669641, 0.77520486, 0.76707967, 0.77196419, 0.77231886,\n",
      "       0.69539723, 0.68832971, 0.73816116, 0.7764363 , 0.7766808 ,\n",
      "       0.76984231, 0.7323116 , 0.76943565, 0.69940412, 0.74040221,\n",
      "       0.76316452, 0.71301395, 0.77512698, 0.77774663, 0.77004197,\n",
      "       0.72702064, 0.69922245, 0.77568171, 0.74792618, 0.71377059,\n",
      "       0.72015891, 0.72384278, 0.77431423, 0.77033792, 0.77534415,\n",
      "       0.7752833 , 0.77615024, 0.769584  , 0.77697397, 0.7691417 ,\n",
      "       0.74923622, 0.74711124, 0.77638794, 0.7465329 , 0.73191287,\n",
      "       0.74498973, 0.77640214, 0.73968918, 0.77237776, 0.7707392 ,\n",
      "       0.76616255, 0.77179127, 0.7690685 , 0.71713959, 0.76458293,\n",
      "       0.77628524, 0.77102979, 0.67348832, 0.77118647, 0.76963027,\n",
      "       0.76603647, 0.77479329, 0.71803729, 0.7763502 , 0.77616498,\n",
      "       0.7696427 , 0.76980658, 0.7726714 , 0.66161478, 0.7680169 ,\n",
      "       0.77510141, 0.77320308, 0.77170445, 0.71600023, 0.77508784,\n",
      "       0.76751342, 0.74473113, 0.76965236, 0.77013824, 0.72533684,\n",
      "       0.77095591, 0.6797439 , 0.77628591, 0.77258602, 0.7407899 ,\n",
      "       0.77536436, 0.75703328, 0.77305785, 0.72462802, 0.77044207,\n",
      "       0.68583385, 0.77526653, 0.7752994 , 0.71898821, 0.77391872])] \n",
      "\n",
      "mean AUC :  0.750216363514221\n",
      "All std:  [array([0.01881804, 0.02041147, 0.01122448, 0.01814501, 0.01905776,\n",
      "       0.01527633, 0.0175119 , 0.01901379, 0.01761971, 0.01313365,\n",
      "       0.02036532, 0.01740526, 0.01927781, 0.01196999, 0.0183974 ,\n",
      "       0.01945079, 0.01779823, 0.02060584, 0.02014501, 0.01367281,\n",
      "       0.01955491, 0.01903199, 0.01823472, 0.01650215, 0.01951717,\n",
      "       0.01956067, 0.01722792, 0.01524714, 0.0250449 , 0.01842488,\n",
      "       0.02262467, 0.03652853, 0.03372461, 0.0177727 , 0.01862947,\n",
      "       0.02861117, 0.02150582, 0.01462912, 0.02284317, 0.01694159,\n",
      "       0.0190426 , 0.01682802, 0.01928559, 0.01129852, 0.02517401,\n",
      "       0.00975529, 0.01989392, 0.02073174, 0.02507091, 0.0105502 ,\n",
      "       0.02710994, 0.02538237, 0.01924924, 0.02001281, 0.02030201,\n",
      "       0.01308597, 0.01872483, 0.01553628, 0.00941664, 0.01855804,\n",
      "       0.01922315, 0.02067684, 0.02140911, 0.00699896, 0.01906684,\n",
      "       0.01617928, 0.01865251, 0.01819958, 0.02398003, 0.01725083,\n",
      "       0.01750328, 0.02157569, 0.02172822, 0.03819946, 0.0179893 ,\n",
      "       0.0139132 , 0.02001044, 0.00830957, 0.02528001, 0.01762632,\n",
      "       0.01865845, 0.01517841, 0.01817883, 0.01877175, 0.01707027,\n",
      "       0.01453176, 0.02177556, 0.017315  , 0.02571515, 0.0234881 ,\n",
      "       0.01603776, 0.01983725, 0.03236668, 0.00962333, 0.01669038,\n",
      "       0.01856338, 0.02167089, 0.01562522, 0.01064353, 0.0164795 ,\n",
      "       0.01868211, 0.0195444 , 0.01876646, 0.01220737, 0.01666021,\n",
      "       0.02158591, 0.02051655, 0.01713133, 0.00638236, 0.02136582,\n",
      "       0.01291032, 0.01881346, 0.01970939, 0.01171481, 0.01752647,\n",
      "       0.02168574, 0.01720107, 0.02381535, 0.01717523, 0.01862392,\n",
      "       0.01903167, 0.01334632, 0.012295  , 0.03094024, 0.0182426 ,\n",
      "       0.01201198, 0.02886058, 0.0177626 , 0.01928364, 0.012013  ,\n",
      "       0.02665686, 0.02335344, 0.0194162 , 0.02094655, 0.02579715,\n",
      "       0.02469281, 0.02873721, 0.01883013, 0.01959729, 0.01869773,\n",
      "       0.01673911, 0.01776397, 0.01794212, 0.01987469, 0.01853614,\n",
      "       0.0211943 , 0.01816199, 0.01905525, 0.0255255 , 0.02062236,\n",
      "       0.02379229, 0.0183708 , 0.02209625, 0.01732923, 0.01949042,\n",
      "       0.01926166, 0.02242846, 0.01793592, 0.02099468, 0.01649864,\n",
      "       0.0193051 , 0.02021743, 0.03661597, 0.01877196, 0.01821525,\n",
      "       0.01769887, 0.01772409, 0.02641701, 0.01718398, 0.01933253,\n",
      "       0.01962305, 0.01940146, 0.01858554, 0.03922593, 0.01941491,\n",
      "       0.01850962, 0.0165106 , 0.01501408, 0.03099074, 0.01680069,\n",
      "       0.00999514, 0.01116793, 0.02065941, 0.01668043, 0.01964219,\n",
      "       0.01841792, 0.02864779, 0.01720372, 0.02127192, 0.02334567,\n",
      "       0.01932911, 0.00612337, 0.01901919, 0.01934477, 0.02024305,\n",
      "       0.0265084 , 0.01778473, 0.01930143, 0.01785567, 0.02107608])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 25, 'min_data_in_leaf': 97, 'max_depth': 47, 'learning_rate': 0.014228304572143526, 'bagging_fraction': 0.8454545454545453} \n",
      "\n",
      "Best index/iterasi :  128\n",
      "Best AUC : 0.7777466308305733 ( std: 0.019283639426538948 ) \n",
      "\n",
      "running time:  222.18553137779236  detik. Dalam menit:  3.7030921896298725  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Seed:  12 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76991368, 0.77863715, 0.7328613 , 0.7671993 , 0.76970187,\n",
      "       0.72028358, 0.73558444, 0.71384473, 0.77380849, 0.77402602,\n",
      "       0.75929185, 0.69042254, 0.76440751, 0.76716792, 0.76772273,\n",
      "       0.70316041, 0.77137159, 0.68624414, 0.74009434, 0.69056188,\n",
      "       0.77060476, 0.74548605, 0.74377506, 0.77599057, 0.77688836,\n",
      "       0.76539569, 0.7682027 , 0.7674351 , 0.70494034, 0.76909681,\n",
      "       0.76693484, 0.71170481, 0.76686462, 0.77195   , 0.77367958,\n",
      "       0.76939857, 0.74221884, 0.77507983, 0.77048287, 0.72488227,\n",
      "       0.74541464, 0.7253205 , 0.77056632, 0.77604727, 0.77718706,\n",
      "       0.73813802, 0.73724928, 0.73549004, 0.7694006 , 0.77667618,\n",
      "       0.77375097, 0.7523926 , 0.75623255, 0.71761427, 0.77002129,\n",
      "       0.77475278, 0.7783623 , 0.73000435, 0.73151533, 0.76353846,\n",
      "       0.77377782, 0.75960845, 0.75230978, 0.77428541, 0.76364779,\n",
      "       0.76785759, 0.77251732, 0.76977182, 0.68814146, 0.77164777,\n",
      "       0.7297569 , 0.76751443, 0.74349623, 0.76976637, 0.77002408,\n",
      "       0.77560477, 0.71652288, 0.77562349, 0.70160877, 0.76807111,\n",
      "       0.76664925, 0.72633064, 0.77217634, 0.77104642, 0.77286309,\n",
      "       0.77262103, 0.72266142, 0.77650329, 0.77019036, 0.67404859,\n",
      "       0.76878836, 0.77581005, 0.77679981, 0.73900458, 0.77099345,\n",
      "       0.70963888, 0.77355642, 0.77180687, 0.71646375, 0.6856123 ,\n",
      "       0.7491138 , 0.77253215, 0.76958902, 0.77337047, 0.70750272,\n",
      "       0.75043286, 0.77299546, 0.70831613, 0.77002627, 0.77557287,\n",
      "       0.76913771, 0.6983992 , 0.77314268, 0.77214197, 0.74957378,\n",
      "       0.77621551, 0.72302583, 0.73791126, 0.77047116, 0.68093216,\n",
      "       0.75052147, 0.75312759, 0.72559649, 0.75267398, 0.73646473,\n",
      "       0.77273576, 0.71684913, 0.76692295, 0.74344174, 0.77614708,\n",
      "       0.68980564, 0.77674836, 0.65229593, 0.77568569, 0.77724855,\n",
      "       0.77069274, 0.74090284, 0.71343093, 0.77363649, 0.72951646,\n",
      "       0.77681009, 0.77266147, 0.77622091, 0.77316445, 0.69597642,\n",
      "       0.71876564, 0.76325167, 0.77060756, 0.77099604, 0.77625348,\n",
      "       0.7698732 , 0.77186418, 0.71217702, 0.72114913, 0.73532789,\n",
      "       0.76991374, 0.77512507, 0.77002059, 0.77465759, 0.77124537,\n",
      "       0.76738076, 0.77183239, 0.73931616, 0.68415084, 0.77171745,\n",
      "       0.76566939, 0.7763282 , 0.7309489 , 0.76782546, 0.69390934,\n",
      "       0.76565796, 0.77570714, 0.76580714, 0.77042898, 0.76260556,\n",
      "       0.70847389, 0.76651538, 0.75622396, 0.70315231, 0.73102655,\n",
      "       0.67657792, 0.75417838, 0.70453463, 0.76703475, 0.77037688,\n",
      "       0.76410727, 0.77527831, 0.77710048, 0.7755138 , 0.69571283,\n",
      "       0.76511249, 0.77171613, 0.77504088, 0.7468124 , 0.7533109 ,\n",
      "       0.73220139, 0.77241532, 0.77017427, 0.76944965, 0.7699568 ])] \n",
      "\n",
      "mean AUC :  0.7519215171218877\n",
      "All std:  [array([0.01991469, 0.01836053, 0.02138448, 0.013032  , 0.01815423,\n",
      "       0.03464449, 0.01834821, 0.0216625 , 0.01895746, 0.01756022,\n",
      "       0.01357278, 0.0310017 , 0.01691991, 0.01953988, 0.01963534,\n",
      "       0.02687606, 0.01812064, 0.02390422, 0.01686888, 0.02499729,\n",
      "       0.01990781, 0.01139031, 0.01689939, 0.01612356, 0.01653039,\n",
      "       0.01940002, 0.02012196, 0.00956155, 0.02426957, 0.01989871,\n",
      "       0.01934674, 0.02140223, 0.01394589, 0.02071603, 0.01795715,\n",
      "       0.02027151, 0.01864126, 0.01731311, 0.02005916, 0.02237971,\n",
      "       0.01937234, 0.02000866, 0.02036985, 0.0193362 , 0.01893146,\n",
      "       0.01462199, 0.01890561, 0.03099996, 0.02009716, 0.01726992,\n",
      "       0.01852341, 0.02237541, 0.00787353, 0.0171201 , 0.01903356,\n",
      "       0.01858351, 0.01870646, 0.02455092, 0.02228672, 0.01837448,\n",
      "       0.01609737, 0.00867363, 0.01854735, 0.01939164, 0.01742018,\n",
      "       0.02141357, 0.01950843, 0.01659873, 0.02442078, 0.01943904,\n",
      "       0.0171358 , 0.01307621, 0.02583553, 0.0192994 , 0.01979956,\n",
      "       0.01896118, 0.02672414, 0.01874771, 0.01488584, 0.01516592,\n",
      "       0.01999483, 0.02596518, 0.01904452, 0.01926635, 0.01951049,\n",
      "       0.01989411, 0.03158036, 0.01923027, 0.02013496, 0.03527685,\n",
      "       0.02144534, 0.01892093, 0.01787772, 0.02727378, 0.01885066,\n",
      "       0.0250367 , 0.01885241, 0.01937145, 0.02750944, 0.04012464,\n",
      "       0.01158378, 0.01854706, 0.01781084, 0.01786547, 0.02951032,\n",
      "       0.02230786, 0.01960425, 0.02628707, 0.02010085, 0.01928313,\n",
      "       0.01074987, 0.03026683, 0.01970721, 0.02000586, 0.01963642,\n",
      "       0.01756855, 0.01445968, 0.03186359, 0.02011294, 0.01998169,\n",
      "       0.00957058, 0.01121072, 0.02503643, 0.02090489, 0.02019946,\n",
      "       0.02058348, 0.02549867, 0.02154601, 0.01915716, 0.01903023,\n",
      "       0.03037572, 0.0188693 , 0.03663433, 0.01703015, 0.01886644,\n",
      "       0.02018051, 0.0181486 , 0.03662887, 0.01930911, 0.01978986,\n",
      "       0.01873573, 0.01899893, 0.01848881, 0.01400254, 0.02197997,\n",
      "       0.02092191, 0.01883817, 0.01407649, 0.01162895, 0.01898474,\n",
      "       0.01951055, 0.01823919, 0.03275787, 0.01842206, 0.0198499 ,\n",
      "       0.0192868 , 0.01902395, 0.01104085, 0.01822291, 0.01991196,\n",
      "       0.01623505, 0.01898946, 0.02107394, 0.02253712, 0.0187303 ,\n",
      "       0.01809592, 0.01901496, 0.01219145, 0.01790134, 0.02440626,\n",
      "       0.01415697, 0.01639451, 0.0196116 , 0.01827685, 0.01958783,\n",
      "       0.02131778, 0.01994429, 0.0085997 , 0.04012952, 0.0217589 ,\n",
      "       0.03821528, 0.0166288 , 0.03080759, 0.01732165, 0.01968497,\n",
      "       0.01606132, 0.01901739, 0.01862586, 0.01909944, 0.03478715,\n",
      "       0.01047557, 0.01802507, 0.01950709, 0.02860485, 0.00593623,\n",
      "       0.03018105, 0.01916213, 0.01964235, 0.01780917, 0.0209749 ])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 36, 'min_data_in_leaf': 98, 'max_depth': 63, 'learning_rate': 0.02095662399480433, 'bagging_fraction': 0.3909090909090909} \n",
      "\n",
      "Best index/iterasi :  1\n",
      "Best AUC : 0.778637152558559 ( std: 0.018360531447619254 ) \n",
      "\n",
      "running time:  203.01987957954407  detik. Dalam menit:  3.383664659659068  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  22 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.77108709, 0.70637529, 0.77609809, 0.77176424, 0.75984849,\n",
      "       0.72816392, 0.76161587, 0.77212401, 0.72956129, 0.76896799,\n",
      "       0.76544189, 0.77258565, 0.74058259, 0.75388121, 0.76439351,\n",
      "       0.77633155, 0.77591414, 0.77074731, 0.77246712, 0.77144191,\n",
      "       0.7553967 , 0.7728957 , 0.77296918, 0.69809182, 0.77361667,\n",
      "       0.72741256, 0.77063284, 0.77611767, 0.77442927, 0.76526218,\n",
      "       0.76998282, 0.77296592, 0.77100837, 0.77599164, 0.69969434,\n",
      "       0.72372109, 0.77544538, 0.77474261, 0.77219635, 0.74978735,\n",
      "       0.75971997, 0.68964474, 0.77121764, 0.74295225, 0.72716024,\n",
      "       0.77542496, 0.77014532, 0.77460942, 0.77042597, 0.77419299,\n",
      "       0.71245127, 0.77726923, 0.76955087, 0.77383738, 0.7527218 ,\n",
      "       0.7691959 , 0.77163392, 0.71681412, 0.75574537, 0.70305569,\n",
      "       0.77616114, 0.7740723 , 0.76914225, 0.76723966, 0.77730729,\n",
      "       0.77576584, 0.76897135, 0.74561072, 0.72830085, 0.7667941 ,\n",
      "       0.70649377, 0.76865182, 0.75409425, 0.73820442, 0.75784434,\n",
      "       0.70188391, 0.75219769, 0.75624317, 0.76894244, 0.74828075,\n",
      "       0.72517284, 0.76663353, 0.7769034 , 0.77783343, 0.77123079,\n",
      "       0.77565964, 0.77914813, 0.74242671, 0.71018334, 0.77036509,\n",
      "       0.67455533, 0.77301993, 0.77718209, 0.77174504, 0.70628791,\n",
      "       0.77079534, 0.7601113 , 0.77110571, 0.76733086, 0.772418  ,\n",
      "       0.77608837, 0.77627717, 0.77686731, 0.76461126, 0.77142585,\n",
      "       0.77273962, 0.77367779, 0.69797712, 0.75665071, 0.77379297,\n",
      "       0.76859093, 0.77084346, 0.77262455, 0.76630161, 0.75563655,\n",
      "       0.75949298, 0.77108022, 0.77512201, 0.70148911, 0.76509789,\n",
      "       0.68136779, 0.7700673 , 0.77173637, 0.76505964, 0.77640216,\n",
      "       0.66762808, 0.66662849, 0.76833216, 0.7090579 , 0.72742502,\n",
      "       0.68050529, 0.77179546, 0.77277009, 0.68995021, 0.77180716,\n",
      "       0.76097119, 0.70152377, 0.72605478, 0.7683253 , 0.77283871,\n",
      "       0.72930726, 0.6957925 , 0.77343299, 0.75604065, 0.76727752,\n",
      "       0.77053638, 0.77562535, 0.68035887, 0.77001344, 0.7202638 ,\n",
      "       0.76732661, 0.76165777, 0.76232727, 0.76793921, 0.7678306 ,\n",
      "       0.77203012, 0.77324673, 0.77287067, 0.75345774, 0.76955329,\n",
      "       0.7723648 , 0.70543879, 0.769691  , 0.76338687, 0.77545217,\n",
      "       0.77229526, 0.76846849, 0.7742462 , 0.70347114, 0.76993147,\n",
      "       0.77400305, 0.74965552, 0.77248367, 0.67741994, 0.77383941,\n",
      "       0.77044773, 0.77198576, 0.76233497, 0.68811239, 0.69222698,\n",
      "       0.77101768, 0.77238393, 0.77554333, 0.71057212, 0.76570302,\n",
      "       0.76706677, 0.77272522, 0.76513892, 0.77555638, 0.7226408 ,\n",
      "       0.72902198, 0.77056006, 0.70407844, 0.74257241, 0.70603681,\n",
      "       0.70649513, 0.77560681, 0.74591071, 0.77615908, 0.77533747])] \n",
      "\n",
      "mean AUC :  0.7539636946837046\n",
      "All std:  [array([0.02012871, 0.02043662, 0.01850297, 0.01990228, 0.0057871 ,\n",
      "       0.02426343, 0.02027343, 0.01927852, 0.01739944, 0.01989408,\n",
      "       0.00930035, 0.01815044, 0.02248137, 0.01269505, 0.01710907,\n",
      "       0.01689465, 0.018704  , 0.01966466, 0.01871471, 0.0153369 ,\n",
      "       0.00583326, 0.02063341, 0.01966392, 0.02900019, 0.01872807,\n",
      "       0.0144112 , 0.01993175, 0.01904955, 0.01793021, 0.00820428,\n",
      "       0.0202505 , 0.01949223, 0.01825298, 0.01884658, 0.0288876 ,\n",
      "       0.01966608, 0.01938102, 0.01881154, 0.02035777, 0.02007388,\n",
      "       0.01154821, 0.0207401 , 0.01904005, 0.02007123, 0.02607809,\n",
      "       0.01868012, 0.01768223, 0.01679036, 0.02000097, 0.01830164,\n",
      "       0.02572873, 0.01835092, 0.0196531 , 0.01840031, 0.0157901 ,\n",
      "       0.02032266, 0.01674823, 0.02307356, 0.01341871, 0.02926997,\n",
      "       0.01950693, 0.01807251, 0.01700267, 0.02176963, 0.01717721,\n",
      "       0.01892958, 0.01955831, 0.01856649, 0.02503688, 0.01719343,\n",
      "       0.0190959 , 0.01914744, 0.02301427, 0.02684832, 0.00454355,\n",
      "       0.03344255, 0.01865382, 0.01468378, 0.01961928, 0.01311756,\n",
      "       0.01869242, 0.01781297, 0.01871018, 0.0195526 , 0.02026992,\n",
      "       0.01882165, 0.01829245, 0.02328976, 0.02485537, 0.01914033,\n",
      "       0.03549881, 0.01770144, 0.01997227, 0.02091757, 0.03475569,\n",
      "       0.02026238, 0.01873354, 0.01954225, 0.01917666, 0.01849359,\n",
      "       0.01855542, 0.01872104, 0.01854464, 0.01597397, 0.01711407,\n",
      "       0.01492003, 0.01730448, 0.03238064, 0.02099461, 0.01876195,\n",
      "       0.01812316, 0.01351175, 0.02048053, 0.0197517 , 0.01538325,\n",
      "       0.01655668, 0.02048583, 0.01686499, 0.01804615, 0.01177168,\n",
      "       0.02237299, 0.01841076, 0.01990211, 0.02091701, 0.0176506 ,\n",
      "       0.06569643, 0.02273189, 0.01919572, 0.01217764, 0.02798707,\n",
      "       0.0243932 , 0.0199752 , 0.01893502, 0.01881258, 0.01879692,\n",
      "       0.00642873, 0.01396869, 0.02409167, 0.01086655, 0.01884517,\n",
      "       0.04078095, 0.0157101 , 0.02141287, 0.00685438, 0.0098588 ,\n",
      "       0.01886622, 0.01836178, 0.0269706 , 0.01932565, 0.02960794,\n",
      "       0.02007505, 0.01463046, 0.01852865, 0.01342029, 0.01403996,\n",
      "       0.01912776, 0.02059421, 0.01827443, 0.01589603, 0.01332503,\n",
      "       0.01915917, 0.02572079, 0.01986699, 0.01272258, 0.01884882,\n",
      "       0.01748778, 0.02163671, 0.01762957, 0.02177259, 0.0181817 ,\n",
      "       0.01798032, 0.02513647, 0.01908072, 0.02473741, 0.01830738,\n",
      "       0.02028644, 0.01836767, 0.01589056, 0.01298196, 0.02018959,\n",
      "       0.01361137, 0.01221843, 0.01838495, 0.01420778, 0.01076797,\n",
      "       0.0175387 , 0.01915434, 0.01241293, 0.0194011 , 0.02105338,\n",
      "       0.02471088, 0.02128852, 0.02535438, 0.01873496, 0.01432839,\n",
      "       0.01523939, 0.01602173, 0.02085368, 0.01952399, 0.01804114])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 24, 'min_data_in_leaf': 100, 'max_depth': 37, 'learning_rate': 0.029817722900196717, 'bagging_fraction': 0.19090909090909092} \n",
      "\n",
      "Best index/iterasi :  86\n",
      "Best AUC : 0.7791481309131291 ( std: 0.018292453228001538 ) \n",
      "\n",
      "running time:  202.65778279304504  detik. Dalam menit:  3.3776297132174173  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Seed:  32 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76491661, 0.77507211, 0.7696629 , 0.77130965, 0.76362203,\n",
      "       0.69407957, 0.75270135, 0.77268506, 0.77152214, 0.77263497,\n",
      "       0.77734752, 0.76972708, 0.71796837, 0.76202709, 0.76234901,\n",
      "       0.64130305, 0.72482218, 0.76838292, 0.67765337, 0.76494347,\n",
      "       0.76906133, 0.77006132, 0.77143897, 0.69255548, 0.74432301,\n",
      "       0.71581532, 0.77541062, 0.76900116, 0.7674574 , 0.77119146,\n",
      "       0.7563347 , 0.73051658, 0.77790986, 0.77523426, 0.76937471,\n",
      "       0.74477823, 0.66241159, 0.77756778, 0.76929915, 0.77311788,\n",
      "       0.77648979, 0.71505966, 0.75798959, 0.76481338, 0.76563793,\n",
      "       0.77312612, 0.77368056, 0.75026482, 0.72961382, 0.77570477,\n",
      "       0.77365337, 0.7021915 , 0.77246396, 0.68197849, 0.73393808,\n",
      "       0.73185167, 0.77601789, 0.72088607, 0.69452225, 0.77305306,\n",
      "       0.75347536, 0.7622984 , 0.77057213, 0.70724739, 0.76910134,\n",
      "       0.77363491, 0.77282174, 0.73960506, 0.73268933, 0.77100443,\n",
      "       0.77216223, 0.77003905, 0.77515854, 0.71195217, 0.7444436 ,\n",
      "       0.77240925, 0.75661034, 0.77659491, 0.7769338 , 0.68761889,\n",
      "       0.7210806 , 0.773324  , 0.73391231, 0.77571979, 0.7545573 ,\n",
      "       0.76833294, 0.77562821, 0.77294716, 0.77010344, 0.76887774,\n",
      "       0.77498628, 0.71469312, 0.77218822, 0.675552  , 0.73261462,\n",
      "       0.7708357 , 0.75450737, 0.76062033, 0.71363521, 0.74869155,\n",
      "       0.76732002, 0.69640942, 0.70504279, 0.66227331, 0.74179889,\n",
      "       0.74220068, 0.65517021, 0.77748702, 0.72419714, 0.70800319,\n",
      "       0.77052946, 0.71724312, 0.70316266, 0.77425609, 0.67941881,\n",
      "       0.75696163, 0.76519967, 0.76047032, 0.772049  , 0.73349921,\n",
      "       0.6750996 , 0.77340054, 0.7758735 , 0.76386194, 0.76758145,\n",
      "       0.77560419, 0.77012197, 0.76567492, 0.70929435, 0.76540442,\n",
      "       0.77065625, 0.73259863, 0.71469367, 0.68156069, 0.77475224,\n",
      "       0.77588475, 0.76864836, 0.73452957, 0.76625961, 0.77203436,\n",
      "       0.77685802, 0.71613396, 0.67127922, 0.75383681, 0.77041276,\n",
      "       0.73213678, 0.77027291, 0.70148288, 0.76884632, 0.77304073,\n",
      "       0.77027716, 0.76477652, 0.72410246, 0.763452  , 0.77611754,\n",
      "       0.68542001, 0.76595069, 0.7710519 , 0.72545086, 0.77136909,\n",
      "       0.74709863, 0.77387427, 0.76906963, 0.77049232, 0.75491275,\n",
      "       0.72086005, 0.76773727, 0.74268238, 0.7757371 , 0.72522427,\n",
      "       0.72326104, 0.7641632 , 0.77195282, 0.7663073 , 0.77389565,\n",
      "       0.74675047, 0.76753337, 0.77489554, 0.77135566, 0.77341275,\n",
      "       0.71086689, 0.7756024 , 0.72260471, 0.76751139, 0.77420827,\n",
      "       0.77319346, 0.76452681, 0.77475027, 0.77206337, 0.77158381,\n",
      "       0.77505622, 0.73186701, 0.77582963, 0.76789581, 0.77511386,\n",
      "       0.77463768, 0.76830035, 0.71477818, 0.7501045 , 0.72620008])] \n",
      "\n",
      "mean AUC :  0.7503805811228613\n",
      "All std:  [array([0.0112237 , 0.01896719, 0.01090785, 0.01437878, 0.01959858,\n",
      "       0.0235501 , 0.0156892 , 0.01724393, 0.01927537, 0.01788895,\n",
      "       0.01734669, 0.0182354 , 0.02935644, 0.01508111, 0.01353352,\n",
      "       0.04292983, 0.02699178, 0.01845536, 0.02500694, 0.02143166,\n",
      "       0.01070675, 0.0194342 , 0.0188447 , 0.03883652, 0.02013893,\n",
      "       0.02924647, 0.01822543, 0.01805091, 0.01194261, 0.02008157,\n",
      "       0.01165846, 0.02154229, 0.01950073, 0.01935203, 0.01914377,\n",
      "       0.01632205, 0.04016261, 0.0191433 , 0.02034123, 0.01722373,\n",
      "       0.01906845, 0.02122732, 0.00968345, 0.01370599, 0.01864134,\n",
      "       0.0166311 , 0.01775842, 0.02311216, 0.01404936, 0.01712702,\n",
      "       0.01267678, 0.02240316, 0.01602625, 0.03295156, 0.02524903,\n",
      "       0.02146487, 0.01831968, 0.02189309, 0.03075235, 0.01904982,\n",
      "       0.01957185, 0.01420697, 0.01877829, 0.02522876, 0.01959083,\n",
      "       0.01742386, 0.01799623, 0.02582612, 0.0317418 , 0.02057587,\n",
      "       0.01792446, 0.02015438, 0.01797844, 0.02522604, 0.01654409,\n",
      "       0.01952931, 0.00707462, 0.01756304, 0.01718767, 0.01804035,\n",
      "       0.02691545, 0.01599579, 0.01224659, 0.0174832 , 0.00550683,\n",
      "       0.01262252, 0.01963565, 0.01828123, 0.02017043, 0.01080794,\n",
      "       0.01751645, 0.01570102, 0.01707289, 0.0342873 , 0.0231941 ,\n",
      "       0.01873351, 0.00857562, 0.01361331, 0.02027434, 0.01506473,\n",
      "       0.02054245, 0.03077122, 0.01447343, 0.03387323, 0.0160167 ,\n",
      "       0.01756792, 0.03675025, 0.01884046, 0.01434732, 0.0215921 ,\n",
      "       0.01986459, 0.02347781, 0.03399347, 0.0181009 , 0.02719241,\n",
      "       0.01873408, 0.0174575 , 0.01080755, 0.0194244 , 0.03356893,\n",
      "       0.01625456, 0.01812807, 0.01896065, 0.01411726, 0.01964289,\n",
      "       0.01839788, 0.01046109, 0.02038895, 0.01882987, 0.01812046,\n",
      "       0.01057585, 0.01305639, 0.02483115, 0.03166992, 0.01963357,\n",
      "       0.01549224, 0.01987315, 0.02178276, 0.01016235, 0.01774683,\n",
      "       0.01817797, 0.02477798, 0.02105987, 0.01738684, 0.01916802,\n",
      "       0.01939232, 0.02083014, 0.01585686, 0.01952422, 0.01909341,\n",
      "       0.01966062, 0.00918394, 0.0252205 , 0.00724471, 0.01901267,\n",
      "       0.04541678, 0.01964298, 0.02042775, 0.02125363, 0.01816793,\n",
      "       0.01964909, 0.01621929, 0.01886446, 0.01841906, 0.01279219,\n",
      "       0.02487138, 0.01890433, 0.02036281, 0.01847704, 0.01625087,\n",
      "       0.0297742 , 0.00978942, 0.02166956, 0.01987816, 0.01705615,\n",
      "       0.01696049, 0.01855486, 0.01374277, 0.01930243, 0.01681935,\n",
      "       0.02471741, 0.01782979, 0.02334463, 0.02075732, 0.01762827,\n",
      "       0.01894359, 0.01882694, 0.01365716, 0.01880804, 0.01859293,\n",
      "       0.01852687, 0.02841967, 0.01516201, 0.02068091, 0.01813127,\n",
      "       0.0189139 , 0.01896794, 0.02774407, 0.01117188, 0.02485255])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 44, 'min_data_in_leaf': 100, 'max_depth': 14, 'learning_rate': 0.011483124145435111, 'bagging_fraction': 0.9272727272727272} \n",
      "\n",
      "Best index/iterasi :  32\n",
      "Best AUC : 0.777909864686191 ( std: 0.019500728800675392 ) \n",
      "\n",
      "running time:  199.42239475250244  detik. Dalam menit:  3.323706579208374  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  42 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76596267, 0.71235718, 0.76656576, 0.77463361, 0.77552361,\n",
      "       0.71952116, 0.77718633, 0.77038799, 0.77338579, 0.75367876,\n",
      "       0.77379696, 0.72778409, 0.76898837, 0.75607426, 0.66364967,\n",
      "       0.74484165, 0.70612361, 0.68045017, 0.7382129 , 0.77214345,\n",
      "       0.76764644, 0.77794899, 0.76997633, 0.74726138, 0.76937515,\n",
      "       0.6972187 , 0.77721466, 0.73477085, 0.77585844, 0.7737903 ,\n",
      "       0.70771231, 0.7740583 , 0.76770107, 0.75405083, 0.7331976 ,\n",
      "       0.75011143, 0.76957632, 0.77427934, 0.76222209, 0.73640627,\n",
      "       0.77074661, 0.73629278, 0.76829969, 0.77391564, 0.72736618,\n",
      "       0.76834627, 0.7738557 , 0.71347542, 0.77248789, 0.76727655,\n",
      "       0.77505658, 0.77118131, 0.6810872 , 0.7724101 , 0.7114067 ,\n",
      "       0.76684018, 0.76809099, 0.77257599, 0.76544272, 0.77225423,\n",
      "       0.76949758, 0.75737296, 0.77241894, 0.77295976, 0.72854663,\n",
      "       0.77914473, 0.77388224, 0.776012  , 0.77494839, 0.77053841,\n",
      "       0.75177249, 0.7751422 , 0.76012479, 0.74758107, 0.77675004,\n",
      "       0.77049988, 0.7740868 , 0.76468861, 0.75602901, 0.76694322,\n",
      "       0.73860621, 0.7715773 , 0.73497662, 0.75398922, 0.77640852,\n",
      "       0.7726028 , 0.77235668, 0.77097165, 0.7591524 , 0.76820126,\n",
      "       0.77259522, 0.77066578, 0.77024598, 0.68131106, 0.75390351,\n",
      "       0.72329342, 0.74320465, 0.71674926, 0.77073625, 0.77407388,\n",
      "       0.77349139, 0.73631965, 0.77099722, 0.75891473, 0.77547984,\n",
      "       0.76634814, 0.67993811, 0.77127165, 0.77550213, 0.77023004,\n",
      "       0.76783645, 0.69061202, 0.77400341, 0.76138428, 0.76735595,\n",
      "       0.76750294, 0.73492008, 0.7095399 , 0.77496832, 0.77526814,\n",
      "       0.7759388 , 0.77039407, 0.77164921, 0.71648663, 0.76730371,\n",
      "       0.7680518 , 0.77708846, 0.77390486, 0.77249461, 0.77841679,\n",
      "       0.76775231, 0.77107805, 0.74478375, 0.72446693, 0.77077869,\n",
      "       0.74885028, 0.72949897, 0.73107368, 0.77315308, 0.77328087,\n",
      "       0.76863608, 0.76481319, 0.77636732, 0.76105924, 0.76730657,\n",
      "       0.77309886, 0.77110667, 0.76191973, 0.73755135, 0.69210127,\n",
      "       0.75596346, 0.77663024, 0.69198383, 0.77218432, 0.77168368,\n",
      "       0.69327716, 0.7665874 , 0.67692554, 0.73997874, 0.76747309,\n",
      "       0.73869125, 0.77314029, 0.75637196, 0.70091774, 0.77595837,\n",
      "       0.76995887, 0.77295622, 0.76984278, 0.77054751, 0.77369151,\n",
      "       0.77600469, 0.66914548, 0.77434052, 0.76025715, 0.75080872,\n",
      "       0.76001723, 0.77298625, 0.75954393, 0.75601458, 0.76464868,\n",
      "       0.76978877, 0.76898351, 0.7715331 , 0.70944881, 0.6875768 ,\n",
      "       0.76319468, 0.70513138, 0.74401876, 0.77499094, 0.76937402,\n",
      "       0.77296129, 0.76529717, 0.75005162, 0.77567596, 0.77063106,\n",
      "       0.77279063, 0.76379494, 0.74010253, 0.73262381, 0.76940815])] \n",
      "\n",
      "mean AUC :  0.7555140713957457\n",
      "All std:  [array([0.01980475, 0.0216553 , 0.02016289, 0.01710673, 0.01801204,\n",
      "       0.01971482, 0.01885539, 0.01992525, 0.01964821, 0.00894192,\n",
      "       0.0193899 , 0.02787693, 0.01938144, 0.01453548, 0.05744544,\n",
      "       0.01724877, 0.02102087, 0.01561238, 0.02406193, 0.01320243,\n",
      "       0.01970277, 0.01797587, 0.01989267, 0.00747309, 0.01960647,\n",
      "       0.03375652, 0.01754818, 0.02465144, 0.01851185, 0.01957753,\n",
      "       0.01648252, 0.01899161, 0.02054458, 0.00968939, 0.0288505 ,\n",
      "       0.00690232, 0.01951045, 0.01915747, 0.00991604, 0.03581825,\n",
      "       0.01910857, 0.02364372, 0.02072313, 0.01901434, 0.02429429,\n",
      "       0.01879214, 0.02022825, 0.02102072, 0.02109459, 0.01862107,\n",
      "       0.01851142, 0.01995277, 0.04174715, 0.01909015, 0.02637992,\n",
      "       0.01762017, 0.01950896, 0.02143147, 0.01878068, 0.01948688,\n",
      "       0.01950752, 0.00485046, 0.01893138, 0.01750333, 0.02773737,\n",
      "       0.0185173 , 0.01948544, 0.01736558, 0.01590733, 0.01931712,\n",
      "       0.00680889, 0.01538183, 0.00715893, 0.00855407, 0.01898465,\n",
      "       0.01895275, 0.02144728, 0.01083078, 0.01781303, 0.01924624,\n",
      "       0.02385012, 0.01613062, 0.02219798, 0.00882291, 0.01926485,\n",
      "       0.01774419, 0.01899809, 0.01973066, 0.00812769, 0.01994988,\n",
      "       0.01938874, 0.01837705, 0.01970442, 0.04455777, 0.02421042,\n",
      "       0.02279973, 0.02077344, 0.02800216, 0.02091836, 0.01849934,\n",
      "       0.018224  , 0.03214047, 0.01878304, 0.0152154 , 0.01900512,\n",
      "       0.01451499, 0.03589745, 0.01842085, 0.01945076, 0.02116518,\n",
      "       0.01122405, 0.0297993 , 0.01774291, 0.01978532, 0.02120519,\n",
      "       0.01296056, 0.02358963, 0.02340479, 0.01899037, 0.01845811,\n",
      "       0.01914905, 0.01524824, 0.01986772, 0.02191332, 0.01729706,\n",
      "       0.01925898, 0.01652642, 0.01772202, 0.01759931, 0.01663437,\n",
      "       0.02043909, 0.02114302, 0.02347052, 0.02433849, 0.01526256,\n",
      "       0.01298427, 0.01681592, 0.01752037, 0.01651086, 0.01885484,\n",
      "       0.02217441, 0.01276291, 0.01646071, 0.01356709, 0.01933067,\n",
      "       0.01851649, 0.01760393, 0.01818444, 0.02099511, 0.00983354,\n",
      "       0.0073385 , 0.01920336, 0.0202748 , 0.0198433 , 0.01871161,\n",
      "       0.01270899, 0.0166067 , 0.02518122, 0.02245261, 0.01870861,\n",
      "       0.02424814, 0.01846973, 0.00433512, 0.01923197, 0.01931628,\n",
      "       0.01988   , 0.02076002, 0.01960527, 0.01987621, 0.0177751 ,\n",
      "       0.01860136, 0.01866703, 0.01908481, 0.01185061, 0.02293197,\n",
      "       0.00603369, 0.01746805, 0.02328873, 0.01449728, 0.00982793,\n",
      "       0.0196468 , 0.01991749, 0.02114726, 0.02370005, 0.0415776 ,\n",
      "       0.0206246 , 0.01709469, 0.02008309, 0.01737761, 0.01994354,\n",
      "       0.02003128, 0.00927661, 0.01183547, 0.01760784, 0.01876773,\n",
      "       0.01905507, 0.02034982, 0.01558453, 0.02269122, 0.02079122])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 29, 'min_data_in_leaf': 98, 'max_depth': 21, 'learning_rate': 0.024911300260677886, 'bagging_fraction': 0.3090909090909091} \n",
      "\n",
      "Best index/iterasi :  65\n",
      "Best AUC : 0.7791447268608324 ( std: 0.018517295900973 ) \n",
      "\n",
      "running time:  208.34057641029358  detik. Dalam menit:  3.4723429401715595  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Seed:  52 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.75265439, 0.67960739, 0.77466573, 0.77487328, 0.76951923,\n",
      "       0.73221258, 0.77640225, 0.7730971 , 0.76693312, 0.73764156,\n",
      "       0.75353388, 0.77042527, 0.67998609, 0.74914961, 0.75791666,\n",
      "       0.7764984 , 0.70936877, 0.76228204, 0.74039428, 0.76243724,\n",
      "       0.70432874, 0.77486231, 0.75980803, 0.70425948, 0.77009832,\n",
      "       0.74484513, 0.70139975, 0.6844684 , 0.77261337, 0.76893377,\n",
      "       0.72987101, 0.76699044, 0.77342547, 0.76941293, 0.74802532,\n",
      "       0.71110856, 0.7696151 , 0.76479858, 0.77620507, 0.77463667,\n",
      "       0.76917509, 0.70032538, 0.77538919, 0.73429938, 0.76788134,\n",
      "       0.77393426, 0.76308779, 0.75504595, 0.7677256 , 0.76153599,\n",
      "       0.72735502, 0.71812511, 0.68440341, 0.72114938, 0.7741846 ,\n",
      "       0.74264583, 0.77609931, 0.74243143, 0.77360923, 0.77386771,\n",
      "       0.685094  , 0.69264927, 0.76688127, 0.67092151, 0.77503606,\n",
      "       0.7252806 , 0.71086987, 0.77076507, 0.77515417, 0.73592683,\n",
      "       0.71279564, 0.76840193, 0.68185102, 0.6708924 , 0.77475436,\n",
      "       0.7744213 , 0.77372947, 0.77081426, 0.76901431, 0.77161944,\n",
      "       0.77146733, 0.72672761, 0.73301983, 0.70634275, 0.76238836,\n",
      "       0.76470972, 0.76399153, 0.70801231, 0.72545844, 0.76343614,\n",
      "       0.7744109 , 0.77108066, 0.75393382, 0.74371023, 0.76924688,\n",
      "       0.77258018, 0.77271242, 0.75908369, 0.75436917, 0.76464472,\n",
      "       0.69324082, 0.69056242, 0.77541816, 0.76981751, 0.77657767,\n",
      "       0.76082354, 0.77152707, 0.76945236, 0.73052171, 0.7671899 ,\n",
      "       0.77435215, 0.77047111, 0.77555472, 0.77431346, 0.72985141,\n",
      "       0.73088119, 0.77091538, 0.7728116 , 0.76965233, 0.77529674,\n",
      "       0.75267518, 0.76960024, 0.7718406 , 0.77046124, 0.69025088,\n",
      "       0.77686027, 0.76764189, 0.7703347 , 0.77239444, 0.76224059,\n",
      "       0.75034135, 0.76908171, 0.75720566, 0.77068055, 0.77080649,\n",
      "       0.76098872, 0.70449098, 0.77561646, 0.75317432, 0.77254374,\n",
      "       0.76945483, 0.76006751, 0.77080765, 0.76951333, 0.766709  ,\n",
      "       0.76788476, 0.69900883, 0.75103276, 0.77070062, 0.76162081,\n",
      "       0.77436073, 0.6875651 , 0.76581194, 0.77307131, 0.71075745,\n",
      "       0.77043783, 0.7683275 , 0.74976851, 0.76845887, 0.76602332,\n",
      "       0.77315703, 0.77016797, 0.76429817, 0.77458477, 0.67763989,\n",
      "       0.69899529, 0.77003945, 0.77112318, 0.71324694, 0.7731973 ,\n",
      "       0.74868465, 0.77222756, 0.76230115, 0.75022519, 0.76330116,\n",
      "       0.7101519 , 0.77378297, 0.76913331, 0.7734523 , 0.70750498,\n",
      "       0.76522345, 0.77233542, 0.71995311, 0.74898399, 0.72565651,\n",
      "       0.76883926, 0.69333739, 0.77117029, 0.6867134 , 0.7724834 ,\n",
      "       0.77470961, 0.70002533, 0.68402852, 0.76753366, 0.774335  ,\n",
      "       0.74499303, 0.77443559, 0.70475327, 0.76953272, 0.73242126])] \n",
      "\n",
      "mean AUC :  0.7506914956366789\n",
      "All std:  [array([0.0081079 , 0.02989099, 0.01783319, 0.01921615, 0.0196004 ,\n",
      "       0.0212486 , 0.01606976, 0.01843745, 0.01176285, 0.01509733,\n",
      "       0.0229834 , 0.02013426, 0.01158335, 0.02275902, 0.00495985,\n",
      "       0.01936429, 0.01434085, 0.01928377, 0.02080786, 0.00736272,\n",
      "       0.02800505, 0.01909243, 0.01053524, 0.01727896, 0.01887535,\n",
      "       0.02211509, 0.02894066, 0.02678086, 0.01793524, 0.01846736,\n",
      "       0.02387535, 0.01953766, 0.01950741, 0.0214156 , 0.00702027,\n",
      "       0.02249386, 0.01971221, 0.01047979, 0.01720906, 0.01751451,\n",
      "       0.01043423, 0.02510475, 0.01773232, 0.01367143, 0.01851167,\n",
      "       0.01870449, 0.01895349, 0.01417841, 0.02148532, 0.01973718,\n",
      "       0.0178299 , 0.03997162, 0.02804667, 0.0226575 , 0.01864089,\n",
      "       0.02226657, 0.01880772, 0.01295555, 0.0192824 , 0.01890323,\n",
      "       0.03634931, 0.02520401, 0.01889992, 0.03511999, 0.01886142,\n",
      "       0.02646353, 0.0323169 , 0.01919407, 0.01911421, 0.02784816,\n",
      "       0.03037417, 0.01895967, 0.01881491, 0.03400434, 0.02085514,\n",
      "       0.01916658, 0.01787094, 0.01936955, 0.02018006, 0.01134434,\n",
      "       0.0200496 , 0.02194274, 0.03544968, 0.02099171, 0.01025421,\n",
      "       0.014443  , 0.01732603, 0.01824966, 0.02510054, 0.02095666,\n",
      "       0.01881604, 0.01772114, 0.01591505, 0.01527106, 0.02017476,\n",
      "       0.01793826, 0.0196052 , 0.0124773 , 0.01083518, 0.02128968,\n",
      "       0.01816   , 0.01745244, 0.01920382, 0.01772719, 0.0182542 ,\n",
      "       0.01469574, 0.01813616, 0.02006535, 0.02682991, 0.01997304,\n",
      "       0.0170227 , 0.02099568, 0.0189595 , 0.01571408, 0.02178724,\n",
      "       0.04162714, 0.01920812, 0.01946708, 0.02006965, 0.01879544,\n",
      "       0.00923418, 0.01949179, 0.01980466, 0.02052461, 0.02117505,\n",
      "       0.0173622 , 0.01693875, 0.01807547, 0.01970652, 0.00773973,\n",
      "       0.01391213, 0.01960342, 0.02005365, 0.02010444, 0.01678112,\n",
      "       0.01124039, 0.02333684, 0.01977385, 0.01655324, 0.01985325,\n",
      "       0.0194687 , 0.00650693, 0.01272593, 0.01770843, 0.01982608,\n",
      "       0.01961531, 0.01314826, 0.01478185, 0.02008543, 0.00912427,\n",
      "       0.01909096, 0.03419681, 0.01964424, 0.01924143, 0.03414016,\n",
      "       0.01971334, 0.01431191, 0.01472102, 0.01747423, 0.01268539,\n",
      "       0.0135712 , 0.02061739, 0.02210572, 0.01858534, 0.02300697,\n",
      "       0.02875542, 0.02026028, 0.01824574, 0.0255906 , 0.01249807,\n",
      "       0.00874151, 0.01787377, 0.00881649, 0.00653318, 0.01903054,\n",
      "       0.01964782, 0.01877539, 0.0201838 , 0.01717729, 0.02174885,\n",
      "       0.01914607, 0.01903447, 0.02220322, 0.02436666, 0.0260016 ,\n",
      "       0.01784244, 0.00987162, 0.02080057, 0.03235474, 0.02031464,\n",
      "       0.01880505, 0.03158943, 0.02592049, 0.0194069 , 0.01952594,\n",
      "       0.02150061, 0.01885368, 0.02649124, 0.02024201, 0.02169209])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 53, 'min_data_in_leaf': 83, 'max_depth': 98, 'learning_rate': 0.02052637752709252, 'bagging_fraction': 0.22727272727272727} \n",
      "\n",
      "Best index/iterasi :  125\n",
      "Best AUC : 0.7768602677338567 ( std: 0.017362203891272212 ) \n",
      "\n",
      "running time:  203.17834520339966  detik. Dalam menit:  3.3863057533899945  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  62 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.77258255, 0.77776953, 0.72483662, 0.7727801 , 0.76869574,\n",
      "       0.67787952, 0.77149916, 0.76941512, 0.77032192, 0.68840177,\n",
      "       0.77057641, 0.68585852, 0.68892817, 0.76756097, 0.77468182,\n",
      "       0.68827345, 0.65523739, 0.77238623, 0.7731682 , 0.7733588 ,\n",
      "       0.73638133, 0.7711863 , 0.77577854, 0.74042471, 0.77363008,\n",
      "       0.77005458, 0.76880128, 0.72787148, 0.77481811, 0.7746909 ,\n",
      "       0.76799155, 0.76960333, 0.76822675, 0.77242528, 0.76851783,\n",
      "       0.76909259, 0.77460801, 0.7381478 , 0.77488041, 0.76767595,\n",
      "       0.68584532, 0.76742268, 0.77319961, 0.66265491, 0.77478471,\n",
      "       0.70802872, 0.73227931, 0.76302891, 0.71305818, 0.66420401,\n",
      "       0.76711241, 0.77306247, 0.77317105, 0.71969604, 0.7214344 ,\n",
      "       0.73525247, 0.75530045, 0.70435067, 0.77119422, 0.70950891,\n",
      "       0.69156379, 0.71067668, 0.71745   , 0.7682782 , 0.74511828,\n",
      "       0.77471505, 0.711689  , 0.77583765, 0.77599533, 0.76983469,\n",
      "       0.70646598, 0.77660835, 0.77387665, 0.77759264, 0.7596642 ,\n",
      "       0.74079278, 0.74272787, 0.68238274, 0.7728143 , 0.7653276 ,\n",
      "       0.76432426, 0.74380898, 0.70139276, 0.71041056, 0.7746676 ,\n",
      "       0.77276413, 0.76195409, 0.76884071, 0.76997144, 0.77447017,\n",
      "       0.77471018, 0.68561244, 0.72884534, 0.77489679, 0.69058249,\n",
      "       0.76975138, 0.77285475, 0.77296108, 0.76127937, 0.77164218,\n",
      "       0.77558905, 0.73778141, 0.69035345, 0.77586985, 0.77074931,\n",
      "       0.77232706, 0.76643539, 0.7412972 , 0.77102337, 0.74221709,\n",
      "       0.70656177, 0.75509625, 0.77336676, 0.76851445, 0.73111587,\n",
      "       0.77278904, 0.77472457, 0.77052984, 0.76855467, 0.77455294,\n",
      "       0.75360457, 0.77169101, 0.76806616, 0.69029775, 0.77033422,\n",
      "       0.77351949, 0.76961635, 0.76711387, 0.75588754, 0.76968698,\n",
      "       0.7236749 , 0.77735724, 0.77343729, 0.73444436, 0.76915219,\n",
      "       0.77229386, 0.77476716, 0.75051471, 0.77545695, 0.76763922,\n",
      "       0.75583571, 0.71571509, 0.67238759, 0.77276541, 0.72760352,\n",
      "       0.77321416, 0.77096092, 0.77574958, 0.77261648, 0.75199214,\n",
      "       0.74072162, 0.76773698, 0.77418425, 0.70674042, 0.77645758,\n",
      "       0.77692567, 0.7072468 , 0.6911869 , 0.77666488, 0.76942941,\n",
      "       0.76670992, 0.7664731 , 0.76799862, 0.7728366 , 0.68386983,\n",
      "       0.76971126, 0.69792925, 0.7708622 , 0.73950977, 0.76799456,\n",
      "       0.77541108, 0.77681225, 0.7654757 , 0.71445218, 0.7710076 ,\n",
      "       0.74802603, 0.77044862, 0.76999346, 0.77233176, 0.75309538,\n",
      "       0.70858586, 0.74624738, 0.74840935, 0.76919699, 0.77518469,\n",
      "       0.76397942, 0.77053006, 0.76609429, 0.76315748, 0.67278922,\n",
      "       0.67291566, 0.77485612, 0.7321584 , 0.72464136, 0.754247  ,\n",
      "       0.77110511, 0.76958079, 0.74036988, 0.67227811, 0.77665008])] \n",
      "\n",
      "mean AUC :  0.7505341371277503\n",
      "All std:  [array([0.01247778, 0.01785655, 0.02932298, 0.0158249 , 0.01920304,\n",
      "       0.03498436, 0.01839118, 0.01827358, 0.01978639, 0.02643209,\n",
      "       0.02096407, 0.01758573, 0.02024115, 0.01377508, 0.01831724,\n",
      "       0.01049758, 0.03181306, 0.01758585, 0.01889607, 0.01963466,\n",
      "       0.028881  , 0.01773452, 0.01839281, 0.01874145, 0.01878201,\n",
      "       0.01891546, 0.01800137, 0.01888237, 0.01968917, 0.01668523,\n",
      "       0.02089399, 0.02008035, 0.01917377, 0.01880509, 0.00965202,\n",
      "       0.02027635, 0.01865939, 0.03049631, 0.01808049, 0.01810076,\n",
      "       0.03674705, 0.01761493, 0.0183749 , 0.03367285, 0.01461069,\n",
      "       0.0250505 , 0.01336687, 0.01470095, 0.01472664, 0.03678903,\n",
      "       0.02031331, 0.01626221, 0.01846655, 0.02078147, 0.01957483,\n",
      "       0.01474907, 0.01114981, 0.03706242, 0.01789971, 0.02072443,\n",
      "       0.01514612, 0.01239744, 0.0163624 , 0.02094249, 0.02052342,\n",
      "       0.01754709, 0.02523572, 0.01932617, 0.01922727, 0.01656613,\n",
      "       0.01768097, 0.01915616, 0.01338051, 0.01754541, 0.01622123,\n",
      "       0.02044731, 0.01444145, 0.02936986, 0.01877972, 0.02052637,\n",
      "       0.0090864 , 0.01503078, 0.02090143, 0.0148382 , 0.01952724,\n",
      "       0.01781169, 0.0152597 , 0.01978439, 0.02012111, 0.01894773,\n",
      "       0.01891225, 0.0170836 , 0.01931641, 0.01902498, 0.01746733,\n",
      "       0.02168511, 0.01324953, 0.0187192 , 0.02026996, 0.02172912,\n",
      "       0.01589565, 0.01693456, 0.02275574, 0.01895184, 0.01609179,\n",
      "       0.01222412, 0.01963125, 0.01993403, 0.01142185, 0.01436525,\n",
      "       0.01600994, 0.01777515, 0.01850642, 0.01383323, 0.02213522,\n",
      "       0.01971413, 0.01678731, 0.01988372, 0.01922054, 0.01893183,\n",
      "       0.02271139, 0.0221138 , 0.01887709, 0.02363782, 0.01863969,\n",
      "       0.01939103, 0.01771464, 0.01668999, 0.00622565, 0.02056608,\n",
      "       0.02864541, 0.01941464, 0.01927318, 0.02078928, 0.01750273,\n",
      "       0.01995389, 0.01856377, 0.01357782, 0.01912836, 0.01914456,\n",
      "       0.01658014, 0.01537522, 0.01692721, 0.01271349, 0.02403683,\n",
      "       0.01684561, 0.01932967, 0.01845628, 0.01921078, 0.00783765,\n",
      "       0.03049533, 0.02003969, 0.01830818, 0.03468686, 0.0187407 ,\n",
      "       0.0187181 , 0.02381073, 0.03219434, 0.01774528, 0.0181241 ,\n",
      "       0.01474981, 0.01955253, 0.01952224, 0.01873952, 0.02253987,\n",
      "       0.01937482, 0.01699812, 0.01220141, 0.03529588, 0.01931157,\n",
      "       0.01702061, 0.01605233, 0.01811552, 0.01805817, 0.01901575,\n",
      "       0.00626922, 0.0192207 , 0.02025929, 0.01555448, 0.00969758,\n",
      "       0.03004826, 0.03952688, 0.02165786, 0.02215165, 0.01958795,\n",
      "       0.01020898, 0.01923542, 0.00924038, 0.01623193, 0.0572463 ,\n",
      "       0.04143742, 0.01754626, 0.02746653, 0.02869028, 0.01926986,\n",
      "       0.01888996, 0.00979265, 0.01767876, 0.02776499, 0.01727171])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 39, 'min_data_in_leaf': 97, 'max_depth': 22, 'learning_rate': 0.02081221569986338, 'bagging_fraction': 0.8454545454545453} \n",
      "\n",
      "Best index/iterasi :  1\n",
      "Best AUC : 0.7777695272939023 ( std: 0.01785655230719389 ) \n",
      "\n",
      "running time:  209.69974303245544  detik. Dalam menit:  3.494995717207591  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Seed:  72 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76791497, 0.68754018, 0.74757836, 0.77134198, 0.73734799,\n",
      "       0.77387055, 0.76995414, 0.77627027, 0.73185514, 0.69657325,\n",
      "       0.76411984, 0.77524769, 0.76536146, 0.77756482, 0.76786694,\n",
      "       0.77123191, 0.73658378, 0.77335092, 0.77089518, 0.70869796,\n",
      "       0.77311336, 0.7756657 , 0.76724247, 0.77108034, 0.70367344,\n",
      "       0.7417012 , 0.7141438 , 0.6804716 , 0.77213305, 0.74199702,\n",
      "       0.77252372, 0.66987006, 0.77014862, 0.7717111 , 0.77789671,\n",
      "       0.67403045, 0.76906087, 0.77394492, 0.74265236, 0.77096522,\n",
      "       0.73114702, 0.69625887, 0.76919899, 0.77544139, 0.72723097,\n",
      "       0.72362715, 0.77621898, 0.77300793, 0.74928992, 0.76738444,\n",
      "       0.77351416, 0.77309933, 0.77673002, 0.71599381, 0.7751397 ,\n",
      "       0.77493668, 0.69324712, 0.76566332, 0.77257902, 0.71469098,\n",
      "       0.69197417, 0.76335544, 0.77511938, 0.77211713, 0.67523994,\n",
      "       0.69338038, 0.69912115, 0.76941717, 0.70090506, 0.70591223,\n",
      "       0.71105746, 0.77596209, 0.77880751, 0.69466718, 0.77525845,\n",
      "       0.72234725, 0.76920004, 0.70253015, 0.76929433, 0.72635054,\n",
      "       0.69973652, 0.76556491, 0.6840032 , 0.736236  , 0.77595163,\n",
      "       0.77496879, 0.73944188, 0.68546854, 0.76854763, 0.76835182,\n",
      "       0.7022293 , 0.77091836, 0.73241392, 0.75847946, 0.77650663,\n",
      "       0.76974094, 0.71342037, 0.71908783, 0.77584236, 0.76784303,\n",
      "       0.73337412, 0.76720033, 0.68650656, 0.77392762, 0.69959332,\n",
      "       0.69355648, 0.76891244, 0.71113571, 0.74499863, 0.77025323,\n",
      "       0.77172661, 0.77158002, 0.77499255, 0.76555058, 0.77513339,\n",
      "       0.7746681 , 0.77611781, 0.76419822, 0.74715882, 0.69701167,\n",
      "       0.7478872 , 0.77253726, 0.76066377, 0.76380404, 0.7429861 ,\n",
      "       0.69914806, 0.7713554 , 0.76640551, 0.72601197, 0.76961756,\n",
      "       0.77433543, 0.77600377, 0.76998715, 0.71097966, 0.76770661,\n",
      "       0.77302849, 0.76922375, 0.76921903, 0.73069664, 0.77462285,\n",
      "       0.73342269, 0.76674803, 0.76009994, 0.72400586, 0.77143886,\n",
      "       0.73822332, 0.7735207 , 0.77072443, 0.67081519, 0.77406101,\n",
      "       0.77431885, 0.75950107, 0.69846908, 0.76820017, 0.77269916,\n",
      "       0.7702494 , 0.77573325, 0.76430354, 0.66866328, 0.77325344,\n",
      "       0.76521703, 0.7673006 , 0.77032946, 0.77123649, 0.76821444,\n",
      "       0.77203281, 0.77170132, 0.77641756, 0.74825635, 0.77546117,\n",
      "       0.75137429, 0.71185135, 0.77284037, 0.77453052, 0.77209014,\n",
      "       0.72233133, 0.7748952 , 0.68177829, 0.77552354, 0.77024858,\n",
      "       0.71603747, 0.77617943, 0.76736197, 0.71675168, 0.77585277,\n",
      "       0.7386241 , 0.71339164, 0.768986  , 0.77555264, 0.74772537,\n",
      "       0.75012098, 0.76551162, 0.77314996, 0.76653312, 0.77065612,\n",
      "       0.76988831, 0.7716765 , 0.71958576, 0.76899337, 0.76933203])] \n",
      "\n",
      "mean AUC :  0.7500708632213737\n",
      "All std:  [array([0.02050814, 0.02089429, 0.0178752 , 0.01994857, 0.02486388,\n",
      "       0.01965515, 0.020545  , 0.01808264, 0.01841905, 0.01844791,\n",
      "       0.01760765, 0.018104  , 0.0190918 , 0.01868006, 0.02034052,\n",
      "       0.02007546, 0.01353979, 0.01673717, 0.01944552, 0.01963198,\n",
      "       0.0180426 , 0.01732431, 0.01869412, 0.01187369, 0.02539735,\n",
      "       0.01836244, 0.03816227, 0.03116457, 0.01831665, 0.00968409,\n",
      "       0.01926592, 0.03354869, 0.01842086, 0.01892785, 0.01898403,\n",
      "       0.02036817, 0.02031923, 0.01972235, 0.02120376, 0.01875312,\n",
      "       0.02532564, 0.01402819, 0.01968824, 0.01871798, 0.02345271,\n",
      "       0.02793826, 0.01887135, 0.01763668, 0.01130039, 0.01926378,\n",
      "       0.02026262, 0.01530661, 0.01953099, 0.02259399, 0.01710307,\n",
      "       0.01881595, 0.02303116, 0.01948822, 0.01868133, 0.03043158,\n",
      "       0.02017903, 0.01884219, 0.01795147, 0.01885837, 0.02503648,\n",
      "       0.0401456 , 0.01928207, 0.01899302, 0.01570869, 0.02912511,\n",
      "       0.02461214, 0.01845827, 0.01833098, 0.02004309, 0.01546914,\n",
      "       0.02636064, 0.02012481, 0.01898958, 0.01794483, 0.0227689 ,\n",
      "       0.03505079, 0.01862709, 0.01764828, 0.01967597, 0.01798433,\n",
      "       0.01862099, 0.02868998, 0.02232005, 0.02051422, 0.02001237,\n",
      "       0.01720718, 0.01437524, 0.02724534, 0.00813139, 0.01862394,\n",
      "       0.02045947, 0.02122636, 0.02085381, 0.01632366, 0.0187765 ,\n",
      "       0.02136969, 0.01496693, 0.02076961, 0.01343182, 0.02017261,\n",
      "       0.03199556, 0.02207274, 0.02734967, 0.03362568, 0.01877232,\n",
      "       0.01826158, 0.01752445, 0.01589287, 0.01789791, 0.01700694,\n",
      "       0.01861466, 0.01564089, 0.01371958, 0.03522297, 0.02585723,\n",
      "       0.01973881, 0.01821859, 0.00785171, 0.00878231, 0.01450375,\n",
      "       0.03291326, 0.02062775, 0.01630637, 0.03617725, 0.02013906,\n",
      "       0.01577476, 0.01647125, 0.01973835, 0.01658388, 0.02005132,\n",
      "       0.01828821, 0.0189384 , 0.00951798, 0.02227953, 0.0142105 ,\n",
      "       0.03164879, 0.0202977 , 0.01474825, 0.02480071, 0.02018594,\n",
      "       0.02575587, 0.01919796, 0.01787411, 0.02003326, 0.01741962,\n",
      "       0.0196589 , 0.01566095, 0.01821659, 0.01934213, 0.01846186,\n",
      "       0.01895914, 0.01725646, 0.0096804 , 0.05347506, 0.01970751,\n",
      "       0.01602113, 0.0199356 , 0.019844  , 0.01917585, 0.01909374,\n",
      "       0.01899358, 0.01291677, 0.0196886 , 0.01573132, 0.01860292,\n",
      "       0.0239679 , 0.0255573 , 0.01974421, 0.01944762, 0.01978157,\n",
      "       0.0193788 , 0.01770027, 0.01357904, 0.01879597, 0.02087025,\n",
      "       0.01963612, 0.01871826, 0.01921862, 0.02596994, 0.01982813,\n",
      "       0.02011371, 0.03338314, 0.00975055, 0.01748316, 0.02698302,\n",
      "       0.008832  , 0.01544608, 0.01936482, 0.01973618, 0.01892841,\n",
      "       0.02028961, 0.01942874, 0.01951092, 0.01816725, 0.01973534])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 20, 'min_data_in_leaf': 100, 'max_depth': 18, 'learning_rate': 0.02614673211801092, 'bagging_fraction': 0.13636363636363635} \n",
      "\n",
      "Best index/iterasi :  72\n",
      "Best AUC : 0.7788075124111111 ( std: 0.018330984812829538 ) \n",
      "\n",
      "running time:  210.59356212615967  detik. Dalam menit:  3.509892702102661  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  82 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.75787286, 0.77079531, 0.77179278, 0.77420428, 0.76959614,\n",
      "       0.77729628, 0.72842517, 0.76821503, 0.73448356, 0.69232835,\n",
      "       0.77404712, 0.70001263, 0.76344504, 0.72496016, 0.7649878 ,\n",
      "       0.76997459, 0.77406471, 0.77475656, 0.76826343, 0.7725691 ,\n",
      "       0.7665762 , 0.77278979, 0.76951711, 0.77013534, 0.7697111 ,\n",
      "       0.76972978, 0.77146674, 0.73283159, 0.77813649, 0.77373428,\n",
      "       0.72811099, 0.73703337, 0.71530822, 0.76692284, 0.69729638,\n",
      "       0.77446563, 0.76561242, 0.77539544, 0.67390467, 0.77395107,\n",
      "       0.76977047, 0.7382644 , 0.77050822, 0.77511638, 0.76266776,\n",
      "       0.74999572, 0.73543411, 0.69497955, 0.76109188, 0.73102101,\n",
      "       0.7506152 , 0.74770266, 0.77392601, 0.74368911, 0.76533533,\n",
      "       0.68830969, 0.77433254, 0.77783755, 0.76250257, 0.7382167 ,\n",
      "       0.76792991, 0.77023882, 0.77611502, 0.72775034, 0.74747697,\n",
      "       0.67055086, 0.74909083, 0.7142713 , 0.76825337, 0.74487103,\n",
      "       0.76501523, 0.76490031, 0.73843128, 0.77356994, 0.76190557,\n",
      "       0.77292995, 0.74217333, 0.75356692, 0.77209261, 0.76411062,\n",
      "       0.76747278, 0.71452807, 0.76792259, 0.76824499, 0.6922815 ,\n",
      "       0.70447308, 0.76986347, 0.71356116, 0.77542623, 0.68071031,\n",
      "       0.76667419, 0.73162527, 0.69063264, 0.77603146, 0.76997839,\n",
      "       0.72533075, 0.72990979, 0.71890347, 0.76931429, 0.767496  ,\n",
      "       0.67166556, 0.76837567, 0.74354951, 0.76552789, 0.7779939 ,\n",
      "       0.75114867, 0.769479  , 0.68125493, 0.76258252, 0.75712865,\n",
      "       0.718962  , 0.72596491, 0.77239664, 0.74842519, 0.77252372,\n",
      "       0.75396954, 0.76720539, 0.76832665, 0.77178562, 0.68038169,\n",
      "       0.6994329 , 0.77261   , 0.72107147, 0.76624023, 0.77022915,\n",
      "       0.76282443, 0.76648632, 0.69447169, 0.77443902, 0.77508224,\n",
      "       0.77357514, 0.77597897, 0.73799941, 0.77306015, 0.71540392,\n",
      "       0.76641632, 0.77640948, 0.77103946, 0.67536173, 0.77466737,\n",
      "       0.69121175, 0.69917127, 0.7714018 , 0.76078428, 0.73593906,\n",
      "       0.77058152, 0.77611461, 0.77431957, 0.76927999, 0.76784292,\n",
      "       0.71335335, 0.77502265, 0.77685409, 0.69632776, 0.72460025,\n",
      "       0.70838478, 0.77684496, 0.76917696, 0.77059301, 0.70678229,\n",
      "       0.75444393, 0.76763452, 0.75756448, 0.66978238, 0.76681146,\n",
      "       0.7758885 , 0.70641482, 0.76240953, 0.77465395, 0.68772965,\n",
      "       0.73489794, 0.76235719, 0.7708114 , 0.7701987 , 0.76663239,\n",
      "       0.67855765, 0.74434175, 0.76376812, 0.7753405 , 0.77427942,\n",
      "       0.77436392, 0.77326843, 0.76346013, 0.77676516, 0.77055228,\n",
      "       0.77466204, 0.7695936 , 0.77176412, 0.7456353 , 0.76362854,\n",
      "       0.70185517, 0.67829208, 0.70666418, 0.7065979 , 0.71012324,\n",
      "       0.71971873, 0.77551865, 0.76835415, 0.77367863, 0.74431414])] \n",
      "\n",
      "mean AUC :  0.7495551223738249\n",
      "All std:  [array([0.00513317, 0.02095817, 0.02066113, 0.01360036, 0.02025506,\n",
      "       0.01796014, 0.02562748, 0.01959867, 0.02635732, 0.03449647,\n",
      "       0.01717341, 0.02265522, 0.0171284 , 0.01899685, 0.01839909,\n",
      "       0.01196865, 0.01812767, 0.0169654 , 0.01626978, 0.01947789,\n",
      "       0.01769979, 0.01897243, 0.0180484 , 0.01122016, 0.01988171,\n",
      "       0.01834442, 0.02050343, 0.0177722 , 0.01781943, 0.01877519,\n",
      "       0.02709137, 0.02172294, 0.0417023 , 0.02024184, 0.02979934,\n",
      "       0.01865762, 0.01151605, 0.01696696, 0.02215174, 0.01501394,\n",
      "       0.01142438, 0.02112864, 0.01972044, 0.01601806, 0.01693589,\n",
      "       0.03013285, 0.02207639, 0.01566729, 0.0133003 , 0.01911012,\n",
      "       0.01123469, 0.02811739, 0.01585149, 0.02848506, 0.01980397,\n",
      "       0.02383664, 0.01860716, 0.01921088, 0.02063331, 0.02081555,\n",
      "       0.01908771, 0.01912907, 0.01474728, 0.02409681, 0.01666671,\n",
      "       0.01444142, 0.02691404, 0.01956846, 0.01903309, 0.02221781,\n",
      "       0.0209444 , 0.01530736, 0.02823127, 0.0180518 , 0.02137629,\n",
      "       0.0191034 , 0.02094083, 0.00872148, 0.01904108, 0.01632652,\n",
      "       0.02180233, 0.02099177, 0.01625808, 0.01964255, 0.03357095,\n",
      "       0.03086087, 0.01983778, 0.02849788, 0.01836383, 0.01557315,\n",
      "       0.02017977, 0.02588347, 0.0300798 , 0.01817828, 0.01979522,\n",
      "       0.01827052, 0.02385065, 0.02701923, 0.01100883, 0.01944697,\n",
      "       0.03993646, 0.01907055, 0.02033364, 0.01233253, 0.01771297,\n",
      "       0.01873968, 0.01734501, 0.01965194, 0.0127966 , 0.02384295,\n",
      "       0.03041019, 0.02555921, 0.01845299, 0.01884771, 0.02118238,\n",
      "       0.02068894, 0.01117966, 0.01951738, 0.01866292, 0.02361301,\n",
      "       0.03339886, 0.01404571, 0.02498181, 0.01826325, 0.01907732,\n",
      "       0.01297142, 0.00847625, 0.03700654, 0.01884771, 0.01775162,\n",
      "       0.0189528 , 0.01903802, 0.01917668, 0.01578568, 0.02595099,\n",
      "       0.0191992 , 0.01920102, 0.01307143, 0.02331567, 0.01827289,\n",
      "       0.02957069, 0.02108893, 0.01914621, 0.0119785 , 0.02598934,\n",
      "       0.01922792, 0.01879403, 0.01420717, 0.01900658, 0.01929454,\n",
      "       0.0209445 , 0.01508468, 0.01903671, 0.01533141, 0.0315033 ,\n",
      "       0.02512699, 0.01887026, 0.0197397 , 0.0216217 , 0.03393914,\n",
      "       0.01178842, 0.0176612 , 0.00871412, 0.02362485, 0.01909104,\n",
      "       0.01848403, 0.02312211, 0.02298694, 0.01940501, 0.02332032,\n",
      "       0.02463923, 0.00865958, 0.01905998, 0.01981994, 0.01487415,\n",
      "       0.02169656, 0.02443048, 0.02028528, 0.01676711, 0.01630362,\n",
      "       0.01762492, 0.01982938, 0.02093863, 0.01864117, 0.02008756,\n",
      "       0.01865843, 0.01937614, 0.01975048, 0.01948291, 0.0146101 ,\n",
      "       0.02316094, 0.0168903 , 0.0230893 , 0.02128018, 0.02559613,\n",
      "       0.02043134, 0.0194853 , 0.01337617, 0.01757985, 0.01991584])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 44, 'min_data_in_leaf': 97, 'max_depth': 82, 'learning_rate': 0.019023011886689447, 'bagging_fraction': 0.13636363636363635} \n",
      "\n",
      "Best index/iterasi :  28\n",
      "Best AUC : 0.7781364918907366 ( std: 0.01781942827866275 ) \n",
      "\n",
      "running time:  194.89285397529602  detik. Dalam menit:  3.2482142329216  menit\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Seed:  92 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.76693765, 0.69739167, 0.72921053, 0.77166609, 0.71032012,\n",
      "       0.76351178, 0.77675706, 0.76973593, 0.76479109, 0.7706648 ,\n",
      "       0.7737523 , 0.76619231, 0.7765846 , 0.76941429, 0.67545873,\n",
      "       0.76819176, 0.63229077, 0.77036778, 0.76675803, 0.76647334,\n",
      "       0.76780823, 0.68703862, 0.65946461, 0.7709736 , 0.77591861,\n",
      "       0.6711724 , 0.77608876, 0.76691946, 0.77531765, 0.75408423,\n",
      "       0.7720294 , 0.67776052, 0.77129952, 0.76992681, 0.75676677,\n",
      "       0.77245609, 0.77397645, 0.75197466, 0.73453103, 0.73670626,\n",
      "       0.77171895, 0.73087568, 0.72092008, 0.77626577, 0.76364302,\n",
      "       0.76121117, 0.75460097, 0.7710573 , 0.77692399, 0.77501142,\n",
      "       0.77653043, 0.74949946, 0.74482765, 0.73925674, 0.77031517,\n",
      "       0.77140255, 0.76914498, 0.74845947, 0.68632091, 0.73035309,\n",
      "       0.77458359, 0.75220742, 0.77346079, 0.77499781, 0.77585039,\n",
      "       0.69923172, 0.75503591, 0.72171553, 0.76442486, 0.77581533,\n",
      "       0.77067704, 0.74287869, 0.76975557, 0.76524061, 0.69349012,\n",
      "       0.76730513, 0.70332864, 0.77667236, 0.71148363, 0.776032  ,\n",
      "       0.74849513, 0.77118587, 0.76976386, 0.7239661 , 0.73973825,\n",
      "       0.77195232, 0.7657678 , 0.77232901, 0.75436294, 0.77426836,\n",
      "       0.76690243, 0.72851628, 0.77288918, 0.76972035, 0.7704339 ,\n",
      "       0.71343458, 0.77074308, 0.76503343, 0.77767206, 0.75841267,\n",
      "       0.67938225, 0.72668553, 0.71192746, 0.77147214, 0.76632602,\n",
      "       0.74024033, 0.77263464, 0.73565943, 0.73415866, 0.77502978,\n",
      "       0.77401294, 0.7649688 , 0.74847982, 0.77217118, 0.70044539,\n",
      "       0.77533885, 0.77516083, 0.73601403, 0.70018992, 0.7698198 ,\n",
      "       0.7742525 , 0.77368041, 0.73120067, 0.77050322, 0.7739915 ,\n",
      "       0.7702667 , 0.76794896, 0.74459038, 0.77211131, 0.76971948,\n",
      "       0.75113714, 0.69199613, 0.77129841, 0.76370669, 0.72050419,\n",
      "       0.68715523, 0.76993487, 0.70870662, 0.72313386, 0.77446067,\n",
      "       0.77257116, 0.6648803 , 0.69948681, 0.77149985, 0.75317792,\n",
      "       0.76052995, 0.7024016 , 0.77589784, 0.71839203, 0.69315338,\n",
      "       0.75696283, 0.76514347, 0.77303071, 0.75466366, 0.76614392,\n",
      "       0.74128409, 0.7712229 , 0.75649894, 0.77206992, 0.69420699,\n",
      "       0.7683996 , 0.76252474, 0.74010152, 0.77273326, 0.68718159,\n",
      "       0.766595  , 0.77199604, 0.77080999, 0.76532679, 0.73009779,\n",
      "       0.69799408, 0.68760645, 0.7443179 , 0.74074571, 0.77394841,\n",
      "       0.77046726, 0.74685464, 0.67315783, 0.7736545 , 0.74929849,\n",
      "       0.77397645, 0.7721442 , 0.76961369, 0.76574641, 0.71320027,\n",
      "       0.76751325, 0.74728156, 0.77255614, 0.68539047, 0.77023936,\n",
      "       0.7606821 , 0.77560783, 0.7277694 , 0.68181367, 0.77624229,\n",
      "       0.76471237, 0.76740542, 0.75595175, 0.77196886, 0.73525444])] \n",
      "\n",
      "mean AUC :  0.7498965718580718\n",
      "All std:  [array([0.01779303, 0.0405825 , 0.02650364, 0.01571634, 0.02552402,\n",
      "       0.00731058, 0.01813356, 0.01977978, 0.0151645 , 0.01967119,\n",
      "       0.01802368, 0.01965066, 0.01906918, 0.02193181, 0.02966381,\n",
      "       0.01931453, 0.01704257, 0.01887135, 0.02027851, 0.01441442,\n",
      "       0.01993792, 0.0251415 , 0.03608432, 0.01915928, 0.01937785,\n",
      "       0.03433845, 0.0194677 , 0.01961817, 0.01855181, 0.00763709,\n",
      "       0.01993413, 0.02460209, 0.02203309, 0.01005075, 0.01712811,\n",
      "       0.01795601, 0.01908317, 0.02260088, 0.01896984, 0.01810591,\n",
      "       0.01654748, 0.02075061, 0.02873567, 0.01794037, 0.00858832,\n",
      "       0.019557  , 0.02025655, 0.01651407, 0.0187113 , 0.01765074,\n",
      "       0.01876727, 0.02319803, 0.03012727, 0.02981997, 0.01763066,\n",
      "       0.01149671, 0.01776659, 0.0177161 , 0.03201064, 0.01949702,\n",
      "       0.01904551, 0.00815257, 0.01343931, 0.0188764 , 0.01862824,\n",
      "       0.02522059, 0.00719861, 0.02187624, 0.00915908, 0.01950903,\n",
      "       0.01888905, 0.02348864, 0.0189203 , 0.00880898, 0.02077136,\n",
      "       0.01974019, 0.01607485, 0.01733684, 0.03158512, 0.01891534,\n",
      "       0.01894067, 0.01848861, 0.0205708 , 0.02535044, 0.01737272,\n",
      "       0.02028328, 0.01717496, 0.01900402, 0.00421346, 0.01765707,\n",
      "       0.02051394, 0.02388416, 0.01976896, 0.01855267, 0.01885314,\n",
      "       0.02321334, 0.01902724, 0.01862169, 0.01767064, 0.01426789,\n",
      "       0.02258796, 0.01720405, 0.03650498, 0.01750172, 0.02118254,\n",
      "       0.01933112, 0.01829521, 0.02859059, 0.01427515, 0.01871344,\n",
      "       0.01815956, 0.01882313, 0.01886295, 0.0181135 , 0.02746549,\n",
      "       0.01667526, 0.01870017, 0.01936771, 0.02134647, 0.01891956,\n",
      "       0.01886178, 0.01820115, 0.03706702, 0.01920941, 0.01688133,\n",
      "       0.01821579, 0.01766216, 0.01480381, 0.01945368, 0.00989413,\n",
      "       0.01058482, 0.01745845, 0.02136906, 0.01723749, 0.02191821,\n",
      "       0.01632398, 0.01957712, 0.02369371, 0.01390236, 0.01371065,\n",
      "       0.01802579, 0.02970422, 0.02512132, 0.01702891, 0.00877838,\n",
      "       0.00866089, 0.02338092, 0.01867751, 0.02425519, 0.02488417,\n",
      "       0.01780916, 0.01100846, 0.01563782, 0.0167823 , 0.01959967,\n",
      "       0.02226998, 0.01283679, 0.01335913, 0.01889571, 0.02698308,\n",
      "       0.02088856, 0.01886878, 0.02700748, 0.01886249, 0.02770911,\n",
      "       0.02005857, 0.02161556, 0.02133057, 0.01845911, 0.03525753,\n",
      "       0.0189796 , 0.02262518, 0.0243352 , 0.0186963 , 0.01476601,\n",
      "       0.02017201, 0.00815228, 0.02218485, 0.01957521, 0.02801149,\n",
      "       0.01872589, 0.02065833, 0.01991779, 0.01949149, 0.01897839,\n",
      "       0.01930265, 0.01530197, 0.01890267, 0.02407644, 0.01918843,\n",
      "       0.01033137, 0.01865629, 0.01910896, 0.02261349, 0.01975893,\n",
      "       0.01569195, 0.0200409 , 0.01954729, 0.01921212, 0.03273024])] \n",
      "\n",
      "Best Hyperparameter:  {'num_leaves': 28, 'min_data_in_leaf': 78, 'max_depth': 47, 'learning_rate': 0.023570694139967277, 'bagging_fraction': 0.5363636363636364} \n",
      "\n",
      "Best index/iterasi :  98\n",
      "Best AUC : 0.7776720646023085 ( std: 0.017670637619234306 ) \n",
      "\n",
      "running time:  207.22096610069275  detik. Dalam menit:  3.453682768344879  menit\n"
     ]
    }
   ],
   "source": [
    "seeds=[1,12,22,32,42,52,62,72,82,92]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=random_search(X_credit,y_credit,model_l,hyper_space_6,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dataset 3(Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuf/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '  (0, 0)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 31)\\t1.0\\n  (0, 32)\\t1.0\\n  (0, 48)\\t1.0\\n  (0, 57)\\t1.0\\n  (0, 58)\\t1.0\\n  (0, 99)\\t1.0\\n  (0, 102)\\t1.0\\n  (0, 103)\\t0.04398744923323508\\n  (0, 104)\\t0.5333333333333333\\n  (0, 106)\\t1.0\\n  (0, 107)\\t0.39795918367346933'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-49263fee4b1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_census\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_census\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_l\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper_space_6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterasi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Seed: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint_hasil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterasi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f7df020fa3a6>\u001b[0m in \u001b[0;36mrandom_search\u001b[0;34m(X, y, model, parameter, iterasi, evalscore, seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m                    verbose= 1)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbest_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    855\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m                                         callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LGBMCheckXY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LGBMCheckSampleWeight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '  (0, 0)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 31)\\t1.0\\n  (0, 32)\\t1.0\\n  (0, 48)\\t1.0\\n  (0, 57)\\t1.0\\n  (0, 58)\\t1.0\\n  (0, 99)\\t1.0\\n  (0, 102)\\t1.0\\n  (0, 103)\\t0.04398744923323508\\n  (0, 104)\\t0.5333333333333333\\n  (0, 106)\\t1.0\\n  (0, 107)\\t0.39795918367346933'"
     ]
    }
   ],
   "source": [
    "seeds=[1,12,22,32,42,52,62,72,82,92]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=random_search(X_census,y_census,model_l,hyper_space_6,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T19:41:52.308824Z",
     "start_time": "2020-12-28T15:27:13.532940Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.5587832729041627, 0.6477664898526327, 0.5951501935892057, 0.5274258319836593, 0.6256390954105648, 0.4988635442378573, 0.592438521250225, 0.5183802113110775, 0.5414697373869247, 0.504765148350738, 0.6997247725270337, 0.7117687605541637, 0.5818940024870508, 0.7229608379659876, 0.7600568246427584, 0.5565036549050127, 0.7331109489851977, 0.772235888332445, 0.7806808647603052, 0.6245483081001512, 0.6165254985355147, 0.7730012027554641, 0.7800471083125698, 0.7807254140803599, 0.7807254140803599, 0.7809152508108572, 0.7806593571486952, 0.5951269925366793, 0.7807921102726536, 0.7805047744580719, 0.7814096762857977, 0.7814981309448472, 0.46574907865363485, 0.773774719141885, 0.7802030168770903, 0.7799696630711808, 0.7811659001682294, 0.7811674628053226, 0.7801199528624856, 0.7782102194591873, 0.77998135917306, 0.7805280809069436, 0.7801000130487006, 0.7804920218722032, 0.780477200496138, 0.7800470609599307, 0.7805574987340379, 0.7801676681319379, 0.780278063324728, 0.780477200496138, 0.7801011139975618, 0.780347257368739, 0.7801956653798566, 0.780278063324728, 0.7803451028236559, 0.780347257368739, 0.7800369555241521, 0.780347257368739, 0.4929546029543182, 0.780236554383794, 0.7803451028236559, 0.780225939907144, 0.49596338999445305, 0.7801441693847418, 0.5854339614981774, 0.7801146020142575, 0.7811652845839201, 0.7800955189006655, 0.5690488290150811, 0.7808890766395471, 0.7811659001682294, 0.7325074486245543, 0.7198972756598258, 0.7414778564439602, 0.6382389981260739, 0.7349353660121476, 0.7206991725343546, 0.7405874368743388, 0.7309870730154157, 0.7790578080243004, 0.7809719555962827, 0.7809719555962827, 0.7809592295745014, 0.7791587401747255, 0.7809260945652309, 0.7809260945652309, 0.7808845189480255, 0.7808845189480255, 0.78088425850851, 0.7809671966560445, 0.7809628046987599, 0.780960176627285, 0.7790212636250085, 0.7810486905480839, 0.7810457310081348, 0.7810877801517322, 0.7811659001682294, 0.7811260174078749, 0.7811260174078749, 0.7810088669785282, 0.7809260945652309, 0.7434660487591149, 0.7809719555962827, 0.7107446437423472, 0.7418433100569143, 0.7808890766395471, 0.7808555154565239, 0.7809628046987599, 0.5341028028069859, 0.7809244135465397, 0.721041392624973, 0.7809628046987599, 0.7791949412673834, 0.7808583566148751, 0.6215693106024641, 0.4886911635184518, 0.7811418687038425, 0.7811260174078749, 0.7809230403200035, 0.519362942203796, 0.5188833421490612, 0.6013763156434422, 0.5026504144259992, 0.6269582659650456, 0.5717377186025677, 0.6375976526651315, 0.7800955189006655, 0.5245810307336295, 0.7811659001682294, 0.505166562484587, 0.7787839529859591, 0.7340407073060033, 0.7809719555962827, 0.7811674272908432, 0.7809719555962827, 0.780925739420437, 0.780925739420437, 0.5569005567319497, 0.7810117554895187, 0.5352524071802455, 0.7336121856967676, 0.7809628046987599, 0.780347257368739, 0.7810117554895187, 0.7809242951649419, 0.567621133672449, 0.7195661304529994, 0.781045659979176, 0.7790578080243004, 0.7811303501743605, 0.7809628046987599, 0.780242347596622, 0.7809230403200035, 0.7787258305091258, 0.7811659001682294, 0.7811458108110548, 0.7809719555962827, 0.7809628046987599, 0.7811458108110548, 0.7809797214291092, 0.7811486519694059, 0.5283935764050601, 0.7339919197655642, 0.5837887034348306, 0.780925739420437, 0.579321679460112, 0.7809797214291092, 0.781045659979176, 0.7787258305091258, 0.7810088669785282, 0.780960176627285, 0.780347257368739, 0.5051871411560254, 0.7809677767258746, 0.7809628046987599, 0.780960176627285, 0.4960335341807059, 0.7809244135465397, 0.7029599775517857, 0.7628765594364303, 0.5178931593883253, 0.746742896377927, 0.5829658172184301, 0.6096494186077311, 0.719653140927504, 0.548254407423405, 0.7387025833488723, 0.47673565158840564, 0.4909494602138877, 0.4830630987203025, 0.5844321457354459, 0.5099959423845595, 0.5580689566441724, 0.769819582421374, 0.5222528821984439, 0.7825915917294437, 0.569337092211084, 0.7678127472106534, 0.6925385628129098, 0.7790578080243004]] \n",
      "\n",
      "mean AUC :  0.7132503890742066\n",
      "All std:  [[0.07482849394053712, 0.09715338747766343, 0.09674016039090613, 0.06402149382201948, 0.0925397307828312, 0.05021356196775756, 0.09352413210578747, 0.07288250738486189, 0.06376576257360544, 0.06887209685226824, 0.14367110866761534, 0.1490831239587258, 0.056840229663005795, 0.12945315107734023, 0.12446865130445912, 0.21326955476169773, 0.13598062760863522, 0.11586428257861041, 0.11359836756841188, 0.09300691809384987, 0.09448576359332832, 0.1167116149548748, 0.11649756738786989, 0.11323959817545066, 0.11323959817545066, 0.1168438024621261, 0.11323987525913154, 0.1424018355023944, 0.11324409674166601, 0.1131419558607812, 0.1132359193600666, 0.11324806779202856, 0.06691187134561773, 0.11579721460796782, 0.1157864810975457, 0.1164720387196252, 0.1163344144547497, 0.11633493964445815, 0.11523497672484033, 0.11664343279602747, 0.11647512018064404, 0.11581076303855821, 0.11577565562297398, 0.11519959934640846, 0.11519985598125093, 0.11649755116949752, 0.11520284989559867, 0.11514108933134647, 0.11498994651934394, 0.11519985598125093, 0.1151179963802969, 0.11501219180730536, 0.11516832617239256, 0.11498994651934394, 0.11501144183251095, 0.11501219180730536, 0.11522135078844836, 0.11501219180730536, 0.07805854226673656, 0.1151065350116393, 0.11501144183251095, 0.11500089036026581, 0.0776688880378739, 0.1151480022795323, 0.06996375462981279, 0.1152331128822642, 0.11633420758423607, 0.11522647357482678, 0.08908021945919381, 0.11678901426411092, 0.1163344144547497, 0.13648136431453428, 0.14550224437738232, 0.1462449069945719, 0.11260637408881978, 0.1507087388112173, 0.1496793634646059, 0.1480248199460333, 0.15027727698160862, 0.11672523145394163, 0.11682638893000825, 0.11682638893000825, 0.11683029825315921, 0.11676804564178826, 0.11681056898699903, 0.11681056898699903, 0.11679651170243864, 0.11679651170243864, 0.11679642382552771, 0.11682452268133357, 0.11661685160958737, 0.11683037366587982, 0.11672823229003813, 0.11662218051711323, 0.11662117947996435, 0.11663751166610034, 0.1163344144547497, 0.1166200804300475, 0.1166200804300475, 0.11661054630435636, 0.11681056898699903, 0.14653846664577183, 0.11682638893000825, 0.14731428555056275, 0.14737841693123646, 0.11678901426411092, 0.11679175711601202, 0.11661685160958737, 0.057105367531775746, 0.11680999336909999, 0.14915001110468218, 0.11661685160958737, 0.11677750488825456, 0.11678655712749314, 0.08948067101415487, 0.09564539860297191, 0.11632569801660742, 0.1166200804300475, 0.11680950372014343, 0.12681429142467607, 0.06370969262831679, 0.08011032181377585, 0.06600321550317569, 0.09971138689687459, 0.06267990463913702, 0.10530241411482372, 0.11522647357482678, 0.08788370993160281, 0.1163344144547497, 0.09465475672252514, 0.11507989779621344, 0.14942611401157146, 0.11682638893000825, 0.1162836393540913, 0.11682638893000825, 0.11681047317808697, 0.11681047317808697, 0.07273303275440114, 0.11662516531660161, 0.06344463939950713, 0.13325921644706573, 0.11661685160958737, 0.11501219180730536, 0.11662516531660161, 0.11680998390282397, 0.07027707177867253, 0.13230823841502984, 0.11662118610028659, 0.11672523145394163, 0.11634444563121644, 0.11661685160958737, 0.11499305055085625, 0.11680950372014343, 0.11674377722141753, 0.1163344144547497, 0.11631881721133586, 0.11682638893000825, 0.11661685160958737, 0.11631881721133586, 0.11663592480989259, 0.11631977297198563, 0.1031883365243726, 0.1495198790123026, 0.058538942362763934, 0.11681047317808697, 0.06203600918714348, 0.11663592480989259, 0.11662118610028659, 0.11674377722141753, 0.11661054630435636, 0.11683037366587982, 0.11501219180730536, 0.060025066314904, 0.11683320636963937, 0.11661685160958737, 0.11683037366587982, 0.09032887190915939, 0.11680999336909999, 0.15454950797967112, 0.1266170710310253, 0.06766407813460112, 0.14500021123813106, 0.07610509593579412, 0.09195871429803557, 0.13215049735914342, 0.05221100784525563, 0.1433240642445763, 0.0999777737730501, 0.09434821124253528, 0.07704109997785323, 0.06974757622982172, 0.06176789468885555, 0.06517830168753315, 0.11714484911936228, 0.06919361525857844, 0.11570347067039367, 0.12713281956554812, 0.11770731017924774, 0.12099312523701443, 0.11672523145394163]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 1.0), ('learning_rate', 0.008873504721061149), ('max_depth', 1), ('min_data_in_leaf', 1), ('num_leaves', 100)]) \n",
      "\n",
      "Best index/iterasi :  195\n",
      "Best AUC : 0.7825915917294437 ( std: 0.11570347067039367 ) \n",
      "\n",
      "running time:  1656.2384638786316  detik. Dalam menit:  27.603974397977193  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  12 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.5681613328161175, 0.5779048518036426, 0.5290857218632308, 0.5032067882959669, 0.5661827886842874, 0.581065219560557, 0.5169886120571885, 0.4929639123293617, 0.5140909743004769, 0.531664309405755, 0.6165254985355147, 0.62249015221791, 0.6165254985355147, 0.6226384606838411, 0.6375823340863547, 0.6375976526651315, 0.6862461760965013, 0.7092429891566383, 0.5871070026882508, 0.6283299295092176, 0.7195661304529994, 0.6337405364849684, 0.780960176627285, 0.7483912811044706, 0.7807785887694255, 0.769269590294667, 0.6215163441180759, 0.7731552935461925, 0.7397186025429303, 0.7805345682185121, 0.7834837372290281, 0.5519045359409634, 0.768633485969476, 0.7812728340480865, 0.7836956765145036, 0.7806451484691715, 0.7314787930628409, 0.6375976526651315, 0.7813531204478266, 0.78360931642815, 0.7825144175773653, 0.7844418962333191, 0.7819116344754704, 0.7799696630711808, 0.7844571081409818, 0.7844411385910919, 0.7843618465967748, 0.7842540600241515, 0.7843002052987141, 0.7843002052987141, 0.7843618465967748, 0.782416621484622, 0.7844962689012647, 0.7580204398532396, 0.7667193836353081, 0.6264859901703972, 0.784442983317342, 0.7723804845727874, 0.784493972298264, 0.7843204011993272, 0.7843451547914617, 0.784487567853814, 0.7844771147587137, 0.7844418962333191, 0.7824214893390029, 0.784260026456689, 0.7843920574529, 0.7843618465967748, 0.784422931501325, 0.7845060708975761, 0.784493972298264, 0.7844249203121708, 0.7843451547914617, 0.7843451547914617, 0.7844418962333191, 0.7845036202708224, 0.7843604023412796, 0.7844869639799887, 0.7843604023412796, 0.7843451547914617, 0.7843604023412796, 0.7844885029407622, 0.7843451547914617, 0.7844909298911962, 0.784487567853814, 0.7844910245964747, 0.7843451547914617, 0.7844997848347242, 0.7844249203121708, 0.7843920574529, 0.784502235333802, 0.7844881242473244, 0.7844997729965643, 0.7843707250889467, 0.7843604023412796, 0.7844548353419767, 0.784502235333802, 0.7843618465967748, 0.7843451547914617, 0.7841647529466466, 0.7844997729965643, 0.7844932383323566, 0.7843283801190299, 0.7844812581146425, 0.7844771147587137, 0.7845006963730283, 0.784324189410462, 0.7844771147587137, 0.7844997729965643, 0.7845020814377247, 0.7824031165149987, 0.7844571081409818, 0.7841053845752668, 0.7844885029407622, 0.784260026456689, 0.7844418250766846, 0.7843744659474424, 0.7844475073933869, 0.7844484899606501, 0.7843780410717008, 0.7844249203121708, 0.7842604052778027, 0.7842545927413426, 0.7842545927413426, 0.7844997729965643, 0.7845060708975761, 0.784516370096599, 0.7844484899606501, 0.7845230348528888, 0.784216047693045, 0.7844571081409818, 0.7841053845752668, 0.7842540600241515, 0.7841245742322971, 0.7845193768615117, 0.7845694641156108, 0.784249147187836, 0.784486289332556, 0.7846368705974924, 0.7846368705974924, 0.7841647529466466, 0.7845060708975761, 0.7844249203121708, 0.7844190130704323, 0.7844759426532184, 0.784486289332556, 0.7843844691924704, 0.784260026456689, 0.7842540600241515, 0.7841981247191128, 0.7846492769889591, 0.7843780410717008, 0.7841053845752668, 0.7844949075128879, 0.7844759426532184, 0.7842540600241515, 0.7844771147587137, 0.7846450744422314, 0.7846492769889591, 0.7841978879559169, 0.7845036202708224, 0.7843707250889467, 0.7844869639799887, 0.7843780410717008, 0.7842540600241515, 0.784486289332556, 0.7844771147587137, 0.7841053845752668, 0.7841981247191128, 0.7846450744422314, 0.7844288979338624, 0.7844976893527644, 0.7845879316448935, 0.7843901041565335, 0.7845036202708224, 0.7842540600241515, 0.7843218690034661, 0.7846147805913121, 0.7831397932333022, 0.7844475073933869, 0.7841053845752668, 0.7844191077757108, 0.7844191077757108, 0.7844771147587137, 0.7844484899606501, 0.7844484899606501, 0.7844869639799887, 0.7844949075128879, 0.7844949075128879, 0.7842604052778027, 0.7842545927413426, 0.7841053845752668, 0.7844411385910919, 0.784249147187836, 0.7841053845752668, 0.784260026456689, 0.784260026456689, 0.784486289332556, 0.7823658712935742, 0.7842540600241515]] \n",
      "\n",
      "mean AUC :  0.7587437809390122\n",
      "All std:  [[0.05451291671225464, 0.0906678745409456, 0.05689120780924702, 0.07146159402881022, 0.05096457427696571, 0.059092932243449824, 0.06307734551702403, 0.09164691329560322, 0.0692038964149535, 0.0673657688566195, 0.09448576359332832, 0.09705616388257225, 0.09448576359332832, 0.09708779053633601, 0.10528997322501896, 0.10530241411482372, 0.10285493572502415, 0.11871740580508913, 0.0642350891680601, 0.10460117824945372, 0.13230823841502984, 0.06473186550812128, 0.11683037366587982, 0.14411587002590698, 0.11359195349069322, 0.11708111927046438, 0.19479685266552138, 0.11656138736607147, 0.14960876989811758, 0.1158156770753237, 0.11627230585912494, 0.07559735445973695, 0.117344879385419, 0.11444885601070075, 0.11631007484462388, 0.1152151588407494, 0.14867084265529112, 0.10530241411482372, 0.11441445913990429, 0.11605172277002364, 0.11612103358273747, 0.11615067072928312, 0.11629487283345959, 0.1164720387196252, 0.11614534737152675, 0.11615043412419929, 0.11612577857873597, 0.11654329340372507, 0.11606773908103371, 0.11606773908103371, 0.11612577857873597, 0.114298568287792, 0.11619003482740858, 0.13179610933491584, 0.12165146424842171, 0.09479876749199584, 0.11626273264131179, 0.1278092765126706, 0.11618931412346865, 0.11607374520087362, 0.11615217456962498, 0.11618770034601682, 0.1161850693839747, 0.11615067072928312, 0.11573117572352178, 0.1165333106494111, 0.11609844851264751, 0.11612577857873597, 0.11615658310774901, 0.11614509455684158, 0.11618931412346865, 0.11615720346815646, 0.11615217456962498, 0.11615217456962498, 0.11615067072928312, 0.11617893194858746, 0.11614806309899546, 0.11616263853873611, 0.11614806309899546, 0.11615217456962498, 0.11614806309899546, 0.11616302858742517, 0.11615217456962498, 0.11616602452467388, 0.11618770034601682, 0.11616605425766091, 0.11615217456962498, 0.11617960002116003, 0.11615720346815646, 0.11609844851264751, 0.11618006347759167, 0.11618798885493423, 0.11618108805543237, 0.1161291547354547, 0.11614806309899546, 0.11612905211290733, 0.11618006347759167, 0.11612577857873597, 0.11615217456962498, 0.11647539327521717, 0.11618108805543237, 0.11617944216902248, 0.11607596666119349, 0.1161756838645625, 0.1161850693839747, 0.11618137787114818, 0.11607494101910022, 0.1161850693839747, 0.11618108805543237, 0.11618032067045993, 0.11575412181910394, 0.11614534737152675, 0.11649737622636894, 0.11616302858742517, 0.1165333106494111, 0.11615123380910207, 0.11613031216987292, 0.11616138741669423, 0.11614317560472544, 0.11613132155120375, 0.11615720346815646, 0.11653342948403529, 0.11654315475103973, 0.11654315475103973, 0.11618108805543237, 0.11614509455684158, 0.11612788577058823, 0.11614317560472544, 0.11615350239861374, 0.11653177745532013, 0.11614534737152675, 0.11649737622636894, 0.11654329340372507, 0.11646295846583597, 0.11617274667900875, 0.11614047144951074, 0.11654173458307855, 0.11616456797732581, 0.11618771041624455, 0.11618771041624455, 0.11647539327521717, 0.11614509455684158, 0.11615720346815646, 0.11616688615112741, 0.11616178447511552, 0.11616456797732581, 0.11650388351279503, 0.1165333106494111, 0.11654329340372507, 0.11604774050716597, 0.11616453711810516, 0.11613132155120375, 0.11649737622636894, 0.1161667365399307, 0.11616178447511552, 0.11654329340372507, 0.1161850693839747, 0.11607778693773842, 0.11616453711810516, 0.11604766725106078, 0.11617893194858746, 0.1161291547354547, 0.11616263853873611, 0.11613132155120375, 0.11654329340372507, 0.11616456797732581, 0.1161850693839747, 0.11649737622636894, 0.11604774050716597, 0.11607778693773842, 0.1161466141463635, 0.11616597939937633, 0.11617327743387788, 0.11649379780040825, 0.11617893194858746, 0.11654329340372507, 0.11649955454185418, 0.11612840632173865, 0.1160588364953846, 0.11616138741669423, 0.11649737622636894, 0.11616691569738138, 0.11616691569738138, 0.1161850693839747, 0.11614317560472544, 0.11614317560472544, 0.11616263853873611, 0.1161667365399307, 0.1161667365399307, 0.11653342948403529, 0.11654315475103973, 0.11649737622636894, 0.11615043412419929, 0.11654173458307855, 0.11649737622636894, 0.1165333106494111, 0.1165333106494111, 0.11616456797732581, 0.11428456914463293, 0.11654329340372507]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 0.7896873745658166), ('learning_rate', 0.009282054400162694), ('max_depth', 1), ('min_data_in_leaf', 100), ('num_leaves', 24)]) \n",
      "\n",
      "Best index/iterasi :  150\n",
      "Best AUC : 0.7846492769889591 ( std: 0.11616453711810516 ) \n",
      "\n",
      "running time:  1474.1195080280304  detik. Dalam menit:  24.56865846713384  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  22 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.5039705486351314, 0.5679844082052398, 0.4979805233668123, 0.487402263615217, 0.49185386204779785, 0.5491556592484138, 0.4855280711856001, 0.5634978220129837, 0.6014083800474884, 0.5843341127797842, 0.6165254985355147, 0.6165254985355147, 0.6825883491079284, 0.6165254985355147, 0.6165254985355147, 0.7043744211649573, 0.7074661425180119, 0.7071094977661908, 0.7265529886885993, 0.7324316844018564, 0.7461488393996785, 0.7732370482455319, 0.7799241025233642, 0.49268182128515525, 0.7779844773240431, 0.5668845875254888, 0.7730442253953882, 0.757837208494805, 0.6097107589185576, 0.7277396121882326, 0.7802797636670514, 0.7492806856010925, 0.5463703448569448, 0.5361479996682347, 0.49242751242007055, 0.7350575313079344, 0.6318175326643329, 0.6057239770631795, 0.6415602957180935, 0.6105707808587852, 0.5097368811245578, 0.7713599434077247, 0.7551102761017867, 0.5287089356144504, 0.591108413106229, 0.6260332826248328, 0.509124828988198, 0.6217854704582001, 0.570906621870308, 0.6683930174847688, 0.5877768290327132, 0.7103130085125776, 0.784493972298264, 0.5693916791333762, 0.5680667499554328, 0.5678931764586747, 0.6102832181672105, 0.5504723767586375, 0.5686885448454471, 0.784249147187836, 0.7679618630639307, 0.7836003786175035, 0.5296865433314698, 0.7834605817884662, 0.7844475073933869, 0.7844812581146425, 0.782417701127868, 0.7824031165149987, 0.7844383901113409, 0.7836278786627109, 0.7844812581146425, 0.7844484899606501, 0.5376588582100201, 0.7843920574529, 0.7844881242473244, 0.7843618465967748, 0.7845498837993075, 0.7831087535783157, 0.7843190516491102, 0.7844467360139976, 0.7824031165149987, 0.7287656971592992, 0.7844997729965643, 0.7844881242473244, 0.7824031165149987, 0.7834947112031597, 0.7844307920394298, 0.7844475073933869, 0.7834991149986039, 0.7844885029407622, 0.5142871032445531, 0.7843780410717008, 0.7831394380885083, 0.7844349827479978, 0.7844190130704323, 0.7842540600241515, 0.7844949075128879, 0.7843618465967748, 0.7846347042142496, 0.7843724297839574, 0.7842545927413426, 0.7843724297839574, 0.7841647529466466, 0.7843780410717008, 0.784249147187836, 0.7843780410717008, 0.7841647529466466, 0.7843367022176914, 0.7845694641156108, 0.7843920574529, 0.7844418250766846, 0.7842540600241515, 0.7841978879559169, 0.7841647529466466, 0.7844759426532184, 0.7845230348528888, 0.7844869639799887, 0.7845230348528888, 0.5299133462248183, 0.7841647529466466, 0.7842366224147713, 0.7843920574529, 0.7843367022176914, 0.7843744659474424, 0.7843920574529, 0.7846147805913121, 0.7843349975226805, 0.7843496650026685, 0.7845694641156108, 0.7846235171532419, 0.7843572414249383, 0.7845230348528888, 0.7846450744422314, 0.784583006970418, 0.784583006970418, 0.5836467274422115, 0.7843901041565335, 0.7845693694103325, 0.7830989752583236, 0.7831260017771391, 0.784260026456689, 0.7844869639799887, 0.7844869639799887, 0.7843709144995034, 0.7843709144995034, 0.7802545529159249, 0.7844976893527644, 0.7844869639799887, 0.7845193768615117, 0.7843761706424531, 0.7844976893527644, 0.7844885029407622, 0.784216047693045, 0.7844976893527644, 0.7844976893527644, 0.7845230348528888, 0.7843709144995034, 0.7843744659474424, 0.7844418250766846, 0.7844885029407622, 0.7843761706424531, 0.7843707250889467, 0.7844885029407622, 0.7846353316367188, 0.7843744659474424, 0.7843780410717008, 0.7843709144995034, 0.7843707250889467, 0.7843724297839574, 0.7843744659474424, 0.7843780410717008, 0.7841245742322971, 0.7843707250889467, 0.7843707250889467, 0.7844885029407622, 0.7843709144995034, 0.7841228695372864, 0.7844418250766846, 0.7843709144995034, 0.7846450744422314, 0.7843780410717008, 0.7843724297839574, 0.7843709144995034, 0.7843761706424531, 0.7841647529466466, 0.7843709144995034, 0.7845193768615117, 0.7843367022176914, 0.7843780410717008, 0.7844885029407622, 0.7843724297839574, 0.7843709144995034, 0.7841647529466466, 0.7843709144995034, 0.7843761706424531, 0.7844885029407622, 0.7844869639799887, 0.7843744659474424, 0.7843709144995034, 0.7844869639799887]] \n",
      "\n",
      "mean AUC :  0.7317230880104476\n",
      "All std:  [[0.06733815423226026, 0.05063834791305811, 0.08805632563962303, 0.07087539981754123, 0.11530122494626692, 0.08168594566690673, 0.07230045332175496, 0.09343980163927834, 0.07526668068618872, 0.09458563446536895, 0.09448576359332832, 0.09448576359332832, 0.1191266350623651, 0.09448576359332832, 0.09448576359332832, 0.12306814784458975, 0.12074369682479934, 0.12073793009621325, 0.13497777696753366, 0.1364542028853289, 0.1362673274085518, 0.12371510684258423, 0.12428707168543296, 0.04952264435888998, 0.11655839500816897, 0.045856970741366604, 0.11634606928103766, 0.1314029321454957, 0.09056519946311135, 0.14897902387347886, 0.11491666101858658, 0.14366889703509034, 0.04623284876782565, 0.12091644887709406, 0.0722147398860643, 0.15027159367891904, 0.10327650548607298, 0.09178582167102582, 0.11272076905859932, 0.07688504420754244, 0.0806418552391666, 0.1282474515466667, 0.14077851999449262, 0.09285074569426287, 0.10015752219794265, 0.09107540559945797, 0.07839022021563614, 0.09085139418101475, 0.04870272577893797, 0.1653470566962548, 0.0908974748282343, 0.14440287685594677, 0.11618931412346865, 0.04607502932650849, 0.07466383018752569, 0.03674679955603795, 0.08958694413614453, 0.050836704444049946, 0.04738304667866635, 0.11654173458307855, 0.11740599385177827, 0.11607006909403174, 0.06978072069138168, 0.11634937271607264, 0.11616138741669423, 0.1161756838645625, 0.11572991407176977, 0.11575412181910394, 0.11626157377794183, 0.11607573009359137, 0.1161756838645625, 0.11614317560472544, 0.05942935440391535, 0.11609844851264751, 0.11618798885493423, 0.11612577857873597, 0.11610863865097987, 0.11612302023725803, 0.11607368440695051, 0.11626360344588307, 0.11575412181910394, 0.14816997354233621, 0.11618108805543237, 0.11618798885493423, 0.11575412181910394, 0.11603667373673411, 0.11614720491619623, 0.11616138741669423, 0.1160374452869102, 0.11616302858742517, 0.08116451040591328, 0.11613132155120375, 0.1160587391777487, 0.11614814822895607, 0.11616688615112741, 0.11654329340372507, 0.1161667365399307, 0.11612577857873597, 0.11607461996081087, 0.11612958531195006, 0.11654315475103973, 0.11612958531195006, 0.11647539327521717, 0.11613132155120375, 0.11654173458307855, 0.11613132155120375, 0.11647539327521717, 0.11610843858807718, 0.11614047144951074, 0.11609844851264751, 0.11615123380910207, 0.11654329340372507, 0.11604766725106078, 0.11647539327521717, 0.11616178447511552, 0.11615350239861374, 0.11616263853873611, 0.11615350239861374, 0.06321425590233341, 0.11647539327521717, 0.11605967703248508, 0.11609844851264751, 0.11610843858807718, 0.11613031216987292, 0.11609844851264751, 0.11612840632173865, 0.11610800740860974, 0.11650802994759059, 0.11614047144951074, 0.11615720348715815, 0.11649535198821684, 0.11615350239861374, 0.11607778693773842, 0.11611784082476859, 0.11611784082476859, 0.06945899446737673, 0.11649379780040825, 0.11614062971234322, 0.11612620363062173, 0.11615446199531701, 0.1165333106494111, 0.11616263853873611, 0.11616263853873611, 0.11612921332842092, 0.11612921332842092, 0.12372471219933664, 0.11616597939937633, 0.11616263853873611, 0.11617274667900875, 0.11613074268716443, 0.11616597939937633, 0.11616302858742517, 0.11653177745532013, 0.11616597939937633, 0.11616597939937633, 0.11615350239861374, 0.11612921332842092, 0.11613031216987292, 0.11615123380910207, 0.11616302858742517, 0.11613074268716443, 0.1161291547354547, 0.11616302858742517, 0.1161873082568234, 0.11613031216987292, 0.11613132155120375, 0.11612921332842092, 0.1161291547354547, 0.11612958531195006, 0.11613031216987292, 0.11613132155120375, 0.11646295846583597, 0.1161291547354547, 0.1161291547354547, 0.11616302858742517, 0.11612921332842092, 0.11646252549393081, 0.11615123380910207, 0.11612921332842092, 0.11607778693773842, 0.11613132155120375, 0.11612958531195006, 0.11612921332842092, 0.11613074268716443, 0.11647539327521717, 0.11612921332842092, 0.11617274667900875, 0.11610843858807718, 0.11613132155120375, 0.11616302858742517, 0.11612958531195006, 0.11612921332842092, 0.11647539327521717, 0.11612921332842092, 0.11613074268716443, 0.11616302858742517, 0.11616263853873611, 0.11613031216987292, 0.11612921332842092, 0.11616263853873611]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 0.561368237450624), ('learning_rate', 0.00925495469493277), ('max_depth', 1), ('min_data_in_leaf', 100), ('num_leaves', 45)]) \n",
      "\n",
      "Best index/iterasi :  132\n",
      "Best AUC : 0.7846450744422314 ( std: 0.11607778693773842 ) \n",
      "\n",
      "running time:  1508.8367130756378  detik. Dalam menit:  25.14727855126063  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  32 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.48531870502785696, 0.489479215490452, 0.5521478967826522, 0.4994921156185859, 0.5321731315605478, 0.5691037257925545, 0.5033220315232151, 0.5343232310789442, 0.5013708888655408, 0.5947281132774321, 0.6068325503730347, 0.5810609061181571, 0.5790004555377061, 0.619906395157872, 0.6253300492026271, 0.6171166511467575, 0.6165254985355147, 0.6165254985355147, 0.7331495027151481, 0.6797286874986485, 0.7794953847294116, 0.7781540590151704, 0.7808765519538617, 0.5840751932033125, 0.7844771147587137, 0.7836211901024259, 0.78138848098274, 0.5502673125980655, 0.6010670406660757, 0.7670552425054326, 0.717799405609968, 0.4965785283755028, 0.7397600655899773, 0.5760292262556816, 0.529137029785811, 0.7798030883246839, 0.609365358765166, 0.7823498897778489, 0.5508009636551344, 0.6413665418984108, 0.7729620695677291, 0.5924265872741492, 0.675291205172259, 0.776974066820624, 0.7814061317273955, 0.7607346111398026, 0.5015874229724209, 0.7781534434308609, 0.7801707368855076, 0.7801943066132638, 0.5430825493125164, 0.7801574899362965, 0.4960766157002696, 0.7779868923086416, 0.5522937989988378, 0.5657859431638105, 0.7844771147587137, 0.7311174390490583, 0.780170559264712, 0.5207604121316761, 0.5676760732751029, 0.7844418962333191, 0.7844826076648593, 0.784260026456689, 0.522450858901819, 0.7842540600241515, 0.5275129795818562, 0.48763239501886607, 0.5534968666075439, 0.5127141116997004, 0.7843891334274301, 0.48380819627004146, 0.6086857336837775, 0.7843367022176914, 0.5196077653275852, 0.7492075770276942, 0.7842540600241515, 0.5775832635347349, 0.774022989026021, 0.7844869639799887, 0.7841647529466466, 0.7779370545513222, 0.784486289332556, 0.7831372598671056, 0.7844771147587137, 0.7844771147587137, 0.7844445834955928, 0.7845060708975761, 0.7844190130704323, 0.7841053845752668, 0.7844571081409818, 0.7841053845752668, 0.784216047693045, 0.7844763214743318, 0.7844976893527644, 0.7843709144995034, 0.7843367022176914, 0.7844759426532184, 0.7843367022176914, 0.7830980518818594, 0.7842540600241515, 0.7841053845752668, 0.784516370096599, 0.7842540600241515, 0.7843367022176914, 0.7842540600241515, 0.7841647529466466, 0.7843298834376485, 0.7846357578104716, 0.7831372598671056, 0.784249147187836, 0.7844411385910919, 0.7844949075128879, 0.7844997729965643, 0.784502235333802, 0.7844955822879963, 0.7845016079113327, 0.7844976893527644, 0.5988961599222699, 0.7842540600241515, 0.7845060708975761, 0.7844191077757108, 0.784516370096599, 0.7844475073933869, 0.7842545927413426, 0.7845060708975761, 0.7844384986814574, 0.7845060708975761, 0.7799273934797459, 0.7844962689012647, 0.7844771147587137, 0.7843604023412796, 0.7844445834955928, 0.7842545927413426, 0.7844191077757108, 0.784516370096599, 0.7844445834955928, 0.7844190130704323, 0.7845032534155445, 0.7844384986814574, 0.7844812581146425, 0.7844771147587137, 0.784502235333802, 0.7844771147587137, 0.784487567853814, 0.7844571081409818, 0.7844771147587137, 0.784486289332556, 0.784493972298264, 0.7844191077757108, 0.7844249203121708, 0.7844349827479978, 0.7844771147587137, 0.7844910245964747, 0.7844190130704323, 0.7804804486811626, 0.784486289332556, 0.7844548353419767, 0.7845060708975761, 0.7842540600241515, 0.7844997729965643, 0.48577894854842296, 0.7844418962333191, 0.7844191077757108, 0.7844479810474545, 0.7844384986814574, 0.784486289332556, 0.7845016079113327, 0.7845032534155445, 0.7844949075128879, 0.7843613020414242, 0.7844418962333191, 0.7844962689012647, 0.784493972298264, 0.7844571081409818, 0.7844349827479978, 0.7844962689012647, 0.784486289332556, 0.7845056920764626, 0.7844976893527644, 0.7845060708975761, 0.7844571081409818, 0.7844949075128879, 0.7843618465967748, 0.7844484899606501, 0.7844418962333191, 0.7841053845752668, 0.7843618465967748, 0.784502235333802, 0.784486289332556, 0.7844475073933869, 0.7844771147587137, 0.7842540600241515, 0.7845060708975761, 0.784486289332556, 0.5779222491082399, 0.784486289332556, 0.7844349827479978, 0.7844881242473244, 0.7844949075128879]] \n",
      "\n",
      "mean AUC :  0.7273144659412487\n",
      "All std:  [[0.09026945288599131, 0.07711335944414427, 0.05702826294548922, 0.10108677497553183, 0.09749963727634643, 0.053233338198776216, 0.0660411831641522, 0.06731135271181947, 0.04322451346802957, 0.07992018012504325, 0.07793387584458113, 0.10704845676361414, 0.07171982110526486, 0.10005653468415873, 0.09317368153634163, 0.08582852258936692, 0.09448576359332832, 0.09448576359332832, 0.1360545712551352, 0.16458016406113918, 0.1225468173967706, 0.11666628527427621, 0.12359648016542576, 0.11572411504062681, 0.1161850693839747, 0.11607527671764123, 0.1144266451884412, 0.078101499916782, 0.09945866679395066, 0.12409912162498025, 0.14734095223005203, 0.05971064777329376, 0.14833613476571386, 0.10772885443981871, 0.0773776184957663, 0.11576074895710006, 0.09391995116420448, 0.11428123643796748, 0.1428372222461269, 0.09026631618323136, 0.12923213098649589, 0.10026713278702325, 0.11188077216093946, 0.13283115724415137, 0.11443952396689731, 0.12940843893814616, 0.07180383365209805, 0.11666604869780194, 0.11406339848839638, 0.11407303632836999, 0.08250108600993303, 0.11410301638891508, 0.0718392637317417, 0.11655930733833325, 0.1025918464017332, 0.07365329833240204, 0.1161850693839747, 0.14808572335663264, 0.1140801867599031, 0.09833469608253666, 0.050649277364569055, 0.11615067072928312, 0.11617610698996435, 0.1165333106494111, 0.06840058855745844, 0.11654329340372507, 0.06204343812283055, 0.07450706026339565, 0.07170535735771547, 0.07490523851914198, 0.11650510722859832, 0.08189811093406357, 0.1072086058297569, 0.11610843858807718, 0.09428270480796715, 0.14490637423451053, 0.11654329340372507, 0.06014421287855368, 0.11594650783859485, 0.11616263853873611, 0.11647539327521717, 0.13328211283168015, 0.11616456797732581, 0.11605817103346458, 0.1161850693839747, 0.1161850693839747, 0.11613210739062971, 0.11614509455684158, 0.11616688615112741, 0.11649737622636894, 0.11614534737152675, 0.11649737622636894, 0.11653177745532013, 0.11616190297409751, 0.11616597939937633, 0.11612921332842092, 0.11610843858807718, 0.11616178447511552, 0.11610843858807718, 0.1161259608700629, 0.11654329340372507, 0.11649737622636894, 0.11612788577058823, 0.11654329340372507, 0.11610843858807718, 0.11654329340372507, 0.11647539327521717, 0.1161165488010917, 0.1161874196160235, 0.11605817103346458, 0.11654173458307855, 0.11615043412419929, 0.1161667365399307, 0.11618108805543237, 0.11618006347759167, 0.11618992474293849, 0.11618017206847985, 0.11616597939937633, 0.09106805435429466, 0.11654329340372507, 0.11614509455684158, 0.11616691569738138, 0.11612788577058823, 0.11616138741669423, 0.11654315475103973, 0.11614509455684158, 0.11613057359918179, 0.11614509455684158, 0.12429199053356291, 0.11619003482740858, 0.1161850693839747, 0.11614806309899546, 0.11613210739062971, 0.11654315475103973, 0.11616691569738138, 0.11612788577058823, 0.11613210739062971, 0.11616688615112741, 0.1161804885326118, 0.11613057359918179, 0.1161756838645625, 0.1161850693839747, 0.11618006347759167, 0.1161850693839747, 0.11618770034601682, 0.11614534737152675, 0.1161850693839747, 0.11616456797732581, 0.11618931412346865, 0.11616691569738138, 0.11615720346815646, 0.11614814822895607, 0.1161850693839747, 0.11616605425766091, 0.11616688615112741, 0.12334084591604114, 0.11616456797732581, 0.11612905211290733, 0.11614509455684158, 0.11654329340372507, 0.11618108805543237, 0.08021236236311657, 0.11615067072928312, 0.11616691569738138, 0.11615220407736211, 0.11613057359918179, 0.11616456797732581, 0.11618017206847985, 0.1161804885326118, 0.1161667365399307, 0.11612560998199822, 0.11615067072928312, 0.11619003482740858, 0.11618931412346865, 0.11614534737152675, 0.11614814822895607, 0.11619003482740858, 0.11616456797732581, 0.1161697280039561, 0.11616597939937633, 0.11614509455684158, 0.11614534737152675, 0.1161667365399307, 0.11612577857873597, 0.11614317560472544, 0.11615067072928312, 0.11649737622636894, 0.11612577857873597, 0.11618006347759167, 0.11616456797732581, 0.11616138741669423, 0.1161850693839747, 0.11654329340372507, 0.11614509455684158, 0.11616456797732581, 0.07187348471296792, 0.11616456797732581, 0.11614814822895607, 0.11618798885493423, 0.1161667365399307]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 0.9731533315107195), ('learning_rate', 0.00927385850415189), ('max_depth', 1), ('min_data_in_leaf', 1), ('num_leaves', 10)]) \n",
      "\n",
      "Best index/iterasi :  108\n",
      "Best AUC : 0.7846357578104716 ( std: 0.1161874196160235 ) \n",
      "\n",
      "running time:  1589.3022935390472  detik. Dalam menit:  26.48837155898412  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  42 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.5104714158362318, 0.5203628215855283, 0.5088696994705355, 0.579956575527761, 0.5390742689277732, 0.5886572040855182, 0.5024061814074041, 0.5059410530151172, 0.47861445670166647, 0.49657371660690725, 0.550873601523326, 0.49098914277740247, 0.6277736367325402, 0.5029917582676794, 0.5595432849191252, 0.6226384606838411, 0.5951674278308818, 0.6073587364265675, 0.6134957294720323, 0.6054167472682199, 0.5222528821984439, 0.5823648779385119, 0.5263817064143136, 0.6217744740165005, 0.6122045402019032, 0.6502487001995554, 0.5753440094582323, 0.7806808647603052, 0.71720058869223, 0.6881885580490787, 0.7809952530947624, 0.7785953858263277, 0.5987801183375635, 0.7805086189722381, 0.7588061595738733, 0.7387025833488723, 0.5752978420093512, 0.769754850105597, 0.74078963874839, 0.5751982767191514, 0.7801740396836923, 0.6112302328443303, 0.5964060395779693, 0.7738259793530534, 0.7802797636670514, 0.7681716306536914, 0.5015078049111137, 0.6062333986923392, 0.4953588034144265, 0.5720883319387243, 0.7824069047261336, 0.7835163402317455, 0.784324189410462, 0.7844812581146425, 0.7844949075128879, 0.6092140992098264, 0.7844418962333191, 0.7808267707051348, 0.7843190516491102, 0.7834888394759005, 0.7844771147587137, 0.7769872425575907, 0.7813642838325149, 0.7227449575948441, 0.5690182598348967, 0.7824341182848012, 0.7843709144995034, 0.5141362661744056, 0.6005070067920981, 0.7834837372290281, 0.7845230348528888, 0.7843920574529, 0.7844869639799887, 0.783101449433721, 0.7843920574529, 0.7843017205831682, 0.5178050024866223, 0.7841647529466466, 0.7841647529466466, 0.7843920574529, 0.5448825071331632, 0.7480215853513328, 0.7843920574529, 0.7297203576448705, 0.5578921547039546, 0.6165254985355147, 0.5949337154017006, 0.5697626835568811, 0.7775165402973295, 0.7819066742865157, 0.7826542155947674, 0.7831252204585925, 0.7843901041565335, 0.7843887190918373, 0.7843901041565335, 0.782124943691798, 0.7841053845752668, 0.7826542155947674, 0.7830505808610754, 0.7831372598671056, 0.7831372598671056, 0.7827667491417933, 0.7827731535862433, 0.7807926412139402, 0.7830436910520737, 0.7830505808610754, 0.783099413270236, 0.7831372598671056, 0.7831369283986314, 0.7843572414249383, 0.7843674932713222, 0.7831372598671056, 0.7827731535862433, 0.7831372598671056, 0.7831397932333022, 0.7831397932333022, 0.7807941210604161, 0.7830505808610754, 0.782373210952648, 0.7841978879559169, 0.7831251020769946, 0.7832418144944288, 0.7843709144995034, 0.7843901041565335, 0.7843724297839574, 0.7843780410717008, 0.7845693694103325, 0.7845693694103325, 0.7808242136626189, 0.7846368705974924, 0.784583006970418, 0.7844885029407622, 0.7824503626107466, 0.7845498837993075, 0.7845498837993075, 0.7845879316448935, 0.7844962689012647, 0.7846492769889591, 0.7824786201705052, 0.7841647529466466, 0.5159128273576719, 0.7841647529466466, 0.7844484899606501, 0.7843618465967748, 0.7844885029407622, 0.7844869639799887, 0.7844976893527644, 0.7843572414249383, 0.7842540600241515, 0.7842540600241515, 0.7832805252769635, 0.7833251906538757, 0.784249147187836, 0.7846368705974924, 0.7842545927413426, 0.7844383901113409, 0.7843002052987141, 0.7836049954998241, 0.7819131734362439, 0.7844418962333191, 0.7844949075128879, 0.7843451547914617, 0.7846450744422314, 0.7841647529466466, 0.784486289332556, 0.7844949075128879, 0.7844949075128879, 0.784260026456689, 0.784249147187836, 0.7844771147587137, 0.7844571081409818, 0.784502235333802, 0.7843724297839574, 0.7824069047261336, 0.7844571081409818, 0.7843707250889467, 0.7843017205831682, 0.7842540600241515, 0.7844418962333191, 0.7844949075128879, 0.7841053845752668, 0.7845036202708224, 0.7841647529466466, 0.7831359458313681, 0.7844484899606501, 0.5743895118663026, 0.7843780410717008, 0.513654731411941, 0.7844949075128879, 0.75911302120324, 0.7844190130704323, 0.7831252204585925, 0.7844484899606501, 0.784486289332556, 0.7841637230267442, 0.5187589786183111, 0.784260026456689, 0.784487567853814, 0.7845244909465439, 0.7844411385910919]] \n",
      "\n",
      "mean AUC :  0.7254754337021958\n",
      "All std:  [[0.08509658227957921, 0.08048034427315905, 0.0565118577517469, 0.06915625926608596, 0.05908040999869688, 0.08452731893062576, 0.06363562628522197, 0.09470530944808951, 0.07401133086207684, 0.0939692056137636, 0.1325430889130574, 0.11213163813268422, 0.10031986185091456, 0.10628018517258704, 0.07389512892177756, 0.09708779053633601, 0.09695777073964802, 0.10460013377795266, 0.0931648637513428, 0.07203515860237224, 0.06919361525857844, 0.0654255152761787, 0.056019878600167244, 0.09159327429823517, 0.10144459319896647, 0.0776429600208961, 0.07961383668529626, 0.11359836756841188, 0.13783377442396033, 0.15801566280331186, 0.11686258471098952, 0.11662734603335882, 0.08206434605603992, 0.11581269002613787, 0.130881188028364, 0.1433240642445763, 0.07871922029948808, 0.1167800325294932, 0.1482679801336212, 0.11164011059618066, 0.11406792988730728, 0.11326508642275633, 0.09233047016033094, 0.1337422081021432, 0.11491666101858658, 0.1317386479939876, 0.08124921466198019, 0.0984793388139557, 0.07466342558940611, 0.07280665097781062, 0.11575538368430473, 0.11630644914949366, 0.11607494101910022, 0.1161756838645625, 0.1161667365399307, 0.08442036946144725, 0.11615067072928312, 0.11893843213645491, 0.11607368440695051, 0.1160349556774545, 0.1161850693839747, 0.1329093722918327, 0.114409251143543, 0.12925840850618564, 0.045800365415828485, 0.11430098677953955, 0.11612921332842092, 0.06686015604347194, 0.10013720482216426, 0.11627230585912494, 0.11615350239861374, 0.11609844851264751, 0.11616263853873611, 0.1158393699829841, 0.11609844851264751, 0.11606810986660882, 0.08284455960388343, 0.11647539327521717, 0.11647539327521717, 0.11609844851264751, 0.059655196766492315, 0.14465333091033725, 0.11609844851264751, 0.14571532669672288, 0.04677094312393, 0.09448576359332832, 0.09150493706335773, 0.04804112847918903, 0.1326605427203923, 0.11630312354755926, 0.11595228759069459, 0.11615424791218011, 0.11649379780040825, 0.11651290802309294, 0.11649379780040825, 0.11621989781683069, 0.11649737622636894, 0.11595228759069459, 0.1162200429296075, 0.11605817103346458, 0.11605817103346458, 0.11575288542823149, 0.11575468035292101, 0.11893378682551305, 0.1162182289422101, 0.1162200429296075, 0.11583883343996719, 0.11605817103346458, 0.11605808397976308, 0.11649535198821684, 0.11640683294404958, 0.11605817103346458, 0.11575468035292101, 0.11605817103346458, 0.1160588364953846, 0.1160588364953846, 0.11890046667453913, 0.1162200429296075, 0.11428746847475804, 0.11604766725106078, 0.11615422578001437, 0.11598070813778434, 0.11612921332842092, 0.11649379780040825, 0.11612958531195006, 0.11613132155120375, 0.11614062971234322, 0.11614062971234322, 0.11893778195552017, 0.11618771041624455, 0.11611784082476859, 0.11616302858742517, 0.1156757103842337, 0.11610863865097987, 0.11610863865097987, 0.11617327743387788, 0.11619003482740858, 0.11616453711810516, 0.11589626296570357, 0.11647539327521717, 0.07865407874831598, 0.11647539327521717, 0.11614317560472544, 0.11612577857873597, 0.11616302858742517, 0.11616263853873611, 0.11616597939937633, 0.11649535198821684, 0.11654329340372507, 0.11654329340372507, 0.11597438223188024, 0.11590030960040917, 0.11654173458307855, 0.11618771041624455, 0.11654315475103973, 0.11626157377794183, 0.11606773908103371, 0.11604384977731323, 0.11629497975892557, 0.11615067072928312, 0.1161667365399307, 0.11615217456962498, 0.11607778693773842, 0.11647539327521717, 0.11616456797732581, 0.1161667365399307, 0.1161667365399307, 0.1165333106494111, 0.11654173458307855, 0.1161850693839747, 0.11614534737152675, 0.11618006347759167, 0.11612958531195006, 0.11575538368430473, 0.11614534737152675, 0.1161291547354547, 0.11606810986660882, 0.11654329340372507, 0.11615067072928312, 0.1161667365399307, 0.11649737622636894, 0.11617893194858746, 0.11647539327521717, 0.11615722400073407, 0.11614317560472544, 0.055405875836805826, 0.11613132155120375, 0.08473919087141878, 0.1161667365399307, 0.13246739691352707, 0.11616688615112741, 0.11615424791218011, 0.11614317560472544, 0.11616456797732581, 0.11604078209152663, 0.06832151230411661, 0.1165333106494111, 0.11618770034601682, 0.11616420107630249, 0.11615043412419929]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 0.1), ('learning_rate', 0.009283153192967708), ('max_depth', 1), ('min_data_in_leaf', 100), ('num_leaves', 10)]) \n",
      "\n",
      "Best index/iterasi :  137\n",
      "Best AUC : 0.7846492769889591 ( std: 0.11616453711810516 ) \n",
      "\n",
      "running time:  1397.194108247757  detik. Dalam menit:  23.28656847079595  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  52 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.545923348800197, 0.5024151708619101, 0.5005568818650886, 0.5294465032608482, 0.581439225233511, 0.5156045606240541, 0.5002167075759028, 0.5825868779392342, 0.5745761176532752, 0.503893169120701, 0.6123558265435624, 0.6165254985355147, 0.5980947161761838, 0.6294653655066025, 0.6048027930162905, 0.6749600963841965, 0.6226351459990981, 0.6504766636282494, 0.6091727517862803, 0.5685848660007482, 0.6375976526651315, 0.7799273934797459, 0.7461488393996785, 0.7325074486245543, 0.7843724297839574, 0.6838439926961059, 0.7819066742865157, 0.7800405262957231, 0.7742000427902751, 0.7843572414249383, 0.7700703776007408, 0.569337092211084, 0.7804555840163495, 0.7802000008165247, 0.6180095312543706, 0.7845927616140904, 0.6118577687145027, 0.7807642656047832, 0.6375976526651315, 0.7800646761417079, 0.7830980518818594, 0.7844382765971661, 0.7807798446230755, 0.7825915917294437, 0.7781540590151704, 0.7844467360139976, 0.7836308855552993, 0.7843283801190299, 0.7844382362152637, 0.7844467360139976, 0.7824236675604055, 0.7836293465945258, 0.7844031247500814, 0.7843002052987141, 0.7843204011993272, 0.7836308855552993, 0.7834975760378302, 0.752428747670352, 0.7562448724341797, 0.758793100431389, 0.7675158766032534, 0.7685274778332949, 0.7603553237785577, 0.5358415581591585, 0.5625407412719463, 0.5929521753248136, 0.6109666935532403, 0.7845244909465439, 0.5699037201693671, 0.7842540600241515, 0.7844484899606501, 0.5383963312796234, 0.7807397951197723, 0.7742031513103715, 0.7810753353580183, 0.5109835218249884, 0.7824031165149987, 0.7824236675604055, 0.6075287164977616, 0.7843901041565335, 0.6844178655942927, 0.5143042281503976, 0.5712797070347374, 0.6946728071030859, 0.7800039345437919, 0.78053462004835, 0.7388154765304835, 0.6296292602084705, 0.7534160049472061, 0.7813531204478266, 0.6925207631980755, 0.784260026456689, 0.47703014501915947, 0.7842540600241515, 0.6226384606838411, 0.7842540600241515, 0.7794983205930412, 0.784260026456689, 0.7845498837993075, 0.7846492769889591, 0.7843707250889467, 0.7774189229333379, 0.7636162366464554, 0.7841978879559169, 0.7844949075128879, 0.7844869639799887, 0.7844869639799887, 0.7843707250889467, 0.7844190130704323, 0.7841053845752668, 0.7803409951587592, 0.784249147187836, 0.7844976893527644, 0.784216047693045, 0.7844759426532184, 0.7844869639799887, 0.7845193768615117, 0.668375871254731, 0.7842540600241515, 0.7842545927413426, 0.7842545927413426, 0.7844190130704323, 0.7844484899606501, 0.7844475073933869, 0.7841647529466466, 0.784260026456689, 0.7844571081409818, 0.7842545927413426, 0.7842540600241515, 0.7844976893527644, 0.7843724297839574, 0.784260026456689, 0.784260026456689, 0.7844484899606501, 0.7842540600241515, 0.7842540600241515, 0.7844759426532184, 0.7845060708975761, 0.7844349827479978, 0.7842540600241515, 0.784249147187836, 0.7844485254751294, 0.7844957953748727, 0.784486289332556, 0.7844571081409818, 0.7844249203121708, 0.784249147187836, 0.7844571081409818, 0.7809478767792565, 0.7844288979338624, 0.784260026456689, 0.7843613020414242, 0.7844571081409818, 0.7845060708975761, 0.7842540600241515, 0.784516370096599, 0.7844249203121708, 0.7841053845752668, 0.7843604023412796, 0.7843618465967748, 0.7806772327699879, 0.784260026456689, 0.7843499492461792, 0.7842540600241515, 0.7844885029407622, 0.7841053845752668, 0.7843891334274301, 0.784486289332556, 0.7844869639799887, 0.7846235171532419, 0.7846368705974924, 0.7845877777488162, 0.7846147805913121, 0.7845694641156108, 0.7845945254999002, 0.7831394380885083, 0.7845036202708224, 0.784249147187836, 0.7844869639799887, 0.7844571081409818, 0.7843367022176914, 0.7842540600241515, 0.7844759426532184, 0.784260026456689, 0.7844484899606501, 0.7845193768615117, 0.7845244909465439, 0.7846492769889591, 0.7844571081409818, 0.7843920574529, 0.6852290917847985, 0.7841647529466466, 0.7843780410717008, 0.7845193768615117, 0.7843920574529, 0.7786012575535868, 0.7841978879559169, 0.7846450744422314, 0.7790797914870425, 0.7823661198949299]] \n",
      "\n",
      "mean AUC :  0.7397332290261077\n",
      "All std:  [[0.04611465589281721, 0.10451836937520582, 0.057820887729140645, 0.06522407438197776, 0.06959343088164638, 0.07082716065260375, 0.08930960201339354, 0.06522439977937473, 0.05994710616591274, 0.07199087973774786, 0.09396330252650863, 0.09448576359332832, 0.08553656499176304, 0.10315833137399173, 0.0882655750898299, 0.16648261933350672, 0.09709398991956555, 0.07697331620950551, 0.07068365848310577, 0.04675966312314391, 0.10530241411482372, 0.12429199053356291, 0.1362673274085518, 0.13648136431453428, 0.11612958531195006, 0.16349396489677448, 0.11630312354755926, 0.11649531375089364, 0.11481676661490678, 0.11649535198821684, 0.11677637140839185, 0.12713281956554812, 0.11519237763429681, 0.114071566750626, 0.06920888505517712, 0.11616312295350342, 0.06889080431095475, 0.11891161475363199, 0.10530241411482372, 0.1163763556194544, 0.1161259608700629, 0.11711774624768861, 0.11891618017476166, 0.11570347067039367, 0.11666628527427621, 0.11626360344588307, 0.11607664277377704, 0.11607596666119349, 0.11626183049442958, 0.11626360344588307, 0.11572001156207161, 0.11607631116246792, 0.11621203911853456, 0.11606773908103371, 0.11607374520087362, 0.11607664277377704, 0.11603700226815278, 0.14021628921428883, 0.13684914279736476, 0.13282377735118953, 0.12340953819180882, 0.11722475248914271, 0.12455491063041796, 0.05934766020411025, 0.10318049950060856, 0.0396162197186661, 0.08807352680841923, 0.11616420107630249, 0.04593669931995795, 0.11654329340372507, 0.11614317560472544, 0.08677439608648999, 0.11367275468024951, 0.11525296302749717, 0.11633251844206353, 0.08245635434356409, 0.11575412181910394, 0.11572001156207161, 0.0852368397299571, 0.11649379780040825, 0.13999917896450434, 0.08614615012023107, 0.04940679112932391, 0.15408010914475023, 0.11643810517096802, 0.1237014416995846, 0.14964093122875702, 0.06412217093128698, 0.1389429457300242, 0.11441445913990429, 0.15513971919456973, 0.1165333106494111, 0.08845918447619214, 0.11654329340372507, 0.09708779053633601, 0.11654329340372507, 0.12254874166417189, 0.1165333106494111, 0.11610863865097987, 0.11616453711810516, 0.1161291547354547, 0.1218426833749688, 0.12619861155834844, 0.11604766725106078, 0.1161667365399307, 0.11616263853873611, 0.11616263853873611, 0.1161291547354547, 0.11616688615112741, 0.11649737622636894, 0.12357776602121755, 0.11654173458307855, 0.11616597939937633, 0.11653177745532013, 0.11616178447511552, 0.11616263853873611, 0.11617274667900875, 0.11191011364888882, 0.11654329340372507, 0.11654315475103973, 0.11654315475103973, 0.11616688615112741, 0.11614317560472544, 0.11616138741669423, 0.11647539327521717, 0.1165333106494111, 0.11614534737152675, 0.11654315475103973, 0.11654329340372507, 0.11616597939937633, 0.11612958531195006, 0.1165333106494111, 0.1165333106494111, 0.11614317560472544, 0.11654329340372507, 0.11654329340372507, 0.11616178447511552, 0.11614509455684158, 0.11614814822895607, 0.11654329340372507, 0.11654173458307855, 0.11614318454914824, 0.11618988621416379, 0.11616456797732581, 0.11614534737152675, 0.11615720346815646, 0.11654173458307855, 0.11614534737152675, 0.11684618779372843, 0.1161466141463635, 0.1165333106494111, 0.11612560998199822, 0.11614534737152675, 0.11614509455684158, 0.11654329340372507, 0.11612788577058823, 0.11615720346815646, 0.11649737622636894, 0.11614806309899546, 0.11612577857873597, 0.11323832052897607, 0.1165333106494111, 0.11614541979417464, 0.11654329340372507, 0.11616302858742517, 0.11649737622636894, 0.11650510722859832, 0.11616456797732581, 0.11616263853873611, 0.11615720348715815, 0.11618771041624455, 0.11617353465319938, 0.11612840632173865, 0.11614047144951074, 0.11616358373046737, 0.1160587391777487, 0.11617893194858746, 0.11654173458307855, 0.11616263853873611, 0.11614534737152675, 0.11610843858807718, 0.11654329340372507, 0.11616178447511552, 0.1165333106494111, 0.11614317560472544, 0.11617274667900875, 0.11616420107630249, 0.11616453711810516, 0.11614534737152675, 0.11609844851264751, 0.1624542350782252, 0.11647539327521717, 0.11613132155120375, 0.11617274667900875, 0.11609844851264751, 0.11662014458710336, 0.11604766725106078, 0.11607778693773842, 0.11697697655999005, 0.11429512098483358]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 0.5425999095739019), ('learning_rate', 0.009284875881806286), ('max_depth', 1), ('min_data_in_leaf', 6), ('num_leaves', 43)]) \n",
      "\n",
      "Best index/iterasi :  99\n",
      "Best AUC : 0.7846492769889591 ( std: 0.11616453711810516 ) \n",
      "\n",
      "running time:  1448.4386975765228  detik. Dalam menit:  24.140644959608714  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  62 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.48214849249737163, 0.5305695106786148, 0.6111983637113516, 0.5464141761618034, 0.47995799635172515, 0.5162848108907219, 0.5067483470927869, 0.500583105575272, 0.5199895583365537, 0.5216016850569904, 0.5933833539742505, 0.6165254985355147, 0.718253178312024, 0.6165254985355147, 0.7341349351570633, 0.7782394033276377, 0.7798264676356178, 0.6109528750243057, 0.7593958200676834, 0.7240541571534463, 0.511671546984187, 0.6053986328231976, 0.7392774962908771, 0.7816101791982718, 0.7831271855931187, 0.6357872846767343, 0.7836308855552993, 0.7806405552631704, 0.7801519141630324, 0.7809260945652309, 0.7807008470110144, 0.7825867250574026, 0.776222215888797, 0.7844382765971661, 0.7826748956715673, 0.7844032431316793, 0.7842977192851569, 0.7843002052987141, 0.5241252246910975, 0.7844431372134194, 0.7844467360139976, 0.7844249203121708, 0.7836293465945258, 0.7781680043674107, 0.7836639502462488, 0.7807323365160731, 0.7836029593363392, 0.7825867250574026, 0.533983557742026, 0.7836020122835555, 0.7835989343620084, 0.7836207402523537, 0.7834021604698702, 0.5637654259059065, 0.784442983317342, 0.5099687414194741, 0.5476272367200908, 0.5914563493560712, 0.6375976526651315, 0.7485742889314333, 0.7662782065311184, 0.7355219842391582, 0.7842545927413426, 0.7387025833488723, 0.6380239117458589, 0.7841053845752668, 0.7523719863491993, 0.7845498837993075, 0.7843572414249383, 0.7844763214743318, 0.7831264989798505, 0.7803707799688072, 0.7846357578104716, 0.7842366224147713, 0.7842545927413426, 0.7841647529466466, 0.7845193768615117, 0.7842540600241515, 0.7843451547914617, 0.7720431430774897, 0.5551864987438484, 0.5099687414194741, 0.587816131217571, 0.7801914515579964, 0.784502235333802, 0.7844997729965643, 0.7844812581146425, 0.7844997729965643, 0.7824069047261336, 0.7841053845752668, 0.7844885029407622, 0.7844190130704323, 0.784493972298264, 0.7843920574529, 0.7844249203121708, 0.7846492769889591, 0.7844349827479978, 0.7844885029407622, 0.7844869639799887, 0.7844484899606501, 0.7844571081409818, 0.7841053845752668, 0.7844484899606501, 0.7844571081409818, 0.7842540600241515, 0.7844191077757108, 0.7844349827479978, 0.7844571081409818, 0.784249147187836, 0.7843789289336854, 0.7844771147587137, 0.7844190130704323, 0.7844771147587137, 0.7844771147587137, 0.7844349827479978, 0.7844962689012647, 0.7844349827479978, 0.7842545927413426, 0.7844910245964747, 0.7843451547914617, 0.7844418962333191, 0.784487567853814, 0.7795908105572781, 0.7843509673279218, 0.7794983205930412, 0.784493972298264, 0.7843618465967748, 0.784493972298264, 0.784493972298264, 0.7843451547914617, 0.7844249203121708, 0.7845016079113327, 0.7843618465967748, 0.784502235333802, 0.7845005306387913, 0.784502235333802, 0.7845056920764626, 0.7844997848347242, 0.7844997729965643, 0.7805993140022071, 0.7101691335801956, 0.7844881242473244, 0.784478961511642, 0.7844997729965643, 0.7845005306387913, 0.7844812581146425, 0.5063612470828927, 0.7845020814377247, 0.7844881242473244, 0.7844894501212217, 0.7824031165149987, 0.78425415472943, 0.7844571081409818, 0.7844349827479978, 0.7844411385910919, 0.7844445834955928, 0.784260026456689, 0.7845060708975761, 0.7844191077757108, 0.7844484899606501, 0.7844910245964747, 0.7844445834955928, 0.7843637170260226, 0.7842538824517548, 0.7843637170260226, 0.7844881242473244, 0.7844191077757108, 0.7843604023412796, 0.7843618465967748, 0.7844955822879963, 0.7844771147587137, 0.7843451547914617, 0.7843604023412796, 0.7843451547914617, 0.7843451547914617, 0.7844771147587137, 0.7844771147587137, 0.7845032534155445, 0.7844771147587137, 0.7844962689012647, 0.7844771147587137, 0.7844418250766846, 0.7843451547914617, 0.7843509673279218, 0.7844771147587137, 0.7845016079113327, 0.7844889174040308, 0.7844249203121708, 0.7806844997007001, 0.5143779870922249, 0.673778310711369, 0.6641064898829311, 0.566156379921189, 0.6637306263014305, 0.525912865310124, 0.5859106030329895, 0.611689093555728, 0.5496984840247885, 0.49789707608305944, 0.5627621790430357]] \n",
      "\n",
      "mean AUC :  0.7371479247885688\n",
      "All std:  [[0.08598785542204988, 0.06465818388274674, 0.10342693927491325, 0.06799111696833081, 0.0723933105742498, 0.06625154542969224, 0.07436999000064363, 0.08516131749687553, 0.07748249134731112, 0.07856786827250792, 0.09140958262527123, 0.09448576359332832, 0.1324598407715983, 0.09448576359332832, 0.13330010613234372, 0.12394531945306407, 0.11339112302524809, 0.08980865704184485, 0.13000910746250813, 0.14954992911574055, 0.11599263934106975, 0.09994387620904076, 0.14997995648288742, 0.11324408755518392, 0.11615477284666423, 0.1044713457869743, 0.11607664277377704, 0.11522270685102708, 0.11407553444510986, 0.11681056898699903, 0.11645805119717523, 0.11613386851799005, 0.11413003346234786, 0.11711774624768861, 0.1161163216009428, 0.11621234385309423, 0.1160669557268976, 0.11606773908103371, 0.07204471235598847, 0.11626247592053232, 0.11626360344588307, 0.11615720346815646, 0.11607631116246792, 0.11664266910494463, 0.11633650812786925, 0.11646177310861983, 0.11607089834573421, 0.11613386851799005, 0.0639783484348297, 0.116070530758079, 0.11606975937921206, 0.11601423061737413, 0.11633685416464214, 0.05766743147179843, 0.11626273264131179, 0.06077183876731375, 0.07217620169449972, 0.08569427320120994, 0.10530241411482372, 0.13317596474850527, 0.11996534941883598, 0.15005788130976933, 0.11654315475103973, 0.1433240642445763, 0.14372580780868097, 0.11649737622636894, 0.1396862255787669, 0.11610863865097987, 0.11649535198821684, 0.11616190297409751, 0.11615458363769061, 0.12352714934396242, 0.1161874196160235, 0.11605967703248508, 0.11654315475103973, 0.11647539327521717, 0.11617274667900875, 0.11654329340372507, 0.11615217456962498, 0.1158874664928095, 0.050485439501757656, 0.06077183876731375, 0.07730104791331664, 0.11389566997329584, 0.11618006347759167, 0.11618108805543237, 0.1161756838645625, 0.11618108805543237, 0.11575538368430473, 0.11649737622636894, 0.11616302858742517, 0.11616688615112741, 0.11618931412346865, 0.11609844851264751, 0.11615720346815646, 0.11616453711810516, 0.11614814822895607, 0.11616302858742517, 0.11616263853873611, 0.11614317560472544, 0.11614534737152675, 0.11649737622636894, 0.11614317560472544, 0.11614534737152675, 0.11654329340372507, 0.11616691569738138, 0.11614814822895607, 0.11614534737152675, 0.11654173458307855, 0.11651698094363755, 0.1161850693839747, 0.11616688615112741, 0.1161850693839747, 0.1161850693839747, 0.11614814822895607, 0.11619003482740858, 0.11614814822895607, 0.11654315475103973, 0.11616605425766091, 0.11615217456962498, 0.11615067072928312, 0.11618770034601682, 0.12240703235300526, 0.11614246480879273, 0.12254874166417189, 0.11618931412346865, 0.11612577857873597, 0.11618931412346865, 0.11618931412346865, 0.11615217456962498, 0.11615720346815646, 0.11618017206847985, 0.11612577857873597, 0.11618006347759167, 0.1161796338837001, 0.11618006347759167, 0.1161697280039561, 0.11617960002116003, 0.11618108805543237, 0.11673846661670709, 0.15042511236342196, 0.11618798885493423, 0.11617510550706625, 0.11618108805543237, 0.1161796338837001, 0.1161756838645625, 0.07619432355351047, 0.11618032067045993, 0.11618798885493423, 0.1161783958413499, 0.11575412181910394, 0.1165433231142344, 0.11614534737152675, 0.11614814822895607, 0.11615043412419929, 0.11613210739062971, 0.1165333106494111, 0.11614509455684158, 0.11616691569738138, 0.11614317560472544, 0.11616605425766091, 0.11613210739062971, 0.11612635774781215, 0.11654293192322848, 0.11612635774781215, 0.11618798885493423, 0.11616691569738138, 0.11614806309899546, 0.11612577857873597, 0.11618992474293849, 0.1161850693839747, 0.11615217456962498, 0.11614806309899546, 0.11615217456962498, 0.11615217456962498, 0.1161850693839747, 0.1161850693839747, 0.1161804885326118, 0.1161850693839747, 0.11619003482740858, 0.1161850693839747, 0.11615123380910207, 0.11615217456962498, 0.11614246480879273, 0.1161850693839747, 0.11618017206847985, 0.11618812391126758, 0.11615720346815646, 0.11889732735118481, 0.05534809235323757, 0.16243230885446985, 0.09752639306819706, 0.04442312050457088, 0.12951002090527064, 0.08251411880362661, 0.09007833167691481, 0.07380930069335405, 0.07779642584209731, 0.09708722466728968, 0.06122778570726287]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 0.1), ('learning_rate', 0.009281661585592661), ('max_depth', 1), ('min_data_in_leaf', 100), ('num_leaves', 100)]) \n",
      "\n",
      "Best index/iterasi :  95\n",
      "Best AUC : 0.7846492769889591 ( std: 0.11616453711810516 ) \n",
      "\n",
      "running time:  1544.287121295929  detik. Dalam menit:  25.738118688265484  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  72 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.5457725116732949, 0.5051354876440889, 0.5089064223550984, 0.6019611337783771, 0.5686479300458046, 0.5267044579779474, 0.5030219351732124, 0.5095235143727361, 0.5635593378196627, 0.5865576648879217, 0.6312068600039997, 0.62249015221791, 0.6050723837968683, 0.6165254985355147, 0.730307960595383, 0.7330828215175212, 0.7331354066233374, 0.5833887056266656, 0.7341349351570633, 0.7319000563217133, 0.7844997729965643, 0.7808379334644854, 0.7537666489423825, 0.5366392815881139, 0.5760292262556816, 0.7807434886256288, 0.7329448195931398, 0.597426675866201, 0.6215163441180759, 0.5734226612752319, 0.5486378892571654, 0.7812271957886624, 0.7674793988244616, 0.7801713524214183, 0.5630574534138885, 0.7670194220577292, 0.7684007290142341, 0.7657162749946047, 0.7319000563217133, 0.7673934311279729, 0.7562590949514718, 0.5036978065120338, 0.572729573820638, 0.7833375129898592, 0.7836040957996796, 0.7834121762636961, 0.7801872247719217, 0.7844997729965643, 0.784487567853814, 0.7844249203121708, 0.7844383901113409, 0.5788826280812531, 0.7841637230267442, 0.7845927616140904, 0.7844885029407622, 0.7843901041565335, 0.7781408594149555, 0.7821925487959931, 0.7845927616140904, 0.7846450744422314, 0.784249147187836, 0.7843367022176914, 0.7845877777488162, 0.7843572414249383, 0.7404588819687092, 0.7831252204585925, 0.7843920574529, 0.7846147805913121, 0.7831397932333022, 0.7846368705974924, 0.7844869639799887, 0.7843572414249383, 0.7846368705974924, 0.7846505081575781, 0.7845244909465439, 0.7843920574529, 0.7846368705974924, 0.7845945254999002, 0.7846368705974924, 0.7846368705974924, 0.7845230348528888, 0.7843920574529, 0.7846147805913121, 0.7843367022176914, 0.7844976893527644, 0.7844881242473244, 0.7843709144995034, 0.7843761706424531, 0.7742393150379785, 0.7844349827479978, 0.7843844691924704, 0.7844976893527644, 0.5027471646776223, 0.7843780410717008, 0.7843604023412796, 0.74235748604363, 0.7845060708975761, 0.7845060708975761, 0.7842540600241515, 0.7813649349313034, 0.7843604023412796, 0.5084033964402729, 0.784516370096599, 0.7843844691924704, 0.7845016079113327, 0.7845694641156108, 0.6133953877526829, 0.7843604023412796, 0.5504906998499013, 0.5670929335062518, 0.784249147187836, 0.7844418962333191, 0.783295027022714, 0.7843618465967748, 0.7845020814377247, 0.7843724297839574, 0.7175294221150297, 0.7733347116660124, 0.7815831290031366, 0.7844997729965643, 0.7844307920394298, 0.7843283801190299, 0.7844385084929388, 0.784324189410462, 0.7844997729965643, 0.7824031165149987, 0.7844475073933869, 0.784493972298264, 0.7844190130704323, 0.7843709144995034, 0.7843618465967748, 0.7792144032020889, 0.6919815883714513, 0.7824214893390029, 0.7842540600241515, 0.784260026456689, 0.7843887190918373, 0.7844763214743318, 0.784260026456689, 0.784260026456689, 0.7845244909465439, 0.7842545927413426, 0.7844349827479978, 0.784260026456689, 0.7844976893527644, 0.7845193768615117, 0.7844976893527644, 0.7844869639799887, 0.7843780410717008, 0.7844885029407622, 0.7844869639799887, 0.784497286983007, 0.7842540600241515, 0.784249147187836, 0.784260026456689, 0.7842540600241515, 0.784260026456689, 0.7845036202708224, 0.7844976893527644, 0.7844885029407622, 0.7843709144995034, 0.784249147187836, 0.7844249203121708, 0.7845244909465439, 0.784249147187836, 0.7845032534155445, 0.7844885029407622, 0.784249147187836, 0.784260026456689, 0.7845193768615117, 0.784249147187836, 0.7845193768615117, 0.7843761706424531, 0.7844759426532184, 0.7842545927413426, 0.784260026456689, 0.7844976893527644, 0.7843367022176914, 0.7843674932713222, 0.7844976893527644, 0.784249147187836, 0.7845193768615117, 0.7844418962333191, 0.7844383901113409, 0.7842545927413426, 0.7844881242473244, 0.7844249203121708, 0.7794941298844733, 0.7806440046969115, 0.7844976893527644, 0.7841053845752668, 0.784249147187836, 0.7844571081409818, 0.7843367022176914, 0.7845498837993075, 0.7843002052987141, 0.78425415472943, 0.7844976893527644, 0.7846450744422314, 0.7841245742322971]] \n",
      "\n",
      "mean AUC :  0.7470556660085569\n",
      "All std:  [[0.05857871286677766, 0.07952479238122583, 0.06944764798974921, 0.09312708696761883, 0.08888286907886513, 0.06602214162676412, 0.07476652536371027, 0.059921516633047706, 0.07312882541213615, 0.06547345608098266, 0.10108934814800234, 0.09705616388257225, 0.07840122278415654, 0.09448576359332832, 0.13329201322818318, 0.13583796474720497, 0.13593038890076936, 0.056688173475181645, 0.13330010613234372, 0.1363641954963276, 0.11618108805543237, 0.11383408537290103, 0.13873263835724883, 0.08690917993890711, 0.10772885443981871, 0.1136729655716598, 0.15033874729759186, 0.09812187238203128, 0.19479685266552138, 0.09635104754873289, 0.03953654713237933, 0.11598989136548617, 0.11768686045086325, 0.11408042606876521, 0.04893753272604451, 0.1195753700330742, 0.11731216397677882, 0.1196652921243353, 0.1363641954963276, 0.11858057412038832, 0.13593157480480947, 0.04958967643374844, 0.08053028240453176, 0.1163991800359772, 0.11607097770700704, 0.11627446846776189, 0.11628008085532042, 0.11618108805543237, 0.11618770034601682, 0.11615720346815646, 0.11626157377794183, 0.06165429938668124, 0.11604078209152663, 0.11616312295350342, 0.11616302858742517, 0.11649379780040825, 0.1166357157594647, 0.1142431208381054, 0.11616312295350342, 0.11607778693773842, 0.11654173458307855, 0.11610843858807718, 0.11617353465319938, 0.11649535198821684, 0.1482017756589851, 0.11615424791218011, 0.11609844851264751, 0.11612840632173865, 0.1160588364953846, 0.11618771041624455, 0.11616263853873611, 0.11649535198821684, 0.11618771041624455, 0.1161649148905855, 0.11616420107630249, 0.11609844851264751, 0.11618771041624455, 0.11616358373046737, 0.11618771041624455, 0.11618771041624455, 0.11615350239861374, 0.11609844851264751, 0.11612840632173865, 0.11610843858807718, 0.11616597939937633, 0.11618798885493423, 0.11612921332842092, 0.11613074268716443, 0.1147748950052631, 0.11614814822895607, 0.11650388351279503, 0.11616597939937633, 0.06929078233605233, 0.11613132155120375, 0.11614806309899546, 0.14716579128172771, 0.11614509455684158, 0.11614509455684158, 0.11654329340372507, 0.11441072452981998, 0.11614806309899546, 0.09462575885436958, 0.11612788577058823, 0.11650388351279503, 0.11618017206847985, 0.11614047144951074, 0.11631450789337863, 0.11614806309899546, 0.057232023649071616, 0.0793379397249953, 0.11654173458307855, 0.11615067072928312, 0.11589203092930413, 0.11612577857873597, 0.11618032067045993, 0.11612958531195006, 0.14872901261742089, 0.12383930121474046, 0.11323223371536373, 0.11618108805543237, 0.11614720491619623, 0.11607596666119349, 0.11626187834675764, 0.11607494101910022, 0.11618108805543237, 0.11575412181910394, 0.11616138741669423, 0.11618931412346865, 0.11616688615112741, 0.11612921332842092, 0.11612577857873597, 0.11676959184483489, 0.1510719585435161, 0.11573117572352178, 0.11654329340372507, 0.1165333106494111, 0.11651290802309294, 0.11616190297409751, 0.1165333106494111, 0.1165333106494111, 0.11616420107630249, 0.11654315475103973, 0.11614814822895607, 0.1165333106494111, 0.11616597939937633, 0.11617274667900875, 0.11616597939937633, 0.11616263853873611, 0.11613132155120375, 0.11616302858742517, 0.11616263853873611, 0.11619045989822986, 0.11654329340372507, 0.11654173458307855, 0.1165333106494111, 0.11654329340372507, 0.1165333106494111, 0.11617893194858746, 0.11616597939937633, 0.11616302858742517, 0.11612921332842092, 0.11654173458307855, 0.11615720346815646, 0.11616420107630249, 0.11654173458307855, 0.1161804885326118, 0.11616302858742517, 0.11654173458307855, 0.1165333106494111, 0.11617274667900875, 0.11654173458307855, 0.11617274667900875, 0.11613074268716443, 0.11616178447511552, 0.11654315475103973, 0.1165333106494111, 0.11616597939937633, 0.11610843858807718, 0.11640683294404958, 0.11616597939937633, 0.11654173458307855, 0.11617274667900875, 0.11615067072928312, 0.11626157377794183, 0.11654315475103973, 0.11618798885493423, 0.11615720346815646, 0.12254748852541703, 0.12341640873437792, 0.11616597939937633, 0.11649737622636894, 0.11654173458307855, 0.11614534737152675, 0.11610843858807718, 0.11610863865097987, 0.11606773908103371, 0.1165433231142344, 0.11616597939937633, 0.11607778693773842, 0.11646295846583597]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 0.1), ('learning_rate', 0.00928075269556406), ('max_depth', 1), ('min_data_in_leaf', 1), ('num_leaves', 100)]) \n",
      "\n",
      "Best index/iterasi :  73\n",
      "Best AUC : 0.7846505081575781 ( std: 0.1161649148905855 ) \n",
      "\n",
      "running time:  1682.8537254333496  detik. Dalam menit:  28.047562090555825  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  82 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.4942715959281354, 0.6045308927706087, 0.6485340721688472, 0.511326802067842, 0.5185287050986245, 0.5042685506561442, 0.486540885357533, 0.532314816589847, 0.5103050208657318, 0.570740674589139, 0.47516078140039847, 0.6204629625720764, 0.4952059835502361, 0.6407226714162236, 0.5144652239172528, 0.688442038088326, 0.5770244244668977, 0.6655033192048705, 0.6833927304420827, 0.5149302602102805, 0.6500135441585467, 0.61327415047069, 0.6188961182928283, 0.7195131393841026, 0.6279014003438025, 0.6165254985355147, 0.6165254985355147, 0.6165254985355147, 0.5617917325085475, 0.6165254985355147, 0.7807397951197723, 0.7725364000188802, 0.7734620923512671, 0.7692588105448838, 0.7655868764079229, 0.7770256886888725, 0.7801905755341716, 0.7272805234919476, 0.7295398650880085, 0.7358569742896773, 0.7841053845752668, 0.7844771147587137, 0.5419200195519732, 0.7619034929060619, 0.729959648872708, 0.5233514442036572, 0.6124841222748227, 0.5565036549050127, 0.5083821737338806, 0.78360931642815, 0.6075500357976661, 0.6818471708624142, 0.5823456072291217, 0.5323813906802758, 0.6525058334270305, 0.78360349205353, 0.5673187052008032, 0.6673402025069107, 0.5464551739017066, 0.5510066734583388, 0.6084919244254725, 0.5816207571351135, 0.6059116252769645, 0.7788738313223232, 0.5790007368898927, 0.441756697450523, 0.782481780959171, 0.7819116344754704, 0.6029829383814886, 0.7824728076340453, 0.7832505510563585, 0.6351189901417461, 0.5605175915486396, 0.7826542155947674, 0.6029034201089698, 0.7825831510450075, 0.783101449433721, 0.5477266985503916, 0.6612094413847853, 0.5461048262891594, 0.7832948139358378, 0.7844445834955928, 0.7845016079113327, 0.7835989343620084, 0.7752906862875073, 0.6420543502393973, 0.7733342672881766, 0.5332972016674526, 0.6234014344539878, 0.5651437720286956, 0.514483267392592, 0.5431129467717335, 0.5476981980018223, 0.6090313769265715, 0.5362978639241519, 0.6297074885566204, 0.5485034103491292, 0.5387708691877126, 0.7510006999167238, 0.5797586255477354, 0.5454173216813761, 0.5536571097879065, 0.6232956110650953, 0.6186162936290399, 0.5878456654795727, 0.7806806404606065, 0.5501483995652318, 0.6392021365696802, 0.49597326491854077, 0.6017603298302969, 0.5942640818203644, 0.7843618465967748, 0.5159436188203286, 0.7824069047261336, 0.5820259033975171, 0.6080900249747311, 0.5935682151705877, 0.7843572414249383, 0.7845230348528888, 0.7831252204585925, 0.7845693694103325, 0.6045852878338693, 0.7824787385521033, 0.784486289332556, 0.7843496650026685, 0.7824069047261336, 0.7831396393372247, 0.7832418144944288, 0.7830989752583236, 0.7843901041565335, 0.7844771147587137, 0.7845694641156108, 0.7845693694103325, 0.7845927616140904, 0.7845498837993075, 0.7845498837993075, 0.7845244909465439, 0.7843451547914617, 0.7843744659474424, 0.7843451547914617, 0.7844976893527644, 0.7842540600241515, 0.7843724297839574, 0.7844771147587137, 0.7844571081409818, 0.7843451547914617, 0.7844812581146425, 0.7845020814377247, 0.7833229177271948, 0.7844467360139976, 0.7824541508218815, 0.7846357578104716, 0.784249147187836, 0.7846505081575781, 0.7812728340480865, 0.7843509673279218, 0.784487567853814, 0.7843283801190299, 0.7844997729965643, 0.7844976893527644, 0.7844997729965643, 0.7824031165149987, 0.7844484899606501, 0.7845060708975761, 0.7845060708975761, 0.7844191077757108, 0.7844771147587137, 0.7843604023412796, 0.7844467360139976, 0.7843709144995034, 0.7843451547914617, 0.7843451547914617, 0.7844962689012647, 0.7843002052987141, 0.7844955822879963, 0.7845032534155445, 0.784502235333802, 0.7844467360139976, 0.7844881242473244, 0.7844890713001084, 0.7844812581146425, 0.7844349827479978, 0.7411635010998143, 0.7844771147587137, 0.7845006963730283, 0.7843761706424531, 0.782417701127868, 0.7844771147587137, 0.7844955822879963, 0.7844889174040308, 0.7842540600241515, 0.7844771147587137, 0.7843613020414242, 0.784502235333802, 0.7845032534155445, 0.7844349827479978, 0.7844997729965643, 0.7845193768615117, 0.5766862559290491, 0.7845056920764626]] \n",
      "\n",
      "mean AUC :  0.6953924580427142\n",
      "All std:  [[0.06910431896299361, 0.12092852028153273, 0.13803205078396444, 0.07246721930547166, 0.0857623127118484, 0.08271951692147206, 0.0774056234424914, 0.05814771492817816, 0.06058722847976571, 0.07919480481615317, 0.07855829381304114, 0.09885839869453807, 0.07343343149652073, 0.06885027880436563, 0.07574416367059893, 0.1627128562113949, 0.08478936377796494, 0.16721517837834737, 0.16427501882113382, 0.09607987950724702, 0.12348397901925016, 0.08355820346332503, 0.09055267969401172, 0.1401405371653611, 0.10780605906974083, 0.09448576359332832, 0.09448576359332832, 0.09448576359332832, 0.08913509505801552, 0.09448576359332832, 0.11367275468024951, 0.11571548130983056, 0.11562590449028892, 0.11788066965975373, 0.11976761181235161, 0.1324456105712387, 0.1138956714691678, 0.15002447331532354, 0.14570337129698238, 0.1496023207898767, 0.11649737622636894, 0.1161850693839747, 0.06178390482081671, 0.13522305467895754, 0.1558183369345418, 0.06884595533439443, 0.08338835626784977, 0.21326955476169773, 0.06601146743893241, 0.11605172277002364, 0.08436306692348365, 0.11678710583457133, 0.10632597261179864, 0.06194258293789716, 0.0880674282367604, 0.11607137504094564, 0.0936851663379186, 0.10883541343618833, 0.07746766156893886, 0.12042910833688328, 0.11235195729305548, 0.05290727017318352, 0.08844719602508797, 0.1216915511081361, 0.07164766725286781, 0.09508271717162832, 0.11590917048507375, 0.11629487283345959, 0.08255933045628767, 0.11590100275767767, 0.11596614684974492, 0.10099071549436159, 0.0727412280994185, 0.11595228759069459, 0.1002552645128478, 0.11573849189903224, 0.1158393699829841, 0.07967082664516821, 0.10773464970479722, 0.11530902253352585, 0.11589197517868385, 0.11613210739062971, 0.11618017206847985, 0.11606975937921206, 0.12537081659009391, 0.08555896470439228, 0.1291246602253823, 0.06490933947110525, 0.08290048550354086, 0.08229116997535862, 0.06356360104830679, 0.06125382450493021, 0.060739617807437946, 0.09838908104633469, 0.0655756813002752, 0.025018898689425834, 0.08079807110109072, 0.061605723297934074, 0.14184398835422032, 0.02800662172980358, 0.06844414060083627, 0.09758348175786395, 0.09015016100388829, 0.13108799509286653, 0.0678230553919667, 0.11889688757430533, 0.059135618894637657, 0.10764608128176796, 0.0835128413039475, 0.08517619499321759, 0.10130572189444724, 0.11612577857873597, 0.07796702204807332, 0.11575538368430473, 0.06107466968173674, 0.09905498805607019, 0.04637095510815888, 0.11649535198821684, 0.11615350239861374, 0.11615424791218011, 0.11614062971234322, 0.1049510022689883, 0.11589629222701811, 0.11616456797732581, 0.11650802994759059, 0.11575538368430473, 0.11613171797639653, 0.11598070813778434, 0.11612620363062173, 0.11649379780040825, 0.1161850693839747, 0.11614047144951074, 0.11614062971234322, 0.11616312295350342, 0.11610863865097987, 0.11610863865097987, 0.11616420107630249, 0.11615217456962498, 0.11613031216987292, 0.11615217456962498, 0.11616597939937633, 0.11654329340372507, 0.11612958531195006, 0.1161850693839747, 0.11614534737152675, 0.11615217456962498, 0.1161756838645625, 0.11618032067045993, 0.11589971538053345, 0.11626360344588307, 0.11567697155756364, 0.1161874196160235, 0.11654173458307855, 0.1161649148905855, 0.11444885601070075, 0.11614246480879273, 0.11618770034601682, 0.11607596666119349, 0.11618108805543237, 0.11616597939937633, 0.11618108805543237, 0.11575412181910394, 0.11614317560472544, 0.11614509455684158, 0.11614509455684158, 0.11616691569738138, 0.1161850693839747, 0.11614806309899546, 0.11626360344588307, 0.11612921332842092, 0.11615217456962498, 0.11615217456962498, 0.11619003482740858, 0.11606773908103371, 0.11618992474293849, 0.1161804885326118, 0.11618006347759167, 0.11626360344588307, 0.11618798885493423, 0.11617827693878184, 0.1161756838645625, 0.11614814822895607, 0.1477006669557624, 0.1161850693839747, 0.11618137787114818, 0.11613074268716443, 0.11572991407176977, 0.1161850693839747, 0.11618992474293849, 0.11618812391126758, 0.11654329340372507, 0.1161850693839747, 0.11612560998199822, 0.11618006347759167, 0.1161804885326118, 0.11614814822895607, 0.11618108805543237, 0.11617274667900875, 0.05227819347770968, 0.1161697280039561]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 0.1), ('learning_rate', 0.009281364334429299), ('max_depth', 1), ('min_data_in_leaf', 9), ('num_leaves', 82)]) \n",
      "\n",
      "Best index/iterasi :  153\n",
      "Best AUC : 0.7846505081575781 ( std: 0.1161649148905855 ) \n",
      "\n",
      "running time:  1484.3106014728546  detik. Dalam menit:  24.738510024547576  menit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  92 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [[0.49931150299403143, 0.5120963059478223, 0.49946389991716056, 0.49961541195276266, 0.4714186760534584, 0.6058299282066884, 0.49967230432682536, 0.5064802263220256, 0.574294307174067, 0.5499251057434207, 0.5858967027902315, 0.5567614548600146, 0.6050723837968683, 0.5697270733945149, 0.5880761968538849, 0.5968515258702964, 0.6165254985355147, 0.62249015221791, 0.6165254985355147, 0.6521057756087486, 0.732470395184391, 0.7474229213477814, 0.7468385779420642, 0.7466935604845565, 0.7651002074909761, 0.78053462004835, 0.7803158114266591, 0.7835989580383279, 0.7845032534155445, 0.7730185975805192, 0.7834833347315951, 0.588113913180624, 0.7809497324825769, 0.7808267707051348, 0.7592376718763877, 0.7568348748983159, 0.7808060065728517, 0.58129769490291, 0.6926601775276879, 0.603187735388082, 0.49768943301717145, 0.6063419693523449, 0.7800244263983999, 0.5707665724676168, 0.7801519141630324, 0.7835991000962456, 0.7837796327437807, 0.7825867250574026, 0.6333094686474826, 0.7836049954998241, 0.7834623101597964, 0.6812913816622589, 0.7836098491453408, 0.7810662673276142, 0.784502235333802, 0.5640113368689873, 0.7845498837993075, 0.7843904356250078, 0.7830505808610754, 0.784583006970418, 0.7830980518818594, 0.7843451547914617, 0.7843451547914617, 0.7834974103035932, 0.784487567853814, 0.78425415472943, 0.6548813602166478, 0.5308070915291114, 0.7842540600241515, 0.5344723294497252, 0.5221795568402582, 0.5201481587865772, 0.6902281454306735, 0.6221492245115681, 0.4927572712983603, 0.6235097305975591, 0.7427489560160286, 0.5178237527691082, 0.48968860472203596, 0.46484032247594526, 0.5000573219410714, 0.5996274942722334, 0.5903774514239422, 0.6794929675923104, 0.6719972265013647, 0.7799245050207972, 0.784324189410462, 0.7824031165149987, 0.7824541508218815, 0.7844812581146425, 0.7824031165149987, 0.7824069047261336, 0.7824031165149987, 0.7824031165149987, 0.7844881242473244, 0.784487567853814, 0.7844881242473244, 0.7844191077757108, 0.7844812581146425, 0.7844812581146425, 0.7844812581146425, 0.7844812581146425, 0.7843761706424531, 0.7844997729965643, 0.7844385084929388, 0.7824031165149987, 0.7844812581146425, 0.7843509673279218, 0.7843451547914617, 0.7844997729965643, 0.7845032534155445, 0.784478961511642, 0.7844997729965643, 0.7844997729965643, 0.7843017205831682, 0.7844032431316793, 0.7844997729965643, 0.7844955822879963, 0.7843451547914617, 0.7844997848347242, 0.7844997729965643, 0.7844976893527644, 0.7824031165149987, 0.7843451547914617, 0.7843509673279218, 0.782417701127868, 0.784307900102582, 0.7843451547914617, 0.7844955822879963, 0.7844997729965643, 0.7844445834955928, 0.7845020814377247, 0.7843451547914617, 0.7844307920394298, 0.7844571081409818, 0.7845016079113327, 0.7844771147587137, 0.7844771147587137, 0.7844190130704323, 0.7844997848347242, 0.7844771147587137, 0.7844771147587137, 0.7843637170260226, 0.784487567853814, 0.784487567853814, 0.7844997729965643, 0.7845693694103325, 0.7843637170260226, 0.7843618465967748, 0.7842540600241515, 0.7843618465967748, 0.784324189410462, 0.7844190130704323, 0.784486289332556, 0.7844190130704323, 0.7844771147587137, 0.7841053845752668, 0.7843451547914617, 0.7844909298911962, 0.7843451547914617, 0.7844771147587137, 0.7844771147587137, 0.784487567853814, 0.6853955406816957, 0.784487567853814, 0.7843618465967748, 0.7845060708975761, 0.7844949075128879, 0.7843499492461792, 0.7845016079113327, 0.7844349827479978, 0.784486289332556, 0.7844571081409818, 0.784216047693045, 0.7844949075128879, 0.7844475073933869, 0.7841053845752668, 0.7844571081409818, 0.7845016079113327, 0.7844484899606501, 0.7844484899606501, 0.7844571081409818, 0.5758327623409291, 0.784493972298264, 0.7844475073933869, 0.7843618465967748, 0.7824503626107466, 0.7842545927413426, 0.7845060708975761, 0.7841053845752668, 0.7845060708975761, 0.7842540600241515, 0.7788448515071413, 0.7842540600241515, 0.7844949075128879, 0.7842540600241515, 0.7843451547914617, 0.7843618465967748, 0.7842540600241515, 0.7842540600241515]] \n",
      "\n",
      "mean AUC :  0.7314950551051025\n",
      "All std:  [[0.09515315388955521, 0.0709972574421397, 0.0764932550940903, 0.07241397296320344, 0.08288426169860336, 0.09577278508619275, 0.09766036060205119, 0.0681014488163249, 0.056819704023652405, 0.08607655892030214, 0.06376365181644204, 0.06877607819519961, 0.07840122278415654, 0.08837837898099568, 0.07440179764463006, 0.09585240547297388, 0.09448576359332832, 0.09705616388257225, 0.09448576359332832, 0.11464769390101813, 0.13654633278824083, 0.1331062261351764, 0.13279873750230725, 0.13304714734378317, 0.12428477111173608, 0.1237014416995846, 0.11364716136818684, 0.11607026133488843, 0.1161804885326118, 0.11647569718769087, 0.11627217401610808, 0.1045655202528181, 0.11652603816306169, 0.11893843213645491, 0.12558381578692518, 0.13501216555455042, 0.11895275493279744, 0.09433988660224611, 0.1568083741876543, 0.08789859414351758, 0.08488422105924155, 0.07506621741622078, 0.11648192520961342, 0.0588790931923109, 0.11407553444510986, 0.11604195502473184, 0.11632759079969186, 0.11613386851799005, 0.09651558163504591, 0.11604384977731323, 0.11634993035812433, 0.1623355082755136, 0.11605600379600103, 0.11633136110998585, 0.11618006347759167, 0.05595533533030126, 0.11610863865097987, 0.11649389937263334, 0.1162200429296075, 0.11611784082476859, 0.1161259608700629, 0.11615217456962498, 0.11615217456962498, 0.1160375318664684, 0.11618770034601682, 0.1165433231142344, 0.15552270994979964, 0.09602982208750034, 0.11654329340372507, 0.06614613244918699, 0.059680213284059556, 0.048406698658237816, 0.15766182747964866, 0.10048418051334906, 0.0476738635684965, 0.05100081141782777, 0.14672884688001184, 0.0896684520491011, 0.07636962569131218, 0.11531141326371178, 0.09024892853672023, 0.0982399310152335, 0.05068068374164503, 0.16468873430761502, 0.16441396228517657, 0.12428794146327972, 0.11607494101910022, 0.11575412181910394, 0.11567697155756364, 0.1161756838645625, 0.11575412181910394, 0.11575538368430473, 0.11575412181910394, 0.11575412181910394, 0.11618798885493423, 0.11618770034601682, 0.11618798885493423, 0.11616691569738138, 0.1161756838645625, 0.1161756838645625, 0.1161756838645625, 0.1161756838645625, 0.11613074268716443, 0.11618108805543237, 0.11626187834675764, 0.11575412181910394, 0.1161756838645625, 0.11614246480879273, 0.11615217456962498, 0.11618108805543237, 0.1161804885326118, 0.11617510550706625, 0.11618108805543237, 0.11618108805543237, 0.11606810986660882, 0.11621234385309423, 0.11618108805543237, 0.11618992474293849, 0.11615217456962498, 0.11617960002116003, 0.11618108805543237, 0.11616597939937633, 0.11575412181910394, 0.11615217456962498, 0.11614246480879273, 0.11572991407176977, 0.1160693463937531, 0.11615217456962498, 0.11618992474293849, 0.11618108805543237, 0.11613210739062971, 0.11618032067045993, 0.11615217456962498, 0.11614720491619623, 0.11614534737152675, 0.11618017206847985, 0.1161850693839747, 0.1161850693839747, 0.11616688615112741, 0.11617960002116003, 0.1161850693839747, 0.1161850693839747, 0.11612635774781215, 0.11618770034601682, 0.11618770034601682, 0.11618108805543237, 0.11614062971234322, 0.11612635774781215, 0.11612577857873597, 0.11654329340372507, 0.11612577857873597, 0.11607494101910022, 0.11616688615112741, 0.11616456797732581, 0.11616688615112741, 0.1161850693839747, 0.11649737622636894, 0.11615217456962498, 0.11616602452467388, 0.11615217456962498, 0.1161850693839747, 0.1161850693839747, 0.11618770034601682, 0.1386999478936882, 0.11618770034601682, 0.11612577857873597, 0.11614509455684158, 0.1161667365399307, 0.11614541979417464, 0.11618017206847985, 0.11614814822895607, 0.11616456797732581, 0.11614534737152675, 0.11653177745532013, 0.1161667365399307, 0.11616138741669423, 0.11649737622636894, 0.11614534737152675, 0.11618017206847985, 0.11614317560472544, 0.11614317560472544, 0.11614534737152675, 0.055650184117529276, 0.11618931412346865, 0.11616138741669423, 0.11612577857873597, 0.1156757103842337, 0.11654315475103973, 0.11614509455684158, 0.11649737622636894, 0.11614509455684158, 0.11654329340372507, 0.12174093011750635, 0.11654329340372507, 0.1161667365399307, 0.11654329340372507, 0.11615217456962498, 0.11612577857873597, 0.11654329340372507, 0.11654329340372507]] \n",
      "\n",
      "Best Hyperparameter:  OrderedDict([('bagging_fraction', 0.1), ('learning_rate', 0.009218746590440918), ('max_depth', 1), ('min_data_in_leaf', 1), ('num_leaves', 100)]) \n",
      "\n",
      "Best index/iterasi :  59\n",
      "Best AUC : 0.784583006970418 ( std: 0.11611784082476859 ) \n",
      "\n",
      "running time:  1493.1784653663635  detik. Dalam menit:  24.88630775610606  menit\n"
     ]
    }
   ],
   "source": [
    "seeds=[1,12,22,32,42,52,62,72,82,92]\n",
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for seed in seeds:\n",
    "    start_time = time.time()\n",
    "    auc,std,best_index,best_param=bayes_opt(X_bank,y_bank,model_l,hyper_space_7,iterasi,eval_metric,seed)\n",
    "    print(\"Seed: \",seed,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \",end_time-start_time,\" detik.\",\"Dalam menit: \",(end_time-start_time)/60,\" menit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "AllAUC=\n",
    "x=range(1,201)\n",
    "scatter_plot_1(x,AllAUC,142,200,\"iterasi\",\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(AllAUC))\n",
    "unik=set(AllAUC)\n",
    "print(len(unik))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T07:11:56.111558Z",
     "start_time": "2020-12-19T07:11:56.107561Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T02:27:17.097691Z",
     "start_time": "2020-12-29T02:03:27.112732Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  0 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  1 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  2 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  3 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  4 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  5 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  6 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  7 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  8 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterasi:  9 \n",
      "\n",
      "Iterasi:  200\n",
      "All AUC:  [array([0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.68444872, 0.5558095 , 0.69067774, 0.55335616, 0.68827106,\n",
      "       0.56359522, 0.69271624, 0.57103391, 0.68612258, 0.5716479 ,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56158866, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.68444872, 0.55222994, 0.69067774, 0.54796269, 0.68827106,\n",
      "       0.56162386, 0.69271624, 0.56855342, 0.68612258, 0.57448233,\n",
      "       0.51934169, 0.51629778, 0.45927552, 0.49725077, 0.47080602,\n",
      "       0.51965949, 0.49332792, 0.49014292, 0.48586867, 0.51518169,\n",
      "       0.51934169, 0.52464628, 0.45927552, 0.49893253, 0.47080602,\n",
      "       0.49302454, 0.49332792, 0.50366874, 0.48586867, 0.50978532,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116,\n",
      "       0.51934169, 0.50589489, 0.45927552, 0.49688575, 0.47080602,\n",
      "       0.49338189, 0.49332792, 0.48839309, 0.48586867, 0.50302116])] \n",
      "\n",
      "mean AUC :  0.5592041759450093\n",
      "All std:  [array([0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.14388071, 0.06501943, 0.15411007, 0.06273252, 0.15462237,\n",
      "       0.06512226, 0.15996924, 0.0662515 , 0.15913985, 0.06084473,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06031235, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.14388071, 0.06109795, 0.15411007, 0.05532304, 0.15462237,\n",
      "       0.06032162, 0.15996924, 0.06102544, 0.15913985, 0.06046253,\n",
      "       0.07109946, 0.08722681, 0.08950277, 0.07692142, 0.09185749,\n",
      "       0.0903394 , 0.09111273, 0.09337366, 0.08536695, 0.08056705,\n",
      "       0.07109946, 0.11284436, 0.08950277, 0.06514115, 0.09185749,\n",
      "       0.09607207, 0.09111273, 0.10700972, 0.08536695, 0.08451646,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ,\n",
      "       0.07109946, 0.07680073, 0.08950277, 0.0640579 , 0.09185749,\n",
      "       0.09361058, 0.09111273, 0.08328617, 0.08536695, 0.0819425 ])] \n",
      "\n",
      "Best Hyperparameter:  {'bagging_fraction': 0.1, 'learning_rate': 0.01, 'max_depth': 10, 'min_data_in_leaf': 70, 'num_leaves': 10} \n",
      "\n",
      "Best index/iterasi :  6\n",
      "Best AUC : 0.6927162433772406 ( std: 0.15996923634381377 ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterasi=200\n",
    "eval_metric='roc_auc'\n",
    "for i in range(0,10):\n",
    "    auc,std,best_index,best_param=grid_search(X_bank,y_bank,model_l,hyper_space_5,eval_metric)\n",
    "    print(\"iterasi: \",i,'\\n')\n",
    "    print_hasil(iterasi,auc,std,best_param,best_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# CatBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Experiment 1: \n",
    "    - Random search \n",
    "    - Iterasi : 200\n",
    "    - random state= 1,12,22,32,42,52,62,72,82,92\n",
    "- Experiment 2: \n",
    "    - BO (gaussian process) \n",
    "    - iterasi : 200\n",
    "    - random state= 1,12,22,32,42,52,62,72,82,92\n",
    "- Experiment 3: \n",
    "    - GS \n",
    "    - 10 iterasi \n",
    "- Experiment 4: \n",
    "    - BOHB \n",
    "    - random state= 1,12,22,32,42,52,62,72,82,92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Experiment 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
